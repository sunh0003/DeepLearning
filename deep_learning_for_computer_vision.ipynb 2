{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install mrcnn mtcnn keras-vggface\n",
    "\n",
    "!git clone https://github.com/experiencor/kangaroo.git\n",
    "\n",
    "!curl -L -o data.zip \"https://drive.google.com/uc?export=download&id=1E7B7ZK6kKGNK5ovc8sqxBywtC7v2_JL8\"\n",
    "!curl -L -o facenet_keras.h5 \"https://drive.google.com/uc?export=download&id=1PZ_6Zsy1Vb0s0JmjEmVd8FS99zoMCiN1\"\n",
    "!curl -L -o yolov3.weights \"https://pjreddie.com/media/files/yolov3.weights\"\n",
    "!curl -L -o mask_rcnn_coco.h5 \"https://goo.gl/a2p7dS\"\n",
    "\n",
    "!unzip -q -o data.zip\n",
    "\n",
    "!rm data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Download dogs-vs-cats.zip from https://www.kaggle.com/c/dogs-vs-cats/data and upload it on Colab before running the following cell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -q -o dogs-vs-cats.zip\n",
    "!unzip -q -o train.zip\n",
    "\n",
    "!rm train1.zip\n",
    "!rm train.zip\n",
    "!rm dogs-vs-cats.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Download train-jpg.tar.7z and train_v2.csv.zip from https://www.kaggle.com/c/planet-understanding-the-amazon-from-space/data and upload it on Colab before running the following cell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -q -o train_v2.csv.zip\n",
    "!7z x test-jpg.tar.7z\n",
    "!tar -xvf test-jpg.tar\n",
    "!7z x train-jpg.tar.7z\n",
    "!tar -xvf train-jpg.tar\n",
    "\n",
    "!rm train_v2.csv.zip\n",
    "!rm train-jpg.tar.7z\n",
    "!rm test-jpg.tar\n",
    "!rm train-jpg.tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Download 5-celebrity-faces-dataset.zip from https://www.kaggle.com/dansbecker/5-celebrity-faces-dataset and upload it on Colab before running the following cell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir 5-celebrity-faces-dataset\n",
    "!unzip -q -o 5-celebrity-faces-dataset.zip -d 5-celebrity-faces-dataset\n",
    "!rm 5-celebrity-faces-dataset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of a multilayer perceptron\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "visible = Input(shape=(10,))\n",
    "hidden1 = Dense(10, activation='relu')(visible)\n",
    "hidden2 = Dense(20, activation='relu')(hidden1)\n",
    "hidden3 = Dense(10, activation='relu')(hidden2)\n",
    "output = Dense(1, activation='sigmoid')(hidden3)\n",
    "model = Model(inputs=visible, outputs=output)\n",
    "# summarize layers\n",
    "model.summary()\n",
    "# plot graph\n",
    "plot_model(model, to_file='multilayer_perceptron_graph.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of a convolutional neural network\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "visible = Input(shape=(64,64,1))\n",
    "conv1 = Conv2D(32, (4,4), activation='relu')(visible)\n",
    "pool1 = MaxPooling2D()(conv1)\n",
    "conv2 = Conv2D(16, (4,4), activation='relu')(pool1)\n",
    "pool2 = MaxPooling2D()(conv2)\n",
    "flat1 = Flatten()(pool2)\n",
    "hidden1 = Dense(10, activation='relu')(flat1)\n",
    "output = Dense(1, activation='sigmoid')(hidden1)\n",
    "model = Model(inputs=visible, outputs=output)\n",
    "# summarize layers\n",
    "model.summary()\n",
    "# plot graph\n",
    "plot_model(model, to_file='convolutional_neural_network.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of a recurrent neural network\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers.recurrent import LSTM\n",
    "visible = Input(shape=(100,1))\n",
    "hidden1 = LSTM(10)(visible)\n",
    "hidden2 = Dense(10, activation='relu')(hidden1)\n",
    "output = Dense(1, activation='sigmoid')(hidden2)\n",
    "model = Model(inputs=visible, outputs=output)\n",
    "# summarize layers\n",
    "model.summary()\n",
    "# plot graph\n",
    "plot_model(model, to_file='recurrent_neural_network.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check PIL and Pillow version numbers\n",
    "import PIL\n",
    "print('Pillow Version:', PIL.__version__)\n",
    "print('PIL Version:', PIL.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and show an image with Pillow\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot\n",
    "# load the image\n",
    "image = Image.open('opera_house.jpg')\n",
    "# summarize some details about the image\n",
    "print(image.format)\n",
    "print(image.mode)\n",
    "print(image.size)\n",
    "# show the image\n",
    "pyplot.imshow(image)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and display an image with Matplotlib\n",
    "from matplotlib import image\n",
    "from matplotlib import pyplot\n",
    "# load image as pixel array\n",
    "data = image.imread('opera_house.jpg')\n",
    "# summarize shape of the pixel array\n",
    "print(data.dtype)\n",
    "print(data.shape)\n",
    "# display the array of pixels as an image\n",
    "pyplot.imshow(data)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert image alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image and convert to and from NumPy array\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "# load the image\n",
    "image = Image.open('opera_house.jpg')\n",
    "# convert image to numpy array\n",
    "data = asarray(image)\n",
    "# summarize shape\n",
    "print(data.shape)\n",
    "# create Pillow image\n",
    "image2 = Image.fromarray(data)\n",
    "# summarize image details\n",
    "print(image2.format)\n",
    "print(image2.mode)\n",
    "print(image2.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load from dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all images in a directory\n",
    "from os import listdir\n",
    "from matplotlib import image\n",
    "# load all images in a directory\n",
    "loaded_images = list()\n",
    "for filename in listdir('images'):\n",
    "\t# load image\n",
    "\timg_data = image.imread('images/' + filename)\n",
    "\t# store loaded image\n",
    "\tloaded_images.append(img_data)\n",
    "\tprint('> loaded %s %s' % (filename, img_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save PNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of saving an image in another format\n",
    "from PIL import Image\n",
    "# load the image\n",
    "image = Image.open('opera_house.jpg')\n",
    "# save as PNG format\n",
    "image.save('opera_house.png', format='PNG')\n",
    "# load the image again and inspect the format\n",
    "image2 = Image.open('opera_house.png')\n",
    "print(image2.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of saving a grayscale version of a loaded image\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot\n",
    "# load the image\n",
    "image = Image.open('opera_house.jpg')\n",
    "# convert the image to grayscale\n",
    "gs_image = image.convert(mode='L')\n",
    "# save in jpeg format\n",
    "gs_image.save('opera_house_grayscale.jpg')\n",
    "# load the image again and show it\n",
    "image2 = Image.open('opera_house_grayscale.jpg')\n",
    "# show the image\n",
    "pyplot.imshow(image2, cmap=\"gray\")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resize image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a thumbnail of an image\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot\n",
    "# load the image\n",
    "image = Image.open('opera_house.jpg')\n",
    "# report the size of the image\n",
    "print(image.size)\n",
    "# create a thumbnail and preserve aspect ratio\n",
    "image.thumbnail((100,100))\n",
    "# report the size of the modified image\n",
    "print(image.size)\n",
    "# show the image\n",
    "pyplot.imshow(image)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resize aspect ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize image and force a new shape\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot\n",
    "# load the image\n",
    "image = Image.open('opera_house.jpg')\n",
    "# report the size of the image\n",
    "print(image.size)\n",
    "# resize image and ignore original aspect ratio\n",
    "img_resized = image.resize((200,200))\n",
    "# report the size of the thumbnail\n",
    "print(img_resized.size)\n",
    "# show the image\n",
    "pyplot.imshow(img_resized)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flip image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create flipped versions of an image\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot\n",
    "# load image\n",
    "image = Image.open('opera_house.jpg')\n",
    "# horizontal flip\n",
    "hoz_flip = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "# vertical flip\n",
    "ver_flip = image.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "# plot all three images using matplotlib\n",
    "pyplot.subplot(311)\n",
    "pyplot.imshow(image)\n",
    "pyplot.subplot(312)\n",
    "pyplot.imshow(hoz_flip)\n",
    "pyplot.subplot(313)\n",
    "pyplot.imshow(ver_flip)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotated image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create rotated versions of an image\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot\n",
    "# load image\n",
    "image = Image.open('opera_house.jpg')\n",
    "# plot original image\n",
    "pyplot.subplot(311)\n",
    "pyplot.imshow(image)\n",
    "# rotate 45 degrees\n",
    "pyplot.subplot(312)\n",
    "pyplot.imshow(image.rotate(45))\n",
    "# rotate 90 degrees\n",
    "pyplot.subplot(313)\n",
    "pyplot.imshow(image.rotate(90))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cropped image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of cropping an image\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot\n",
    "# load image\n",
    "image = Image.open('opera_house.jpg')\n",
    "# create a cropped image\n",
    "cropped = image.crop((100, 100, 200, 200))\n",
    "# show cropped image\n",
    "pyplot.imshow(cropped)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and show an image with Pillow\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot\n",
    "# load the image\n",
    "image = Image.open('sydney_bridge.jpg')\n",
    "# summarize some details about the image\n",
    "print(image.format)\n",
    "print(image.mode)\n",
    "print(image.size)\n",
    "# show the image\n",
    "pyplot.imshow(image)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of pixel normalization\n",
    "from numpy import asarray\n",
    "from PIL import Image\n",
    "# load image\n",
    "image = Image.open('sydney_bridge.jpg')\n",
    "pixels = asarray(image)\n",
    "# confirm pixel range is 0-255\n",
    "print('Data Type: %s' % pixels.dtype)\n",
    "print('Min: %.3f, Max: %.3f' % (pixels.min(), pixels.max()))\n",
    "# convert from integers to floats\n",
    "pixels = pixels.astype('float32')\n",
    "# normalize to the range 0-1\n",
    "pixels /= 255.0\n",
    "# confirm the normalization\n",
    "print('Min: %.3f, Max: %.3f' % (pixels.min(), pixels.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of global centering (subtract mean)\n",
    "from numpy import asarray\n",
    "from PIL import Image\n",
    "# load image\n",
    "image = Image.open('sydney_bridge.jpg')\n",
    "pixels = asarray(image)\n",
    "# convert from integers to floats\n",
    "pixels = pixels.astype('float32')\n",
    "# calculate global mean\n",
    "mean = pixels.mean()\n",
    "print('Mean: %.3f' % mean)\n",
    "print('Min: %.3f, Max: %.3f' % (pixels.min(), pixels.max()))\n",
    "# global centering of pixels\n",
    "pixels = pixels - mean\n",
    "# confirm it had the desired effect\n",
    "mean = pixels.mean()\n",
    "print('Mean: %.3f' % mean)\n",
    "print('Min: %.3f, Max: %.3f' % (pixels.min(), pixels.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of per-channel centering (subtract mean)\n",
    "from numpy import asarray\n",
    "from PIL import Image\n",
    "# load image\n",
    "image = Image.open('sydney_bridge.jpg')\n",
    "pixels = asarray(image)\n",
    "# convert from integers to floats\n",
    "pixels = pixels.astype('float32')\n",
    "# calculate per-channel means and standard deviations\n",
    "means = pixels.mean(axis=(0,1), dtype='float64')\n",
    "print('Means: %s' % means)\n",
    "print('Mins: %s, Maxs: %s' % (pixels.min(axis=(0,1)), pixels.max(axis=(0,1))))\n",
    "# per-channel centering of pixels\n",
    "pixels -= means\n",
    "# confirm it had the desired effect\n",
    "means = pixels.mean(axis=(0,1), dtype='float64')\n",
    "print('Means: %s' % means)\n",
    "print('Mins: %s, Maxs: %s' % (pixels.min(axis=(0,1)), pixels.max(axis=(0,1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of global pixel standardization\n",
    "from numpy import asarray\n",
    "from PIL import Image\n",
    "# load image\n",
    "image = Image.open('sydney_bridge.jpg')\n",
    "pixels = asarray(image)\n",
    "# convert from integers to floats\n",
    "pixels = pixels.astype('float32')\n",
    "# calculate global mean and standard deviation\n",
    "mean, std = pixels.mean(), pixels.std()\n",
    "print('Mean: %.3f, Standard Deviation: %.3f' % (mean, std))\n",
    "# global standardization of pixels\n",
    "pixels = (pixels - mean) / std\n",
    "# confirm it had the desired effect\n",
    "mean, std = pixels.mean(), pixels.std()\n",
    "print('Mean: %.3f, Standard Deviation: %.3f' % (mean, std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positive global standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of global pixel standardization shifted to positive domain\n",
    "from numpy import asarray\n",
    "from numpy import clip\n",
    "from PIL import Image\n",
    "# load image\n",
    "image = Image.open('sydney_bridge.jpg')\n",
    "pixels = asarray(image)\n",
    "# convert from integers to floats\n",
    "pixels = pixels.astype('float32')\n",
    "# calculate global mean and standard deviation\n",
    "mean, std = pixels.mean(), pixels.std()\n",
    "print('Mean: %.3f, Standard Deviation: %.3f' % (mean, std))\n",
    "# global standardization of pixels\n",
    "pixels = (pixels - mean) / std\n",
    "# clip pixel values to [-1,1]\n",
    "pixels = clip(pixels, -1.0, 1.0)\n",
    "# shift from [-1,1] to [0,1] with 0.5 mean\n",
    "pixels = (pixels + 1.0) / 2.0\n",
    "# confirm it had the desired effect\n",
    "mean, std = pixels.mean(), pixels.std()\n",
    "print('Mean: %.3f, Standard Deviation: %.3f' % (mean, std))\n",
    "print('Min: %.3f, Max: %.3f' % (pixels.min(), pixels.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of per-channel pixel standardization\n",
    "from numpy import asarray\n",
    "from PIL import Image\n",
    "# load image\n",
    "image = Image.open('sydney_bridge.jpg')\n",
    "pixels = asarray(image)\n",
    "# convert from integers to floats\n",
    "pixels = pixels.astype('float32')\n",
    "# calculate per-channel means and standard deviations\n",
    "means = pixels.mean(axis=(0,1), dtype='float64')\n",
    "stds = pixels.std(axis=(0,1), dtype='float64')\n",
    "print('Means: %s, Stds: %s' % (means, stds))\n",
    "# per-channel standardization of pixels\n",
    "pixels = (pixels - means) / stds\n",
    "# confirm it had the desired effect\n",
    "means = pixels.mean(axis=(0,1), dtype='float64')\n",
    "stds = pixels.std(axis=(0,1), dtype='float64')\n",
    "print('Means: %s, Stds: %s' % (means, stds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 06"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of loading an image with the Keras API\n",
    "from keras.preprocessing.image import load_img\n",
    "from matplotlib import pyplot\n",
    "# load the image\n",
    "img = load_img('bondi_beach.jpg')\n",
    "# report details about the image\n",
    "print(type(img))\n",
    "print(img.format)\n",
    "print(img.mode)\n",
    "print(img.size)\n",
    "# show the image\n",
    "pyplot.imshow(img)\n",
    "pyplot.show(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of converting an image with the Keras API\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import array_to_img\n",
    "# load the image\n",
    "img = load_img('bondi_beach.jpg')\n",
    "print(type(img))\n",
    "# convert to numpy array\n",
    "img_array = img_to_array(img)\n",
    "print(img_array.dtype)\n",
    "print(img_array.shape)\n",
    "# convert back to image\n",
    "img_pil = array_to_img(img_array)\n",
    "print(type(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of saving an image with the Keras API\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import save_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from matplotlib import pyplot\n",
    "# load image as as grayscale\n",
    "img = load_img('bondi_beach.jpg', color_mode='grayscale')\n",
    "# convert image to a numpy array\n",
    "img_array = img_to_array(img)\n",
    "# save the image with a new filename\n",
    "save_img('bondi_beach_grayscale.jpg', img_array)\n",
    "# load the image to confirm it was saved correctly\n",
    "img = load_img('bondi_beach_grayscale.jpg')\n",
    "print(type(img))\n",
    "print(img.format)\n",
    "print(img.mode)\n",
    "print(img.size)\n",
    "pyplot.imshow(img)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and summarize the MNIST dataset\n",
    "from keras.datasets import mnist\n",
    "# load dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "# summarize dataset shape\n",
    "print('Train', train_images.shape, train_labels.shape)\n",
    "print('Test', (test_images.shape, test_labels.shape))\n",
    "# summarize pixel values\n",
    "print('Train', train_images.min(), train_images.max(), train_images.mean(), train_images.std())\n",
    "print('Test', test_images.min(), test_images.max(), test_images.mean(), test_images.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of normalizing a image dataset\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# load dataset\n",
    "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
    "# reshape dataset to have a single channel\n",
    "width, height, channels = trainX.shape[1], trainX.shape[2], 1\n",
    "trainX = trainX.reshape((trainX.shape[0], width, height, channels))\n",
    "testX = testX.reshape((testX.shape[0], width, height, channels))\n",
    "# confirm scale of pixels\n",
    "print('Train min=%.3f, max=%.3f' % (trainX.min(), trainX.max()))\n",
    "print('Test min=%.3f, max=%.3f' % (testX.min(), testX.max()))\n",
    "# create generator (1.0/255.0 = 0.003921568627451)\n",
    "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "# Note: there is no need to fit the generator in this case\n",
    "# prepare a iterators to scale images\n",
    "train_iterator = datagen.flow(trainX, trainY, batch_size=64)\n",
    "test_iterator = datagen.flow(testX, testY, batch_size=64)\n",
    "print('Batches train=%d, test=%d' % (len(train_iterator), len(test_iterator)))\n",
    "# confirm the scaling works\n",
    "batchX, batchy = train_iterator.next()\n",
    "print('Batch shape=%s, min=%.3f, max=%.3f' % (batchX.shape, batchX.min(), batchX.max()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of centering a image dataset\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# load dataset\n",
    "(trainX, trainy), (testX, testy) = mnist.load_data()\n",
    "# reshape dataset to have a single channel\n",
    "width, height, channels = trainX.shape[1], trainX.shape[2], 1\n",
    "trainX = trainX.reshape((trainX.shape[0], width, height, channels))\n",
    "testX = testX.reshape((testX.shape[0], width, height, channels))\n",
    "# report per-image mean\n",
    "print('Means train=%.3f, test=%.3f' % (trainX.mean(), testX.mean()))\n",
    "# create generator that centers pixel values\n",
    "datagen = ImageDataGenerator(featurewise_center=True)\n",
    "# calculate the mean on the training dataset\n",
    "datagen.fit(trainX)\n",
    "print('Data Generator Mean: %.3f' % datagen.mean)\n",
    "# demonstrate effect on a single batch of samples\n",
    "iterator = datagen.flow(trainX, trainy, batch_size=64)\n",
    "# get a batch\n",
    "batchX, batchy = iterator.next()\n",
    "# mean pixel value in the batch\n",
    "print(batchX.shape, batchX.mean())\n",
    "# demonstrate effect on entire training dataset\n",
    "iterator = datagen.flow(trainX, trainy, batch_size=len(trainX), shuffle=False)\n",
    "# get a batch\n",
    "batchX, batchy = iterator.next()\n",
    "# mean pixel value in the batch\n",
    "print(batchX.shape, batchX.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of standardizing a image dataset\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# load dataset\n",
    "(trainX, trainy), (testX, testy) = mnist.load_data()\n",
    "# reshape dataset to have a single channel\n",
    "width, height, channels = trainX.shape[1], trainX.shape[2], 1\n",
    "trainX = trainX.reshape((trainX.shape[0], width, height, channels))\n",
    "testX = testX.reshape((testX.shape[0], width, height, channels))\n",
    "# report pixel means and standard deviations\n",
    "print('Statistics train=%.3f (%.3f), test=%.3f (%.3f)' % (trainX.mean(), trainX.std(), testX.mean(), testX.std()))\n",
    "# create generator that centers pixel values\n",
    "datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
    "# calculate the mean on the training dataset\n",
    "datagen.fit(trainX)\n",
    "print('Data Generator mean=%.3f, std=%.3f' % (datagen.mean, datagen.std))\n",
    "# demonstrate effect on a single batch of samples\n",
    "iterator = datagen.flow(trainX, trainy, batch_size=64)\n",
    "# get a batch\n",
    "batchX, batchy = iterator.next()\n",
    "# pixel stats in the batch\n",
    "print(batchX.shape, batchX.mean(), batchX.std())\n",
    "# demonstrate effect on entire training dataset\n",
    "iterator = datagen.flow(trainX, trainy, batch_size=len(trainX), shuffle=False)\n",
    "# get a batch\n",
    "batchX, batchy = iterator.next()\n",
    "# pixel stats in the batch\n",
    "print(batchX.shape, batchX.mean(), batchX.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 08"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of progressively loading images from file\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# create generator\n",
    "datagen = ImageDataGenerator()\n",
    "# prepare an iterators for each dataset\n",
    "train_it = datagen.flow_from_directory('data/train/', class_mode='binary')\n",
    "val_it = datagen.flow_from_directory('data/validation/', class_mode='binary')\n",
    "test_it = datagen.flow_from_directory('data/test/', class_mode='binary')\n",
    "# confirm the iterator works\n",
    "batchX, batchy = train_it.next()\n",
    "print('Batch shape=%s, min=%.3f, max=%.3f' % (batchX.shape, batchX.min(), batchX.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 09"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Horizontal shift augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of horizontal shift image augmentation\n",
    "from numpy import expand_dims\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "# load the image\n",
    "img = load_img('bird.jpg')\n",
    "# convert to numpy array\n",
    "data = img_to_array(img)\n",
    "# expand dimension to one sample\n",
    "samples = expand_dims(data, 0)\n",
    "# create image data augmentation generator\n",
    "datagen = ImageDataGenerator(width_shift_range=[-200,200])\n",
    "# prepare iterator\n",
    "it = datagen.flow(samples, batch_size=1)\n",
    "# generate samples and plot\n",
    "for i in range(9):\n",
    "\t# define subplot\n",
    "\tpyplot.subplot(330 + 1 + i)\n",
    "\t# generate batch of images\n",
    "\tbatch = it.next()\n",
    "\t# convert to unsigned integers for viewing\n",
    "\timage = batch[0].astype('uint8')\n",
    "\t# plot raw pixel data\n",
    "\tpyplot.imshow(image)\n",
    "# show the figure\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vertical shift augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of vertical shift image augmentation\n",
    "from numpy import expand_dims\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "# load the image\n",
    "img = load_img('bird.jpg')\n",
    "# convert to numpy array\n",
    "data = img_to_array(img)\n",
    "# expand dimension to one sample\n",
    "samples = expand_dims(data, 0)\n",
    "# create image data augmentation generator\n",
    "datagen = ImageDataGenerator(height_shift_range=0.5)\n",
    "# prepare iterator\n",
    "it = datagen.flow(samples, batch_size=1)\n",
    "# generate samples and plot\n",
    "for i in range(9):\n",
    "\t# define subplot\n",
    "\tpyplot.subplot(330 + 1 + i)\n",
    "\t# generate batch of images\n",
    "\tbatch = it.next()\n",
    "\t# convert to unsigned integers for viewing\n",
    "\timage = batch[0].astype('uint8')\n",
    "\t# plot raw pixel data\n",
    "\tpyplot.imshow(image)\n",
    "# show the figure\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Horizontal flip augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of horizontal flip image augmentation\n",
    "from numpy import expand_dims\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "# load the image\n",
    "img = load_img('bird.jpg')\n",
    "# convert to numpy array\n",
    "data = img_to_array(img)\n",
    "# expand dimension to one sample\n",
    "samples = expand_dims(data, 0)\n",
    "# create image data augmentation generator\n",
    "datagen = ImageDataGenerator(horizontal_flip=True)\n",
    "# prepare iterator\n",
    "it = datagen.flow(samples, batch_size=1)\n",
    "# generate samples and plot\n",
    "for i in range(9):\n",
    "\t# define subplot\n",
    "\tpyplot.subplot(330 + 1 + i)\n",
    "\t# generate batch of images\n",
    "\tbatch = it.next()\n",
    "\t# convert to unsigned integers for viewing\n",
    "\timage = batch[0].astype('uint8')\n",
    "\t# plot raw pixel data\n",
    "\tpyplot.imshow(image)\n",
    "# show the figure\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotation augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of random rotation image augmentation\n",
    "from numpy import expand_dims\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "# load the image\n",
    "img = load_img('bird.jpg')\n",
    "# convert to numpy array\n",
    "data = img_to_array(img)\n",
    "# expand dimension to one sample\n",
    "samples = expand_dims(data, 0)\n",
    "# create image data augmentation generator\n",
    "datagen = ImageDataGenerator(rotation_range=90)\n",
    "# prepare iterator\n",
    "it = datagen.flow(samples, batch_size=1)\n",
    "# generate samples and plot\n",
    "for i in range(9):\n",
    "\t# define subplot\n",
    "\tpyplot.subplot(330 + 1 + i)\n",
    "\t# generate batch of images\n",
    "\tbatch = it.next()\n",
    "\t# convert to unsigned integers for viewing\n",
    "\timage = batch[0].astype('uint8')\n",
    "\t# plot raw pixel data\n",
    "\tpyplot.imshow(image)\n",
    "# show the figure\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brightness augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of brighting image augmentation\n",
    "from numpy import expand_dims\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "# load the image\n",
    "img = load_img('bird.jpg')\n",
    "# convert to numpy array\n",
    "data = img_to_array(img)\n",
    "# expand dimension to one sample\n",
    "samples = expand_dims(data, 0)\n",
    "# create image data augmentation generator\n",
    "datagen = ImageDataGenerator(brightness_range=[0.2,1.0])\n",
    "# prepare iterator\n",
    "it = datagen.flow(samples, batch_size=1)\n",
    "# generate samples and plot\n",
    "for i in range(9):\n",
    "\t# define subplot\n",
    "\tpyplot.subplot(330 + 1 + i)\n",
    "\t# generate batch of images\n",
    "\tbatch = it.next()\n",
    "\t# convert to unsigned integers for viewing\n",
    "\timage = batch[0].astype('uint8')\n",
    "\t# plot raw pixel data\n",
    "\tpyplot.imshow(image)\n",
    "# show the figure\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zoom augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of zoom image augmentation\n",
    "from numpy import expand_dims\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "# load the image\n",
    "img = load_img('bird.jpg')\n",
    "# convert to numpy array\n",
    "data = img_to_array(img)\n",
    "# expand dimension to one sample\n",
    "samples = expand_dims(data, 0)\n",
    "# create image data augmentation generator\n",
    "datagen = ImageDataGenerator(zoom_range=[0.5,1.0])\n",
    "# prepare iterator\n",
    "it = datagen.flow(samples, batch_size=1)\n",
    "# generate samples and plot\n",
    "for i in range(9):\n",
    "\t# define subplot\n",
    "\tpyplot.subplot(330 + 1 + i)\n",
    "\t# generate batch of images\n",
    "\tbatch = it.next()\n",
    "\t# convert to unsigned integers for viewing\n",
    "\timage = batch[0].astype('uint8')\n",
    "\t# plot raw pixel data\n",
    "\tpyplot.imshow(image)\n",
    "# show the figure\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of expanding dimensions\n",
    "from numpy import expand_dims\n",
    "from numpy import asarray\n",
    "from PIL import Image\n",
    "# load the image\n",
    "img = Image.open('penguin_parade.jpg')\n",
    "# convert the image to grayscale\n",
    "img = img.convert(mode='L')\n",
    "# convert to numpy array\n",
    "data = asarray(img)\n",
    "print(data.shape)\n",
    "# add channels first\n",
    "data_first = expand_dims(data, axis=0)\n",
    "print(data_first.shape)\n",
    "# add channels last\n",
    "data_last = expand_dims(data, axis=2)\n",
    "print(data_last.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change channel ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change image from channels last to channels first format\n",
    "from numpy import moveaxis\n",
    "from numpy import asarray\n",
    "from PIL import Image\n",
    "# load the color image\n",
    "img = Image.open('penguin_parade.jpg')\n",
    "# convert to numpy array\n",
    "data = asarray(img)\n",
    "print(data.shape)\n",
    "# change channels last to channels first format\n",
    "data = moveaxis(data, 2, 0)\n",
    "print(data.shape)\n",
    "# change channels first to channels last format\n",
    "data = moveaxis(data, 0, 2)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show channel ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show preferred channel order\n",
    "from keras import backend\n",
    "print(backend.image_data_format())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Force channel ordering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# force a channel ordering\n",
    "from keras import backend\n",
    "# force channels-first ordering\n",
    "backend.set_image_data_format('channels_first')\n",
    "print(backend.image_data_format())\n",
    "# force channels-last ordering\n",
    "backend.set_image_data_format('channels_last')\n",
    "print(backend.image_data_format())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D filter model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of calculation 1d convolutions\n",
    "from numpy import asarray\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D\n",
    "# define input data\n",
    "data = asarray([0, 0, 0, 1, 1, 0, 0, 0])\n",
    "data = data.reshape(1, 8, 1)\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(1, 3, input_shape=(8, 1)))\n",
    "# define a vertical line detector\n",
    "weights = [asarray([[[0]],[[1]],[[0]]]), asarray([0.0])]\n",
    "# store the weights in the model\n",
    "model.set_weights(weights)\n",
    "# confirm they were stored\n",
    "print(model.get_weights())\n",
    "# apply filter to input data\n",
    "yhat = model.predict(data)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually apply 1D filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually apply a 1d filter\n",
    "from numpy import asarray\n",
    "print(asarray([0, 1, 0]).dot(asarray([0, 0, 0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D filter model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of calculation 2d convolutions\n",
    "from numpy import asarray\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "# define input data\n",
    "data = [[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0]]\n",
    "data = asarray(data)\n",
    "data = data.reshape(1, 8, 8, 1)\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(1, (3,3), input_shape=(8, 8, 1)))\n",
    "# define a vertical line detector\n",
    "detector = [[[[0]],[[1]],[[0]]],\n",
    "            [[[0]],[[1]],[[0]]],\n",
    "            [[[0]],[[1]],[[0]]]]\n",
    "weights = [asarray(detector), asarray([0.0])]\n",
    "# store the weights in the model\n",
    "model.set_weights(weights)\n",
    "# confirm they were stored\n",
    "print(model.get_weights())\n",
    "# apply filter to input data\n",
    "yhat = model.predict(data)\n",
    "for r in range(yhat.shape[1]):\n",
    "\t# print each column in the row\n",
    "\tprint([yhat[0,r,c,0] for c in range(yhat.shape[2])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually apply 2D filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of manually applying a 2d filter.\n",
    "from numpy import asarray\n",
    "from numpy import tensordot\n",
    "m1 = asarray([[0, 1, 0],\n",
    "\t\t\t  [0, 1, 0],\n",
    "\t\t\t  [0, 1, 0]])\n",
    "m2 = asarray([[0, 0, 0],\n",
    "\t\t\t  [0, 0, 0],\n",
    "\t\t\t  [0, 0, 0]])\n",
    "print(tensordot(m1, m2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D vertical line filter conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of using a single convolutional layer\n",
    "from numpy import asarray\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "# define input data\n",
    "data = [[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0]]\n",
    "data = asarray(data)\n",
    "data = data.reshape(1, 8, 8, 1)\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(1, (3,3), input_shape=(8, 8, 1)))\n",
    "# summarize model\n",
    "model.summary()\n",
    "# define a vertical line detector\n",
    "detector = [[[[0]],[[1]],[[0]]],\n",
    "            [[[0]],[[1]],[[0]]],\n",
    "            [[[0]],[[1]],[[0]]]]\n",
    "weights = [asarray(detector), asarray([0.0])]\n",
    "# store the weights in the model\n",
    "model.set_weights(weights)\n",
    "# apply filter to input data\n",
    "yhat = model.predict(data)\n",
    "# enumerate rows\n",
    "for r in range(yhat.shape[1]):\n",
    "\t# print each column in the row\n",
    "\tprint([yhat[0,r,c,0] for c in range(yhat.shape[2])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked conv layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of stacked convolutional layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(1, (3,3), input_shape=(8, 8, 1)))\n",
    "model.add(Conv2D(1, (3,3)))\n",
    "# summarize model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv with 5x5 kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of a convolutional layer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(1, (5,5), input_shape=(8, 8, 1)))\n",
    "# summarize model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv with 1x1 kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of a convolutional layer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(1, (1,1), input_shape=(8, 8, 1)))\n",
    "# summarize model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv with 8x8 kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of a convolutional layer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(1, (8,8), input_shape=(8, 8, 1)))\n",
    "# summarize model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv with padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example a convolutional layer with padding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(1, (3,3), padding='same', input_shape=(8, 8, 1)))\n",
    "# summarize model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked conv with padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example a deep cnn with padding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(1, (3,3), padding='same', input_shape=(8, 8, 1)))\n",
    "model.add(Conv2D(1, (3,3), padding='same'))\n",
    "model.add(Conv2D(1, (3,3), padding='same'))\n",
    "# summarize model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv with larger stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of vertical line filter with a stride of 2\n",
    "from numpy import asarray\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "# define input data\n",
    "data = [[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0]]\n",
    "data = asarray(data)\n",
    "data = data.reshape(1, 8, 8, 1)\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(1, (3,3), strides=(2, 2), input_shape=(8, 8, 1)))\n",
    "# summarize model\n",
    "model.summary()\n",
    "# define a vertical line detector\n",
    "detector = [[[[0]],[[1]],[[0]]],\n",
    "            [[[0]],[[1]],[[0]]],\n",
    "            [[[0]],[[1]],[[0]]]]\n",
    "weights = [asarray(detector), asarray([0.0])]\n",
    "# store the weights in the model\n",
    "model.set_weights(weights)\n",
    "# apply filter to input data\n",
    "yhat = model.predict(data)\n",
    "# enumerate rows\n",
    "for r in range(yhat.shape[1]):\n",
    "\t# print each column in the row\n",
    "\tprint([yhat[0,r,c,0] for c in range(yhat.shape[2])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D vertical line filter conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of vertical line detection with a convolutional layer\n",
    "from numpy import asarray\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "# define input data\n",
    "data = [[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0]]\n",
    "data = asarray(data)\n",
    "data = data.reshape(1, 8, 8, 1)\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(1, (3,3), activation='relu', input_shape=(8, 8, 1)))\n",
    "# summarize model\n",
    "model.summary()\n",
    "# define a vertical line detector\n",
    "detector = [[[[0]],[[1]],[[0]]],\n",
    "            [[[0]],[[1]],[[0]]],\n",
    "            [[[0]],[[1]],[[0]]]]\n",
    "weights = [asarray(detector), asarray([0.0])]\n",
    "# store the weights in the model\n",
    "model.set_weights(weights)\n",
    "# apply filter to input data\n",
    "yhat = model.predict(data)\n",
    "# enumerate rows\n",
    "for r in range(yhat.shape[1]):\n",
    "\t# print each column in the row\n",
    "\tprint([yhat[0,r,c,0] for c in range(yhat.shape[2])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avg pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of average pooling\n",
    "from numpy import asarray\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import AveragePooling2D\n",
    "# define input data\n",
    "data = [[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0]]\n",
    "data = asarray(data)\n",
    "data = data.reshape(1, 8, 8, 1)\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(1, (3,3), activation='relu', input_shape=(8, 8, 1)))\n",
    "model.add(AveragePooling2D())\n",
    "# summarize model\n",
    "model.summary()\n",
    "# define a vertical line detector\n",
    "detector = [[[[0]],[[1]],[[0]]],\n",
    "            [[[0]],[[1]],[[0]]],\n",
    "            [[[0]],[[1]],[[0]]]]\n",
    "weights = [asarray(detector), asarray([0.0])]\n",
    "# store the weights in the model\n",
    "model.set_weights(weights)\n",
    "# apply filter to input data\n",
    "yhat = model.predict(data)\n",
    "# enumerate rows\n",
    "for r in range(yhat.shape[1]):\n",
    "\t# print each column in the row\n",
    "\tprint([yhat[0,r,c,0] for c in range(yhat.shape[2])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of max pooling\n",
    "from numpy import asarray\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "# define input data\n",
    "data = [[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0]]\n",
    "data = asarray(data)\n",
    "data = data.reshape(1, 8, 8, 1)\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(1, (3,3), activation='relu', input_shape=(8, 8, 1)))\n",
    "model.add(MaxPooling2D())\n",
    "# summarize model\n",
    "model.summary()\n",
    "# define a vertical line detector\n",
    "detector = [[[[0]],[[1]],[[0]]],\n",
    "            [[[0]],[[1]],[[0]]],\n",
    "            [[[0]],[[1]],[[0]]]]\n",
    "weights = [asarray(detector), asarray([0.0])]\n",
    "# store the weights in the model\n",
    "model.set_weights(weights)\n",
    "# apply filter to input data\n",
    "yhat = model.predict(data)\n",
    "# enumerate rows\n",
    "for r in range(yhat.shape[1]):\n",
    "\t# print each column in the row\n",
    "\tprint([yhat[0,r,c,0] for c in range(yhat.shape[2])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global max pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of using global max pooling\n",
    "from numpy import asarray\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "# define input data\n",
    "data = [[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0]]\n",
    "data = asarray(data)\n",
    "data = data.reshape(1, 8, 8, 1)\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(1, (3,3), activation='relu', input_shape=(8, 8, 1)))\n",
    "model.add(GlobalMaxPooling2D())\n",
    "# summarize model\n",
    "model.summary()\n",
    "# define a vertical line detector\n",
    "detector = [[[[0]],[[1]],[[0]]],\n",
    "            [[[0]],[[1]],[[0]]],\n",
    "            [[[0]],[[1]],[[0]]]]\n",
    "weights = [asarray(detector), asarray([0.0])]\n",
    "# store the weights in the model\n",
    "model.set_weights(weights)\n",
    "# apply filter to input data\n",
    "yhat = model.predict(data)\n",
    "# show result\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of simple cnn model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(512, (3,3), padding='same', activation='relu', input_shape=(256, 256, 3)))\n",
    "# summarize model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of a 1x1 filter for projection\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(512, (3,3), padding='same', activation='relu', input_shape=(256, 256, 3)))\n",
    "model.add(Conv2D(512, (1,1), activation='relu'))\n",
    "# summarize model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decreasing feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of a 1x1 filter for dimensionality reduction\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(512, (3,3), padding='same', activation='relu', input_shape=(256, 256, 3)))\n",
    "model.add(Conv2D(64, (1,1), activation='relu'))\n",
    "# summarize model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increasing feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of a 1x1 filter to increase dimensionality\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(512, (3,3), padding='same', activation='relu', input_shape=(256, 256, 3)))\n",
    "model.add(Conv2D(1024, (1,1), activation='relu'))\n",
    "# summarize model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One VGG block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of creating a CNN model with a VGG block\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.utils import plot_model\n",
    "\n",
    "# function for creating a vgg block\n",
    "def vgg_block(layer_in, n_filters, n_conv):\n",
    "\t# add convolutional layers\n",
    "\tfor _ in range(n_conv):\n",
    "\t\tlayer_in = Conv2D(n_filters, (3,3), padding='same', activation='relu')(layer_in)\n",
    "\t# add max pooling layer\n",
    "\tlayer_in = MaxPooling2D((2,2), strides=(2,2))(layer_in)\n",
    "\treturn layer_in\n",
    "\n",
    "# define model input\n",
    "visible = Input(shape=(256, 256, 3))\n",
    "# add vgg module\n",
    "layer = vgg_block(visible, 64, 2)\n",
    "# create model\n",
    "model = Model(inputs=visible, outputs=layer)\n",
    "# summarize model\n",
    "model.summary()\n",
    "# plot model architecture\n",
    "plot_model(model, show_shapes=True, to_file='vgg_block.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Many VGG blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of creating a CNN model with many VGG blocks\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.utils import plot_model\n",
    "\n",
    "# function for creating a vgg block\n",
    "def vgg_block(layer_in, n_filters, n_conv):\n",
    "\t# add convolutional layers\n",
    "\tfor _ in range(n_conv):\n",
    "\t\tlayer_in = Conv2D(n_filters, (3,3), padding='same', activation='relu')(layer_in)\n",
    "\t# add max pooling layer\n",
    "\tlayer_in = MaxPooling2D((2,2), strides=(2,2))(layer_in)\n",
    "\treturn layer_in\n",
    "\n",
    "# define model input\n",
    "visible = Input(shape=(256, 256, 3))\n",
    "# add vgg module\n",
    "layer = vgg_block(visible, 64, 2)\n",
    "# add vgg module\n",
    "layer = vgg_block(layer, 128, 2)\n",
    "# add vgg module\n",
    "layer = vgg_block(layer, 256, 4)\n",
    "# create model\n",
    "model = Model(inputs=visible, outputs=layer)\n",
    "# summarize model\n",
    "model.summary()\n",
    "# plot model architecture\n",
    "plot_model(model, show_shapes=True, to_file='multiple_vgg_blocks.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of creating a CNN with an inception module\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.utils import plot_model\n",
    "\n",
    "# function for creating a naive inception block\n",
    "def naive_inception_module(layer_in, f1, f2, f3):\n",
    "\t# 1x1 conv\n",
    "\tconv1 = Conv2D(f1, (1,1), padding='same', activation='relu')(layer_in)\n",
    "\t# 3x3 conv\n",
    "\tconv3 = Conv2D(f2, (3,3), padding='same', activation='relu')(layer_in)\n",
    "\t# 5x5 conv\n",
    "\tconv5 = Conv2D(f3, (5,5), padding='same', activation='relu')(layer_in)\n",
    "\t# 3x3 max pooling\n",
    "\tpool = MaxPooling2D((3,3), strides=(1,1), padding='same')(layer_in)\n",
    "\t# concatenate filters, assumes filters/channels last\n",
    "\tlayer_out = concatenate([conv1, conv3, conv5, pool], axis=-1)\n",
    "\treturn layer_out\n",
    "\n",
    "# define model input\n",
    "visible = Input(shape=(256, 256, 3))\n",
    "# add inception module\n",
    "layer = naive_inception_module(visible, 64, 128, 32)\n",
    "# create model\n",
    "model = Model(inputs=visible, outputs=layer)\n",
    "# summarize model\n",
    "model.summary()\n",
    "# plot model architecture\n",
    "plot_model(model, show_shapes=True, to_file='naive_inception_module.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of creating a CNN with an efficient inception module\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.utils import plot_model\n",
    "\n",
    "# function for creating a projected inception module\n",
    "def inception_module(layer_in, f1, f2_in, f2_out, f3_in, f3_out, f4_out):\n",
    "\t# 1x1 conv\n",
    "\tconv1 = Conv2D(f1, (1,1), padding='same', activation='relu')(layer_in)\n",
    "\t# 3x3 conv\n",
    "\tconv3 = Conv2D(f2_in, (1,1), padding='same', activation='relu')(layer_in)\n",
    "\tconv3 = Conv2D(f2_out, (3,3), padding='same', activation='relu')(conv3)\n",
    "\t# 5x5 conv\n",
    "\tconv5 = Conv2D(f3_in, (1,1), padding='same', activation='relu')(layer_in)\n",
    "\tconv5 = Conv2D(f3_out, (5,5), padding='same', activation='relu')(conv5)\n",
    "\t# 3x3 max pooling\n",
    "\tpool = MaxPooling2D((3,3), strides=(1,1), padding='same')(layer_in)\n",
    "\tpool = Conv2D(f4_out, (1,1), padding='same', activation='relu')(pool)\n",
    "\t# concatenate filters, assumes filters/channels last\n",
    "\tlayer_out = concatenate([conv1, conv3, conv5, pool], axis=-1)\n",
    "\treturn layer_out\n",
    "\n",
    "# define model input\n",
    "visible = Input(shape=(256, 256, 3))\n",
    "# add inception block 1\n",
    "layer = inception_module(visible, 64, 96, 128, 16, 32, 32)\n",
    "# add inception block 1\n",
    "layer = inception_module(layer, 128, 128, 192, 32, 96, 64)\n",
    "# create model\n",
    "model = Model(inputs=visible, outputs=layer)\n",
    "# summarize model\n",
    "model.summary()\n",
    "# plot model architecture\n",
    "plot_model(model, show_shapes=True, to_file='inception_module.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of a CNN model with an identity or projection residual module\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import add\n",
    "from keras.utils import plot_model\n",
    "\n",
    "# function for creating an identity or projection residual module\n",
    "def residual_module(layer_in, n_filters):\n",
    "\tmerge_input = layer_in\n",
    "\t# check if the number of filters needs to be increase, assumes channels last format\n",
    "\tif layer_in.shape[-1] != n_filters:\n",
    "\t\tmerge_input = Conv2D(n_filters, (1,1), padding='same', activation='relu', kernel_initializer='he_normal')(layer_in)\n",
    "\t# conv1\n",
    "\tconv1 = Conv2D(n_filters, (3,3), padding='same', activation='relu', kernel_initializer='he_normal')(layer_in)\n",
    "\t# conv2\n",
    "\tconv2 = Conv2D(n_filters, (3,3), padding='same', activation='linear', kernel_initializer='he_normal')(conv1)\n",
    "\t# add filters, assumes filters/channels last\n",
    "\tlayer_out = add([conv2, merge_input])\n",
    "\t# activation function\n",
    "\tlayer_out = Activation('relu')(layer_out)\n",
    "\treturn layer_out\n",
    "\n",
    "# define model input\n",
    "visible = Input(shape=(256, 256, 3))\n",
    "# add vgg module\n",
    "layer = residual_module(visible, 64)\n",
    "# create model\n",
    "model = Model(inputs=visible, outputs=layer)\n",
    "# summarize model\n",
    "model.summary()\n",
    "# plot model architecture\n",
    "plot_model(model, show_shapes=True, to_file='residual_module.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of loading the vgg16 model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "# load model\n",
    "model = VGG16()\n",
    "# summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of loading the inception v3 model\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "# load model\n",
    "model = InceptionV3()\n",
    "# summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of loading the resnet50 model\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "# load model\n",
    "model = ResNet50()\n",
    "# summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of using a pre-trained model as a classifier\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.applications.vgg16 import VGG16\n",
    "# load an image from file\n",
    "image = load_img('dog.jpg', target_size=(224, 224))\n",
    "# convert the image pixels to a numpy array\n",
    "image = img_to_array(image)\n",
    "# reshape data for the model\n",
    "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "# prepare the image for the VGG model\n",
    "image = preprocess_input(image)\n",
    "# load the model\n",
    "model = VGG16()\n",
    "# predict the probability across all output classes\n",
    "yhat = model.predict(image)\n",
    "# convert the probabilities to class labels\n",
    "label = decode_predictions(yhat)\n",
    "# retrieve the most likely result, e.g. highest probability\n",
    "label = label[0][0]\n",
    "# print the classification\n",
    "print('%s (%.2f%%)' % (label[1], label[2]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of using the vgg16 model as a feature extraction model\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from pickle import dump\n",
    "# load an image from file\n",
    "image = load_img('dog.jpg', target_size=(224, 224))\n",
    "# convert the image pixels to a numpy array\n",
    "image = img_to_array(image)\n",
    "# reshape data for the model\n",
    "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "# prepare the image for the VGG model\n",
    "image = preprocess_input(image)\n",
    "# load model\n",
    "model = VGG16()\n",
    "# remove the output layer\n",
    "model.layers.pop()\n",
    "model = Model(inputs=model.inputs, outputs=model.layers[-1].output)\n",
    "# get extracted features\n",
    "features = model.predict(image)\n",
    "print(features.shape)\n",
    "# save to file\n",
    "dump(features, open('dog.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained model with new output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of tending the vgg16 model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "# load model without classifier layers\n",
    "model = VGG16(include_top=False, input_shape=(300, 300, 3))\n",
    "# add new classifier layers\n",
    "flat1 = Flatten()(model.outputs)\n",
    "class1 = Dense(1024, activation='relu')(flat1)\n",
    "output = Dense(10, activation='softmax')(class1)\n",
    "# define new model\n",
    "model = Model(inputs=model.inputs, outputs=output)\n",
    "# summarize\n",
    "model.summary()\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of loading the fashion mnist dataset\n",
    "from matplotlib import pyplot\n",
    "from keras.datasets import fashion_mnist\n",
    "# load dataset\n",
    "(trainX, trainy), (testX, testy) = fashion_mnist.load_data()\n",
    "# summarize loaded dataset\n",
    "print('Train: X=%s, y=%s' % (trainX.shape, trainy.shape))\n",
    "print('Test: X=%s, y=%s' % (testX.shape, testy.shape))\n",
    "# plot first few images\n",
    "for i in range(9):\n",
    "\t# define subplot\n",
    "\tpyplot.subplot(330 + 1 + i)\n",
    "\t# plot raw pixel data\n",
    "\tpyplot.imshow(trainX[i], cmap=pyplot.get_cmap('gray'))\n",
    "# show the figure\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline cnn model for fashion mnist\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "\t# load dataset\n",
    "\t(trainX, trainY), (testX, testY) = fashion_mnist.load_data()\n",
    "\t# reshape dataset to have a single channel\n",
    "\ttrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "\ttestX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
    "\t# one hot encode target values\n",
    "\ttrainY = to_categorical(trainY)\n",
    "\ttestY = to_categorical(testY)\n",
    "\treturn trainX, trainY, testX, testY\n",
    "\n",
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "\t# convert from integers to floats\n",
    "\ttrain_norm = train.astype('float32')\n",
    "\ttest_norm = test.astype('float32')\n",
    "\t# normalize to range 0-1\n",
    "\ttrain_norm = train_norm / 255.0\n",
    "\ttest_norm = test_norm / 255.0\n",
    "\t# return normalized images\n",
    "\treturn train_norm, test_norm\n",
    "\n",
    "# define cnn model\n",
    "def define_model():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(10, activation='softmax'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.01, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "# evaluate a model using k-fold cross-validation\n",
    "def evaluate_model(dataX, dataY, n_folds=5):\n",
    "\tscores, histories = list(), list()\n",
    "\t# prepare cross validation\n",
    "\tkfold = KFold(n_folds, shuffle=True, random_state=1)\n",
    "\t# enumerate splits\n",
    "\tfor train_ix, test_ix in kfold.split(dataX):\n",
    "\t\t# define model\n",
    "\t\tmodel = define_model()\n",
    "\t\t# select rows for train and test\n",
    "\t\ttrainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]\n",
    "\t\t# fit model\n",
    "\t\thistory = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=0)\n",
    "\t\t# evaluate model\n",
    "\t\t_, acc = model.evaluate(testX, testY, verbose=0)\n",
    "\t\tprint('> %.3f' % (acc * 100.0))\n",
    "\t\t# append scores\n",
    "\t\tscores.append(acc)\n",
    "\t\thistories.append(history)\n",
    "\treturn scores, histories\n",
    "\n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(histories):\n",
    "\tfor i in range(len(histories)):\n",
    "\t\t# plot loss\n",
    "\t\tpyplot.subplot(211)\n",
    "\t\tpyplot.title('Cross Entropy Loss')\n",
    "\t\tpyplot.plot(histories[i].history['loss'], color='blue', label='train')\n",
    "\t\tpyplot.plot(histories[i].history['val_loss'], color='orange', label='test')\n",
    "\t\t# plot accuracy\n",
    "\t\tpyplot.subplot(212)\n",
    "\t\tpyplot.title('Classification Accuracy')\n",
    "\t\tpyplot.plot(histories[i].history['acc'], color='blue', label='train')\n",
    "\t\tpyplot.plot(histories[i].history['val_acc'], color='orange', label='test')\n",
    "\tpyplot.show()\n",
    "\n",
    "# summarize model performance\n",
    "def summarize_performance(scores):\n",
    "\t# print summary\n",
    "\tprint('Accuracy: mean=%.3f std=%.3f, n=%d' % (mean(scores)*100, std(scores)*100, len(scores)))\n",
    "\t# box and whisker plots of results\n",
    "\tpyplot.boxplot(scores)\n",
    "\tpyplot.show()\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# load dataset\n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\t# prepare pixel data\n",
    "\ttrainX, testX = prep_pixels(trainX, testX)\n",
    "\t# evaluate model\n",
    "\tscores, histories = evaluate_model(trainX, trainY)\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(histories)\n",
    "\t# summarize estimated performance\n",
    "\tsummarize_performance(scores)\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline with padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with padded convolutions for the fashion mnist dataset\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "\t# load dataset\n",
    "\t(trainX, trainY), (testX, testY) = fashion_mnist.load_data()\n",
    "\t# reshape dataset to have a single channel\n",
    "\ttrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "\ttestX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
    "\t# one hot encode target values\n",
    "\ttrainY = to_categorical(trainY)\n",
    "\ttestY = to_categorical(testY)\n",
    "\treturn trainX, trainY, testX, testY\n",
    "\n",
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "\t# convert from integers to floats\n",
    "\ttrain_norm = train.astype('float32')\n",
    "\ttest_norm = test.astype('float32')\n",
    "\t# normalize to range 0-1\n",
    "\ttrain_norm = train_norm / 255.0\n",
    "\ttest_norm = test_norm / 255.0\n",
    "\t# return normalized images\n",
    "\treturn train_norm, test_norm\n",
    "\n",
    "# define cnn model\n",
    "def define_model():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), padding='same', activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(10, activation='softmax'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.01, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "# evaluate a model using k-fold cross-validation\n",
    "def evaluate_model(dataX, dataY, n_folds=5):\n",
    "\tscores, histories = list(), list()\n",
    "\t# prepare cross validation\n",
    "\tkfold = KFold(n_folds, shuffle=True, random_state=1)\n",
    "\t# enumerate splits\n",
    "\tfor train_ix, test_ix in kfold.split(dataX):\n",
    "\t\t# define model\n",
    "\t\tmodel = define_model()\n",
    "\t\t# select rows for train and test\n",
    "\t\ttrainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]\n",
    "\t\t# fit model\n",
    "\t\thistory = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=0)\n",
    "\t\t# evaluate model\n",
    "\t\t_, acc = model.evaluate(testX, testY, verbose=0)\n",
    "\t\tprint('> %.3f' % (acc * 100.0))\n",
    "\t\t# append scores\n",
    "\t\tscores.append(acc)\n",
    "\t\thistories.append(history)\n",
    "\treturn scores, histories\n",
    "\n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(histories):\n",
    "\tfor i in range(len(histories)):\n",
    "\t\t# plot loss\n",
    "\t\tpyplot.subplot(211)\n",
    "\t\tpyplot.title('Cross Entropy Loss')\n",
    "\t\tpyplot.plot(histories[i].history['loss'], color='blue', label='train')\n",
    "\t\tpyplot.plot(histories[i].history['val_loss'], color='orange', label='test')\n",
    "\t\t# plot accuracy\n",
    "\t\tpyplot.subplot(212)\n",
    "\t\tpyplot.title('Classification Accuracy')\n",
    "\t\tpyplot.plot(histories[i].history['acc'], color='blue', label='train')\n",
    "\t\tpyplot.plot(histories[i].history['val_acc'], color='orange', label='test')\n",
    "\tpyplot.show()\n",
    "\n",
    "# summarize model performance\n",
    "def summarize_performance(scores):\n",
    "\t# print summary\n",
    "\tprint('Accuracy: mean=%.3f std=%.3f, n=%d' % (mean(scores)*100, std(scores)*100, len(scores)))\n",
    "\t# box and whisker plots of results\n",
    "\tpyplot.boxplot(scores)\n",
    "\tpyplot.show()\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# load dataset\n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\t# prepare pixel data\n",
    "\ttrainX, testX = prep_pixels(trainX, testX)\n",
    "\t# evaluate model\n",
    "\tscores, histories = evaluate_model(trainX, trainY)\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(histories)\n",
    "\t# summarize estimated performance\n",
    "\tsummarize_performance(scores)\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline with padding, more filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with double the filters for the fashion mnist dataset\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "\t# load dataset\n",
    "\t(trainX, trainY), (testX, testY) = fashion_mnist.load_data()\n",
    "\t# reshape dataset to have a single channel\n",
    "\ttrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "\ttestX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
    "\t# one hot encode target values\n",
    "\ttrainY = to_categorical(trainY)\n",
    "\ttestY = to_categorical(testY)\n",
    "\treturn trainX, trainY, testX, testY\n",
    "\n",
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "\t# convert from integers to floats\n",
    "\ttrain_norm = train.astype('float32')\n",
    "\ttest_norm = test.astype('float32')\n",
    "\t# normalize to range 0-1\n",
    "\ttrain_norm = train_norm / 255.0\n",
    "\ttest_norm = test_norm / 255.0\n",
    "\t# return normalized images\n",
    "\treturn train_norm, test_norm\n",
    "\n",
    "# define cnn model\n",
    "def define_model():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(64, (3, 3), padding='same', activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(10, activation='softmax'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.01, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "# evaluate a model using k-fold cross-validation\n",
    "def evaluate_model(dataX, dataY, n_folds=5):\n",
    "\tscores, histories = list(), list()\n",
    "\t# prepare cross validation\n",
    "\tkfold = KFold(n_folds, shuffle=True, random_state=1)\n",
    "\t# enumerate splits\n",
    "\tfor train_ix, test_ix in kfold.split(dataX):\n",
    "\t\t# define model\n",
    "\t\tmodel = define_model()\n",
    "\t\t# select rows for train and test\n",
    "\t\ttrainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]\n",
    "\t\t# fit model\n",
    "\t\thistory = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=0)\n",
    "\t\t# evaluate model\n",
    "\t\t_, acc = model.evaluate(testX, testY, verbose=0)\n",
    "\t\tprint('> %.3f' % (acc * 100.0))\n",
    "\t\t# append scores\n",
    "\t\tscores.append(acc)\n",
    "\t\thistories.append(history)\n",
    "\treturn scores, histories\n",
    "\n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(histories):\n",
    "\tfor i in range(len(histories)):\n",
    "\t\t# plot loss\n",
    "\t\tpyplot.subplot(211)\n",
    "\t\tpyplot.title('Cross Entropy Loss')\n",
    "\t\tpyplot.plot(histories[i].history['loss'], color='blue', label='train')\n",
    "\t\tpyplot.plot(histories[i].history['val_loss'], color='orange', label='test')\n",
    "\t\t# plot accuracy\n",
    "\t\tpyplot.subplot(212)\n",
    "\t\tpyplot.title('Classification Accuracy')\n",
    "\t\tpyplot.plot(histories[i].history['acc'], color='blue', label='train')\n",
    "\t\tpyplot.plot(histories[i].history['val_acc'], color='orange', label='test')\n",
    "\tpyplot.show()\n",
    "\n",
    "# summarize model performance\n",
    "def summarize_performance(scores):\n",
    "\t# print summary\n",
    "\tprint('Accuracy: mean=%.3f std=%.3f, n=%d' % (mean(scores)*100, std(scores)*100, len(scores)))\n",
    "\t# box and whisker plots of results\n",
    "\tpyplot.boxplot(scores)\n",
    "\tpyplot.show()\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# load dataset\n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\t# prepare pixel data\n",
    "\ttrainX, testX = prep_pixels(trainX, testX)\n",
    "\t# evaluate model\n",
    "\tscores, histories = evaluate_model(trainX, trainY)\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(histories)\n",
    "\t# summarize estimated performance\n",
    "\tsummarize_performance(scores)\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the final model to file\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "\t# load dataset\n",
    "\t(trainX, trainY), (testX, testY) = fashion_mnist.load_data()\n",
    "\t# reshape dataset to have a single channel\n",
    "\ttrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "\ttestX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
    "\t# one hot encode target values\n",
    "\ttrainY = to_categorical(trainY)\n",
    "\ttestY = to_categorical(testY)\n",
    "\treturn trainX, trainY, testX, testY\n",
    "\n",
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "\t# convert from integers to floats\n",
    "\ttrain_norm = train.astype('float32')\n",
    "\ttest_norm = test.astype('float32')\n",
    "\t# normalize to range 0-1\n",
    "\ttrain_norm = train_norm / 255.0\n",
    "\ttest_norm = test_norm / 255.0\n",
    "\t# return normalized images\n",
    "\treturn train_norm, test_norm\n",
    "\n",
    "# define cnn model\n",
    "def define_model():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(10, activation='softmax'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.01, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# load dataset\n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\t# prepare pixel data\n",
    "\ttrainX, testX = prep_pixels(trainX, testX)\n",
    "\t# define model\n",
    "\tmodel = define_model()\n",
    "\t# fit model\n",
    "\tmodel.fit(trainX, trainY, epochs=10, batch_size=32, verbose=0)\n",
    "\t# save model\n",
    "\tmodel.save('final_model.h5')\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the deep model on the test dataset\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "\t# load dataset\n",
    "\t(trainX, trainY), (testX, testY) = fashion_mnist.load_data()\n",
    "\t# reshape dataset to have a single channel\n",
    "\ttrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "\ttestX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
    "\t# one hot encode target values\n",
    "\ttrainY = to_categorical(trainY)\n",
    "\ttestY = to_categorical(testY)\n",
    "\treturn trainX, trainY, testX, testY\n",
    "\n",
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "\t# convert from integers to floats\n",
    "\ttrain_norm = train.astype('float32')\n",
    "\ttest_norm = test.astype('float32')\n",
    "\t# normalize to range 0-1\n",
    "\ttrain_norm = train_norm / 255.0\n",
    "\ttest_norm = test_norm / 255.0\n",
    "\t# return normalized images\n",
    "\treturn train_norm, test_norm\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# load dataset\n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\t# prepare pixel data\n",
    "\ttrainX, testX = prep_pixels(trainX, testX)\n",
    "\t# load model\n",
    "\tmodel = load_model('final_model.h5')\n",
    "\t# evaluate model on test dataset\n",
    "\t_, acc = model.evaluate(testX, testY, verbose=0)\n",
    "\tprint('> %.3f' % (acc * 100.0))\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction for a new image.\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import load_model\n",
    "\n",
    "# load and prepare the image\n",
    "def load_image(filename):\n",
    "\t# load the image\n",
    "\timg = load_img(filename, grayscale=True, target_size=(28, 28))\n",
    "\t# convert to array\n",
    "\timg = img_to_array(img)\n",
    "\t# reshape into a single sample with 1 channel\n",
    "\timg = img.reshape(1, 28, 28, 1)\n",
    "\t# prepare pixel data\n",
    "\timg = img.astype('float32')\n",
    "\timg = img / 255.0\n",
    "\treturn img\n",
    "\n",
    "# load an image and predict the class\n",
    "def run_example():\n",
    "\t# load the image\n",
    "\timg = load_image('sample_image.png')\n",
    "\t# load model\n",
    "\tmodel = load_model('final_model.h5')\n",
    "\t# predict the class\n",
    "\tresult = model.predict_classes(img)\n",
    "\tprint(result[0])\n",
    "\n",
    "# entry point, run the example\n",
    "run_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of loading the cifar10 dataset\n",
    "from matplotlib import pyplot\n",
    "from keras.datasets import cifar10\n",
    "# load dataset\n",
    "(trainX, trainy), (testX, testy) = cifar10.load_data()\n",
    "# summarize loaded dataset\n",
    "print('Train: X=%s, y=%s' % (trainX.shape, trainy.shape))\n",
    "print('Test: X=%s, y=%s' % (testX.shape, testy.shape))\n",
    "# plot first few images\n",
    "for i in range(9):\n",
    "\t# define subplot\n",
    "\tpyplot.subplot(330 + 1 + i)\n",
    "\t# plot raw pixel data\n",
    "\tpyplot.imshow(trainX[i])\n",
    "# show the figure\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test harness\n",
    "\n",
    "\n",
    "NOTE: no model is defined, this example will not run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test harness for evaluating models on the cifar10 dataset\n",
    "# NOTE: no model is defined, this example will not run\n",
    "import sys\n",
    "from matplotlib import pyplot\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "\n",
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "\t# load dataset\n",
    "\t(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
    "\t# one hot encode target values\n",
    "\ttrainY = to_categorical(trainY)\n",
    "\ttestY = to_categorical(testY)\n",
    "\treturn trainX, trainY, testX, testY\n",
    "\n",
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "\t# convert from integers to floats\n",
    "\ttrain_norm = train.astype('float32')\n",
    "\ttest_norm = test.astype('float32')\n",
    "\t# normalize to range 0-1\n",
    "\ttrain_norm = train_norm / 255.0\n",
    "\ttest_norm = test_norm / 255.0\n",
    "\t# return normalized images\n",
    "\treturn train_norm, test_norm\n",
    "\n",
    "# define cnn model\n",
    "def define_model():\n",
    "\tmodel = Sequential()\n",
    "\t# ...\n",
    "\treturn model\n",
    "\n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "\t# plot loss\n",
    "\tpyplot.subplot(211)\n",
    "\tpyplot.title('Cross Entropy Loss')\n",
    "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "\t# plot accuracy\n",
    "\tpyplot.subplot(212)\n",
    "\tpyplot.title('Classification Accuracy')\n",
    "\tpyplot.plot(history.history['acc'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_acc'], color='orange', label='test')\n",
    "\t# save plot to file\n",
    "\tfilename = sys.argv[0].split('/')[-1]\n",
    "\tpyplot.savefig(filename + '_plot.png')\n",
    "\tpyplot.close()\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# load dataset\n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\t# prepare pixel data\n",
    "\ttrainX, testX = prep_pixels(trainX, testX)\n",
    "\t# define model\n",
    "\tmodel = define_model()\n",
    "\t# fit model\n",
    "\thistory = model.fit(trainX, trainY, epochs=100, batch_size=64, validation_data=(testX, testY), verbose=0)\n",
    "\t# evaluate model\n",
    "\t_, acc = model.evaluate(testX, testY, verbose=0)\n",
    "\tprint('> %.3f' % (acc * 100.0))\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(history)\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model baseline 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline with 1 vgg block for the cifar10 dataset\n",
    "import sys\n",
    "from matplotlib import pyplot\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "\t# load dataset\n",
    "\t(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
    "\t# one hot encode target values\n",
    "\ttrainY = to_categorical(trainY)\n",
    "\ttestY = to_categorical(testY)\n",
    "\treturn trainX, trainY, testX, testY\n",
    "\n",
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "\t# convert from integers to floats\n",
    "\ttrain_norm = train.astype('float32')\n",
    "\ttest_norm = test.astype('float32')\n",
    "\t# normalize to range 0-1\n",
    "\ttrain_norm = train_norm / 255.0\n",
    "\ttest_norm = test_norm / 255.0\n",
    "\t# return normalized images\n",
    "\treturn train_norm, test_norm\n",
    "\n",
    "# define cnn model\n",
    "def define_model():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(10, activation='softmax'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.001, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "\t# plot loss\n",
    "\tpyplot.subplot(211)\n",
    "\tpyplot.title('Cross Entropy Loss')\n",
    "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "\t# plot accuracy\n",
    "\tpyplot.subplot(212)\n",
    "\tpyplot.title('Classification Accuracy')\n",
    "\tpyplot.plot(history.history['acc'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_acc'], color='orange', label='test')\n",
    "\t# save plot to file\n",
    "\tfilename = sys.argv[0].split('/')[-1]\n",
    "\tpyplot.savefig(filename + '_plot.png')\n",
    "\tpyplot.close()\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# load dataset\n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\t# prepare pixel data\n",
    "\ttrainX, testX = prep_pixels(trainX, testX)\n",
    "\t# define model\n",
    "\tmodel = define_model()\n",
    "\t# fit model\n",
    "\thistory = model.fit(trainX, trainY, epochs=100, batch_size=64, validation_data=(testX, testY), verbose=0)\n",
    "\t# evaluate model\n",
    "\t_, acc = model.evaluate(testX, testY, verbose=0)\n",
    "\tprint('> %.3f' % (acc * 100.0))\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(history)\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model baseline 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline with 2 vgg blocks for the cifar10 dataset\n",
    "import sys\n",
    "from matplotlib import pyplot\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "\t# load dataset\n",
    "\t(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
    "\t# one hot encode target values\n",
    "\ttrainY = to_categorical(trainY)\n",
    "\ttestY = to_categorical(testY)\n",
    "\treturn trainX, trainY, testX, testY\n",
    "\n",
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "\t# convert from integers to floats\n",
    "\ttrain_norm = train.astype('float32')\n",
    "\ttest_norm = test.astype('float32')\n",
    "\t# normalize to range 0-1\n",
    "\ttrain_norm = train_norm / 255.0\n",
    "\ttest_norm = test_norm / 255.0\n",
    "\t# return normalized images\n",
    "\treturn train_norm, test_norm\n",
    "\n",
    "# define cnn model\n",
    "def define_model():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(10, activation='softmax'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.001, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "\t# plot loss\n",
    "\tpyplot.subplot(211)\n",
    "\tpyplot.title('Cross Entropy Loss')\n",
    "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "\t# plot accuracy\n",
    "\tpyplot.subplot(212)\n",
    "\tpyplot.title('Classification Accuracy')\n",
    "\tpyplot.plot(history.history['acc'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_acc'], color='orange', label='test')\n",
    "\t# save plot to file\n",
    "\tfilename = sys.argv[0].split('/')[-1]\n",
    "\tpyplot.savefig(filename + '_plot.png')\n",
    "\tpyplot.close()\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# load dataset\n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\t# prepare pixel data\n",
    "\ttrainX, testX = prep_pixels(trainX, testX)\n",
    "\t# define model\n",
    "\tmodel = define_model()\n",
    "\t# fit model\n",
    "\thistory = model.fit(trainX, trainY, epochs=100, batch_size=64, validation_data=(testX, testY), verbose=0)\n",
    "\t# evaluate model\n",
    "\t_, acc = model.evaluate(testX, testY, verbose=0)\n",
    "\tprint('> %.3f' % (acc * 100.0))\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(history)\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model baseline 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline with 3 vgg blocks for the cifar10 dataset\n",
    "import sys\n",
    "from matplotlib import pyplot\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "\t# load dataset\n",
    "\t(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
    "\t# one hot encode target values\n",
    "\ttrainY = to_categorical(trainY)\n",
    "\ttestY = to_categorical(testY)\n",
    "\treturn trainX, trainY, testX, testY\n",
    "\n",
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "\t# convert from integers to floats\n",
    "\ttrain_norm = train.astype('float32')\n",
    "\ttest_norm = test.astype('float32')\n",
    "\t# normalize to range 0-1\n",
    "\ttrain_norm = train_norm / 255.0\n",
    "\ttest_norm = test_norm / 255.0\n",
    "\t# return normalized images\n",
    "\treturn train_norm, test_norm\n",
    "\n",
    "# define cnn model\n",
    "def define_model():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(10, activation='softmax'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.001, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "\t# plot loss\n",
    "\tpyplot.subplot(211)\n",
    "\tpyplot.title('Cross Entropy Loss')\n",
    "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "\t# plot accuracy\n",
    "\tpyplot.subplot(212)\n",
    "\tpyplot.title('Classification Accuracy')\n",
    "\tpyplot.plot(history.history['acc'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_acc'], color='orange', label='test')\n",
    "\t# save plot to file\n",
    "\tfilename = sys.argv[0].split('/')[-1]\n",
    "\tpyplot.savefig(filename + '_plot.png')\n",
    "\tpyplot.close()\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# load dataset\n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\t# prepare pixel data\n",
    "\ttrainX, testX = prep_pixels(trainX, testX)\n",
    "\t# define model\n",
    "\tmodel = define_model()\n",
    "\t# fit model\n",
    "\thistory = model.fit(trainX, trainY, epochs=100, batch_size=64, validation_data=(testX, testY), verbose=0)\n",
    "\t# evaluate model\n",
    "\t_, acc = model.evaluate(testX, testY, verbose=0)\n",
    "\tprint('> %.3f' % (acc * 100.0))\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(history)\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3 VGG dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline model with dropout on the cifar10 dataset\n",
    "import sys\n",
    "from matplotlib import pyplot\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "\t# load dataset\n",
    "\t(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
    "\t# one hot encode target values\n",
    "\ttrainY = to_categorical(trainY)\n",
    "\ttestY = to_categorical(testY)\n",
    "\treturn trainX, trainY, testX, testY\n",
    "\n",
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "\t# convert from integers to floats\n",
    "\ttrain_norm = train.astype('float32')\n",
    "\ttest_norm = test.astype('float32')\n",
    "\t# normalize to range 0-1\n",
    "\ttrain_norm = train_norm / 255.0\n",
    "\ttest_norm = test_norm / 255.0\n",
    "\t# return normalized images\n",
    "\treturn train_norm, test_norm\n",
    "\n",
    "# define cnn model\n",
    "def define_model():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Dense(10, activation='softmax'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.001, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "\t# plot loss\n",
    "\tpyplot.subplot(211)\n",
    "\tpyplot.title('Cross Entropy Loss')\n",
    "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "\t# plot accuracy\n",
    "\tpyplot.subplot(212)\n",
    "\tpyplot.title('Classification Accuracy')\n",
    "\tpyplot.plot(history.history['acc'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_acc'], color='orange', label='test')\n",
    "\t# save plot to file\n",
    "\tfilename = sys.argv[0].split('/')[-1]\n",
    "\tpyplot.savefig(filename + '_plot.png')\n",
    "\tpyplot.close()\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# load dataset\n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\t# prepare pixel data\n",
    "\ttrainX, testX = prep_pixels(trainX, testX)\n",
    "\t# define model\n",
    "\tmodel = define_model()\n",
    "\t# fit model\n",
    "\thistory = model.fit(trainX, trainY, epochs=100, batch_size=64, validation_data=(testX, testY), verbose=0)\n",
    "\t# evaluate model\n",
    "\t_, acc = model.evaluate(testX, testY, verbose=0)\n",
    "\tprint('> %.3f' % (acc * 100.0))\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(history)\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3 VGG data aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline model with data augmentation on the cifar10 dataset\n",
    "import sys\n",
    "from matplotlib import pyplot\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "\t# load dataset\n",
    "\t(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
    "\t# one hot encode target values\n",
    "\ttrainY = to_categorical(trainY)\n",
    "\ttestY = to_categorical(testY)\n",
    "\treturn trainX, trainY, testX, testY\n",
    "\n",
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "\t# convert from integers to floats\n",
    "\ttrain_norm = train.astype('float32')\n",
    "\ttest_norm = test.astype('float32')\n",
    "\t# normalize to range 0-1\n",
    "\ttrain_norm = train_norm / 255.0\n",
    "\ttest_norm = test_norm / 255.0\n",
    "\t# return normalized images\n",
    "\treturn train_norm, test_norm\n",
    "\n",
    "# define cnn model\n",
    "def define_model():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(10, activation='softmax'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.001, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "\t# plot loss\n",
    "\tpyplot.subplot(211)\n",
    "\tpyplot.title('Cross Entropy Loss')\n",
    "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "\t# plot accuracy\n",
    "\tpyplot.subplot(212)\n",
    "\tpyplot.title('Classification Accuracy')\n",
    "\tpyplot.plot(history.history['acc'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_acc'], color='orange', label='test')\n",
    "\t# save plot to file\n",
    "\tfilename = sys.argv[0].split('/')[-1]\n",
    "\tpyplot.savefig(filename + '_plot.png')\n",
    "\tpyplot.close()\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# load dataset\n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\t# prepare pixel data\n",
    "\ttrainX, testX = prep_pixels(trainX, testX)\n",
    "\t# define model\n",
    "\tmodel = define_model()\n",
    "\t# create data generator\n",
    "\tdatagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
    "\t# prepare iterator\n",
    "\tit_train = datagen.flow(trainX, trainY, batch_size=64)\n",
    "\t# fit model\n",
    "\tsteps = int(trainX.shape[0] / 64)\n",
    "\thistory = model.fit_generator(it_train, steps_per_epoch=steps, epochs=100, validation_data=(testX, testY), verbose=0)\n",
    "\t# evaluate model\n",
    "\t_, acc = model.evaluate(testX, testY, verbose=0)\n",
    "\tprint('> %.3f' % (acc * 100.0))\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(history)\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3 VGG dropout data aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline model with dropout and data augmentation on the cifar10 dataset\n",
    "import sys\n",
    "from matplotlib import pyplot\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dropout\n",
    "\n",
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "\t# load dataset\n",
    "\t(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
    "\t# one hot encode target values\n",
    "\ttrainY = to_categorical(trainY)\n",
    "\ttestY = to_categorical(testY)\n",
    "\treturn trainX, trainY, testX, testY\n",
    "\n",
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "\t# convert from integers to floats\n",
    "\ttrain_norm = train.astype('float32')\n",
    "\ttest_norm = test.astype('float32')\n",
    "\t# normalize to range 0-1\n",
    "\ttrain_norm = train_norm / 255.0\n",
    "\ttest_norm = test_norm / 255.0\n",
    "\t# return normalized images\n",
    "\treturn train_norm, test_norm\n",
    "\n",
    "# define cnn model\n",
    "def define_model():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Dense(10, activation='softmax'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.001, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "\t# plot loss\n",
    "\tpyplot.subplot(211)\n",
    "\tpyplot.title('Cross Entropy Loss')\n",
    "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "\t# plot accuracy\n",
    "\tpyplot.subplot(212)\n",
    "\tpyplot.title('Classification Accuracy')\n",
    "\tpyplot.plot(history.history['acc'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_acc'], color='orange', label='test')\n",
    "\t# save plot to file\n",
    "\tfilename = sys.argv[0].split('/')[-1]\n",
    "\tpyplot.savefig(filename + '_plot.png')\n",
    "\tpyplot.close()\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# load dataset\n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\t# prepare pixel data\n",
    "\ttrainX, testX = prep_pixels(trainX, testX)\n",
    "\t# define model\n",
    "\tmodel = define_model()\n",
    "\t# create data generator\n",
    "\tdatagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
    "\t# prepare iterator\n",
    "\tit_train = datagen.flow(trainX, trainY, batch_size=64)\n",
    "\t# fit model\n",
    "\tsteps = int(trainX.shape[0] / 64)\n",
    "\thistory = model.fit_generator(it_train, steps_per_epoch=steps, epochs=200, validation_data=(testX, testY), verbose=0)\n",
    "\t# evaluate model\n",
    "\t_, acc = model.evaluate(testX, testY, verbose=0)\n",
    "\tprint('> %.3f' % (acc * 100.0))\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(history)\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3 VGG dropout data aug BN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline model with dropout and data augmentation on the cifar10 dataset\n",
    "import sys\n",
    "from matplotlib import pyplot\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "\t# load dataset\n",
    "\t(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
    "\t# one hot encode target values\n",
    "\ttrainY = to_categorical(trainY)\n",
    "\ttestY = to_categorical(testY)\n",
    "\treturn trainX, trainY, testX, testY\n",
    "\n",
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "\t# convert from integers to floats\n",
    "\ttrain_norm = train.astype('float32')\n",
    "\ttest_norm = test.astype('float32')\n",
    "\t# normalize to range 0-1\n",
    "\ttrain_norm = train_norm / 255.0\n",
    "\ttest_norm = test_norm / 255.0\n",
    "\t# return normalized images\n",
    "\treturn train_norm, test_norm\n",
    "\n",
    "# define cnn model\n",
    "def define_model():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Dropout(0.3))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Dropout(0.4))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(Dense(10, activation='softmax'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.001, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "\t# plot loss\n",
    "\tpyplot.subplot(211)\n",
    "\tpyplot.title('Cross Entropy Loss')\n",
    "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "\t# plot accuracy\n",
    "\tpyplot.subplot(212)\n",
    "\tpyplot.title('Classification Accuracy')\n",
    "\tpyplot.plot(history.history['acc'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_acc'], color='orange', label='test')\n",
    "\t# save plot to file\n",
    "\tfilename = sys.argv[0].split('/')[-1]\n",
    "\tpyplot.savefig(filename + '_plot.png')\n",
    "\tpyplot.close()\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# load dataset\n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\t# prepare pixel data\n",
    "\ttrainX, testX = prep_pixels(trainX, testX)\n",
    "\t# define model\n",
    "\tmodel = define_model()\n",
    "\t# create data generator\n",
    "\tdatagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
    "\t# prepare iterator\n",
    "\tit_train = datagen.flow(trainX, trainY, batch_size=64)\n",
    "\t# fit model\n",
    "\tsteps = int(trainX.shape[0] / 64)\n",
    "\thistory = model.fit_generator(it_train, steps_per_epoch=steps, epochs=400, validation_data=(testX, testY), verbose=0)\n",
    "\t# evaluate model\n",
    "\t_, acc = model.evaluate(testX, testY, verbose=0)\n",
    "\tprint('> %.3f' % (acc * 100.0))\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(history)\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the final model to file\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "\t# load dataset\n",
    "\t(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
    "\t# one hot encode target values\n",
    "\ttrainY = to_categorical(trainY)\n",
    "\ttestY = to_categorical(testY)\n",
    "\treturn trainX, trainY, testX, testY\n",
    "\n",
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "\t# convert from integers to floats\n",
    "\ttrain_norm = train.astype('float32')\n",
    "\ttest_norm = test.astype('float32')\n",
    "\t# normalize to range 0-1\n",
    "\ttrain_norm = train_norm / 255.0\n",
    "\ttest_norm = test_norm / 255.0\n",
    "\t# return normalized images\n",
    "\treturn train_norm, test_norm\n",
    "\n",
    "# define cnn model\n",
    "def define_model():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Dropout(0.3))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Dropout(0.4))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(Dense(10, activation='softmax'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.001, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# load dataset\n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\t# prepare pixel data\n",
    "\ttrainX, testX = prep_pixels(trainX, testX)\n",
    "\t# define model\n",
    "\tmodel = define_model()\n",
    "\t# create data generator\n",
    "\tdatagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
    "\t# prepare iterator\n",
    "\tit_train = datagen.flow(trainX, trainY, batch_size=64)\n",
    "\t# fit model\n",
    "\tsteps = int(trainX.shape[0] / 64)\n",
    "\tmodel.fit_generator(it_train, steps_per_epoch=steps, epochs=400, validation_data=(testX, testY), verbose=0)\n",
    "\t# save model\n",
    "\tmodel.save('final_model.h5')\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction for a new image.\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import load_model\n",
    "\n",
    "# load and prepare the image\n",
    "def load_image(filename):\n",
    "\t# load the image\n",
    "\timg = load_img(filename, target_size=(32, 32))\n",
    "\t# convert to array\n",
    "\timg = img_to_array(img)\n",
    "\t# reshape into a single sample with 3 channels\n",
    "\timg = img.reshape(1, 32, 32, 3)\n",
    "\t# prepare pixel data\n",
    "\timg = img.astype('float32')\n",
    "\timg = img / 255.0\n",
    "\treturn img\n",
    "\n",
    "# load an image and predict the class\n",
    "def run_example():\n",
    "\t# load the image\n",
    "\timg = load_image('sample_image_20.png')\n",
    "\t# load model\n",
    "\tmodel = load_model('final_model.h5')\n",
    "\t# predict the class\n",
    "\tresult = model.predict_classes(img)\n",
    "\tprint(result[0])\n",
    "\n",
    "# entry point, run the example\n",
    "run_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot dog photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot dog photos from the dogs vs cats dataset\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.image import imread\n",
    "# define location of dataset\n",
    "folder = 'train/'\n",
    "# plot first few images\n",
    "for i in range(9):\n",
    "\t# define subplot\n",
    "\tpyplot.subplot(330 + 1 + i)\n",
    "\t# define filename\n",
    "\tfilename = folder + 'dog.' + str(i) + '.jpg'\n",
    "\t# load image pixels\n",
    "\timage = imread(filename)\n",
    "\t# plot raw pixel data\n",
    "\tpyplot.imshow(image)\n",
    "# show the figure\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot cat photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot cat photos from the dogs vs cats dataset\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.image import imread\n",
    "# define location of dataset\n",
    "folder = 'train/'\n",
    "# plot first few images\n",
    "for i in range(9):\n",
    "\t# define subplot\n",
    "\tpyplot.subplot(330 + 1 + i)\n",
    "\t# define filename\n",
    "\tfilename = folder + 'cat.' + str(i) + '.jpg'\n",
    "\t# load image pixels\n",
    "\timage = imread(filename)\n",
    "\t# plot raw pixel data\n",
    "\tpyplot.imshow(image)\n",
    "# show the figure\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess photo sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dogs vs cats dataset, reshape and save to a new file\n",
    "from os import listdir\n",
    "from numpy import asarray\n",
    "from numpy import save\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "# define location of dataset\n",
    "folder = 'train/'\n",
    "photos, labels = list(), list()\n",
    "# enumerate files in the directory\n",
    "for file in listdir(folder):\n",
    "\t# determine class\n",
    "\toutput = 0.0\n",
    "\tif file.startswith('cat'):\n",
    "\t\toutput = 1.0\n",
    "\t# load image\n",
    "\tphoto = load_img(folder + file, target_size=(200, 200))\n",
    "\t# convert to numpy array\n",
    "\tphoto = img_to_array(photo)\n",
    "\t# store\n",
    "\tphotos.append(photo)\n",
    "\tlabels.append(output)\n",
    "# convert to numpy arrays\n",
    "photos = asarray(photos)\n",
    "labels = asarray(labels)\n",
    "print(photos.shape, labels.shape)\n",
    "# save the reshaped photos\n",
    "save('dogs_vs_cats_photos.npy', photos)\n",
    "save('dogs_vs_cats_labels.npy', labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load preprocessed photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and confirm the shape\n",
    "from numpy import load\n",
    "photos = load('dogs_vs_cats_photos.npy')\n",
    "labels = load('dogs_vs_cats_labels.npy')\n",
    "print(photos.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restructure dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organize dataset into a useful structure\n",
    "from os import makedirs\n",
    "from os import listdir\n",
    "from shutil import copyfile\n",
    "from random import seed\n",
    "from random import random\n",
    "# create directories\n",
    "dataset_home = 'dataset_dogs_vs_cats/'\n",
    "subdirs = ['train/', 'test/']\n",
    "for subdir in subdirs:\n",
    "\t# create label subdirectories\n",
    "\tlabeldirs = ['dogs/', 'cats/']\n",
    "\tfor labldir in labeldirs:\n",
    "\t\tnewdir = dataset_home + subdir + labldir\n",
    "\t\tmakedirs(newdir, exist_ok=True)\n",
    "# seed random number generator\n",
    "seed(1)\n",
    "# define ratio of pictures to use for validation\n",
    "val_ratio = 0.25\n",
    "# copy training dataset images into subdirectories\n",
    "src_directory = 'train/'\n",
    "for file in listdir(src_directory):\n",
    "\tsrc = src_directory + '/' + file\n",
    "\tdst_dir = 'train/'\n",
    "\tif random() < val_ratio:\n",
    "\t\tdst_dir = 'test/'\n",
    "\tif file.startswith('cat'):\n",
    "\t\tdst = dataset_home + dst_dir + 'cats/'  + file\n",
    "\t\tcopyfile(src, dst)\n",
    "\telif file.startswith('dog'):\n",
    "\t\tdst = dataset_home + dst_dir + 'dogs/'  + file\n",
    "\t\tcopyfile(src, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model baseline 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-vgg block baseline model for the dogs vs cats dataset\n",
    "import sys\n",
    "from matplotlib import pyplot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# define cnn model\n",
    "def define_model():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(1, activation='sigmoid'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.001, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "\t# plot loss\n",
    "\tpyplot.subplot(211)\n",
    "\tpyplot.title('Cross Entropy Loss')\n",
    "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "\t# plot accuracy\n",
    "\tpyplot.subplot(212)\n",
    "\tpyplot.title('Classification Accuracy')\n",
    "\tpyplot.plot(history.history['acc'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_acc'], color='orange', label='test')\n",
    "\t# save plot to file\n",
    "\tfilename = sys.argv[0].split('/')[-1]\n",
    "\tpyplot.savefig(filename + '_plot.png')\n",
    "\tpyplot.close()\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# define model\n",
    "\tmodel = define_model()\n",
    "\t# create data generator\n",
    "\tdatagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\t# prepare iterators\n",
    "\ttrain_it = datagen.flow_from_directory('dataset_dogs_vs_cats/train/',\n",
    "\t\tclass_mode='binary', batch_size=64, target_size=(200, 200))\n",
    "\ttest_it = datagen.flow_from_directory('dataset_dogs_vs_cats/test/',\n",
    "\t\tclass_mode='binary', batch_size=64, target_size=(200, 200))\n",
    "\t# fit model\n",
    "\thistory = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
    "\t\tvalidation_data=test_it, validation_steps=len(test_it), epochs=20, verbose=0)\n",
    "\t# evaluate model\n",
    "\t_, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
    "\tprint('> %.3f' % (acc * 100.0))\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(history)\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model baseline 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-vgg block baseline model for the dogs vs cats dataset\n",
    "import sys\n",
    "from matplotlib import pyplot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# define cnn model\n",
    "def define_model():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(1, activation='sigmoid'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.001, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "\t# plot loss\n",
    "\tpyplot.subplot(211)\n",
    "\tpyplot.title('Cross Entropy Loss')\n",
    "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "\t# plot accuracy\n",
    "\tpyplot.subplot(212)\n",
    "\tpyplot.title('Classification Accuracy')\n",
    "\tpyplot.plot(history.history['acc'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_acc'], color='orange', label='test')\n",
    "\t# save plot to file\n",
    "\tfilename = sys.argv[0].split('/')[-1]\n",
    "\tpyplot.savefig(filename + '_plot.png')\n",
    "\tpyplot.close()\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# define model\n",
    "\tmodel = define_model()\n",
    "\t# create data generator\n",
    "\tdatagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\t# prepare iterators\n",
    "\ttrain_it = datagen.flow_from_directory('dataset_dogs_vs_cats/train/',\n",
    "\t\tclass_mode='binary', batch_size=64, target_size=(200, 200))\n",
    "\ttest_it = datagen.flow_from_directory('dataset_dogs_vs_cats/test/',\n",
    "\t\tclass_mode='binary', batch_size=64, target_size=(200, 200))\n",
    "\t# fit model\n",
    "\thistory = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
    "\t\tvalidation_data=test_it, validation_steps=len(test_it), epochs=20, verbose=0)\n",
    "\t# evaluate model\n",
    "\t_, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
    "\tprint('> %.3f' % (acc * 100.0))\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(history)\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model baseline 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-vgg block baseline model for the dogs vs cats dataset\n",
    "import sys\n",
    "from matplotlib import pyplot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# define cnn model\n",
    "def define_model():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(1, activation='sigmoid'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.001, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "\t# plot loss\n",
    "\tpyplot.subplot(211)\n",
    "\tpyplot.title('Cross Entropy Loss')\n",
    "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "\t# plot accuracy\n",
    "\tpyplot.subplot(212)\n",
    "\tpyplot.title('Classification Accuracy')\n",
    "\tpyplot.plot(history.history['acc'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_acc'], color='orange', label='test')\n",
    "\t# save plot to file\n",
    "\tfilename = sys.argv[0].split('/')[-1]\n",
    "\tpyplot.savefig(filename + '_plot.png')\n",
    "\tpyplot.close()\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# define model\n",
    "\tmodel = define_model()\n",
    "\t# create data generator\n",
    "\tdatagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\t# prepare iterators\n",
    "\ttrain_it = datagen.flow_from_directory('dataset_dogs_vs_cats/train/',\n",
    "\t\tclass_mode='binary', batch_size=64, target_size=(200, 200))\n",
    "\ttest_it = datagen.flow_from_directory('dataset_dogs_vs_cats/test/',\n",
    "\t\tclass_mode='binary', batch_size=64, target_size=(200, 200))\n",
    "\t# fit model\n",
    "\thistory = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
    "\t\tvalidation_data=test_it, validation_steps=len(test_it), epochs=20, verbose=0)\n",
    "\t# evaluate model\n",
    "\t_, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
    "\tprint('> %.3f' % (acc * 100.0))\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(history)\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model baseline 3 dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline model with dropout for the dogs vs cats dataset\n",
    "import sys\n",
    "from matplotlib import pyplot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# define cnn model\n",
    "def define_model():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(Dense(1, activation='sigmoid'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.001, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "\t# plot loss\n",
    "\tpyplot.subplot(211)\n",
    "\tpyplot.title('Cross Entropy Loss')\n",
    "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "\t# plot accuracy\n",
    "\tpyplot.subplot(212)\n",
    "\tpyplot.title('Classification Accuracy')\n",
    "\tpyplot.plot(history.history['acc'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_acc'], color='orange', label='test')\n",
    "\t# save plot to file\n",
    "\tfilename = sys.argv[0].split('/')[-1]\n",
    "\tpyplot.savefig(filename + '_plot.png')\n",
    "\tpyplot.close()\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# define model\n",
    "\tmodel = define_model()\n",
    "\t# create data generator\n",
    "\tdatagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\t# prepare iterator\n",
    "\ttrain_it = datagen.flow_from_directory('dataset_dogs_vs_cats/train/',\n",
    "\t\tclass_mode='binary', batch_size=64, target_size=(200, 200))\n",
    "\ttest_it = datagen.flow_from_directory('dataset_dogs_vs_cats/test/',\n",
    "\t\tclass_mode='binary', batch_size=64, target_size=(200, 200))\n",
    "\t# fit model\n",
    "\thistory = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
    "\t\tvalidation_data=test_it, validation_steps=len(test_it), epochs=50, verbose=0)\n",
    "\t# evaluate model\n",
    "\t_, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
    "\tprint('> %.3f' % (acc * 100.0))\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(history)\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model baseline 3 data aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline model with data augmentation for the dogs vs cats dataset\n",
    "import sys\n",
    "from matplotlib import pyplot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# define cnn model\n",
    "def define_model():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(1, activation='sigmoid'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.001, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "\t# plot loss\n",
    "\tpyplot.subplot(211)\n",
    "\tpyplot.title('Cross Entropy Loss')\n",
    "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "\t# plot accuracy\n",
    "\tpyplot.subplot(212)\n",
    "\tpyplot.title('Classification Accuracy')\n",
    "\tpyplot.plot(history.history['acc'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_acc'], color='orange', label='test')\n",
    "\t# save plot to file\n",
    "\tfilename = sys.argv[0].split('/')[-1]\n",
    "\tpyplot.savefig(filename + '_plot.png')\n",
    "\tpyplot.close()\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# define model\n",
    "\tmodel = define_model()\n",
    "\t# create data generators\n",
    "\ttrain_datagen = ImageDataGenerator(rescale=1.0/255.0,\n",
    "\t\twidth_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
    "\ttest_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\t# prepare iterators\n",
    "\ttrain_it = train_datagen.flow_from_directory('dataset_dogs_vs_cats/train/',\n",
    "\t\tclass_mode='binary', batch_size=64, target_size=(200, 200))\n",
    "\ttest_it = test_datagen.flow_from_directory('dataset_dogs_vs_cats/test/',\n",
    "\t\tclass_mode='binary', batch_size=64, target_size=(200, 200))\n",
    "\t# fit model\n",
    "\thistory = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
    "\t\tvalidation_data=test_it, validation_steps=len(test_it), epochs=50, verbose=0)\n",
    "\t# evaluate model\n",
    "\t_, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
    "\tprint('> %.3f' % (acc * 100.0))\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(history)\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vgg16 model used for transfer learning on the dogs and cats dataset\n",
    "import sys\n",
    "from matplotlib import pyplot\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# define cnn model\n",
    "def define_model():\n",
    "\t# load model\n",
    "\tmodel = VGG16(include_top=False, input_shape=(224, 224, 3))\n",
    "\t# mark loaded layers as not trainable\n",
    "\tfor layer in model.layers:\n",
    "\t\tlayer.trainable = False\n",
    "\t# add new classifier layers\n",
    "\tflat1 = Flatten()(model.layers[-1].output)\n",
    "\tclass1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
    "\toutput = Dense(1, activation='sigmoid')(class1)\n",
    "\t# define new model\n",
    "\tmodel = Model(inputs=model.inputs, outputs=output)\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.001, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "\t# plot loss\n",
    "\tpyplot.subplot(211)\n",
    "\tpyplot.title('Cross Entropy Loss')\n",
    "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "\t# plot accuracy\n",
    "\tpyplot.subplot(212)\n",
    "\tpyplot.title('Classification Accuracy')\n",
    "\tpyplot.plot(history.history['acc'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_acc'], color='orange', label='test')\n",
    "\t# save plot to file\n",
    "\tfilename = sys.argv[0].split('/')[-1]\n",
    "\tpyplot.savefig(filename + '_plot.png')\n",
    "\tpyplot.close()\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# define model\n",
    "\tmodel = define_model()\n",
    "\t# create data generator\n",
    "\tdatagen = ImageDataGenerator(featurewise_center=True)\n",
    "\t# specify imagenet mean values for centering\n",
    "\tdatagen.mean = [123.68, 116.779, 103.939]\n",
    "\t# prepare iterator\n",
    "\ttrain_it = datagen.flow_from_directory('dataset_dogs_vs_cats/train/',\n",
    "\t\tclass_mode='binary', batch_size=64, target_size=(224, 224))\n",
    "\ttest_it = datagen.flow_from_directory('dataset_dogs_vs_cats/test/',\n",
    "\t\tclass_mode='binary', batch_size=64, target_size=(224, 224))\n",
    "\t# fit model\n",
    "\thistory = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
    "\t\tvalidation_data=test_it, validation_steps=len(test_it), epochs=10, verbose=1)\n",
    "\t# evaluate model\n",
    "\t_, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
    "\tprint('> %.3f' % (acc * 100.0))\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(history)\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organize dataset into a useful structure\n",
    "from os import makedirs\n",
    "from os import listdir\n",
    "from shutil import copyfile\n",
    "# create directories\n",
    "dataset_home = 'finalize_dogs_vs_cats/'\n",
    "# create label subdirectories\n",
    "labeldirs = ['dogs/', 'cats/']\n",
    "for labldir in labeldirs:\n",
    "\tnewdir = dataset_home + labldir\n",
    "\tmakedirs(newdir, exist_ok=True)\n",
    "# copy training dataset images into subdirectories\n",
    "src_directory = 'dogs-vs-cats/train/'\n",
    "for file in listdir(src_directory):\n",
    "\tsrc = src_directory + '/' + file\n",
    "\tif file.startswith('cat'):\n",
    "\t\tdst = dataset_home + 'cats/'  + file\n",
    "\t\tcopyfile(src, dst)\n",
    "\telif file.startswith('dog'):\n",
    "\t\tdst = dataset_home + 'dogs/'  + file\n",
    "\t\tcopyfile(src, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the final model to file\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# define cnn model\n",
    "def define_model():\n",
    "\t# load model\n",
    "\tmodel = VGG16(include_top=False, input_shape=(224, 224, 3))\n",
    "\t# mark loaded layers as not trainable\n",
    "\tfor layer in model.layers:\n",
    "\t\tlayer.trainable = False\n",
    "\t# add new classifier layers\n",
    "\tflat1 = Flatten()(model.layers[-1].output)\n",
    "\tclass1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
    "\toutput = Dense(1, activation='sigmoid')(class1)\n",
    "\t# define new model\n",
    "\tmodel = Model(inputs=model.inputs, outputs=output)\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.001, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "# define model\n",
    "\tmodel = define_model()\n",
    "\t# create data generator\n",
    "\tdatagen = ImageDataGenerator(featurewise_center=True)\n",
    "\t# specify imagenet mean values for centering\n",
    "\tdatagen.mean = [123.68, 116.779, 103.939]\n",
    "\t# prepare iterator\n",
    "\ttrain_it = datagen.flow_from_directory('finalize_dogs_vs_cats/',\n",
    "\t\tclass_mode='binary', batch_size=64, target_size=(224, 224))\n",
    "\t# fit model\n",
    "\tmodel.fit_generator(train_it, steps_per_epoch=len(train_it), epochs=10, verbose=0)\n",
    "\t# save model\n",
    "\tmodel.save('final_model.h5')\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction for a new image.\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import load_model\n",
    "\n",
    "# load and prepare the image\n",
    "def load_image(filename):\n",
    "\t# load the image\n",
    "\timg = load_img(filename, target_size=(224, 224))\n",
    "\t# convert to array\n",
    "\timg = img_to_array(img)\n",
    "\t# reshape into a single sample with 3 channels\n",
    "\timg = img.reshape(1, 224, 224, 3)\n",
    "\t# center pixel data\n",
    "\timg = img.astype('float32')\n",
    "\timg = img - [123.68, 116.779, 103.939]\n",
    "\treturn img\n",
    "\n",
    "# load an image and predict the class\n",
    "def run_example():\n",
    "\t# load the image\n",
    "\timg = load_image('sample_image.jpg')\n",
    "\t# load model\n",
    "\tmodel = load_model('final_model.h5')\n",
    "\t# predict the class\n",
    "\tresult = model.predict(img)\n",
    "\tprint(result[0])\n",
    "\n",
    "# entry point, run the example\n",
    "run_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the first 9 images in the planet dataset\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.image import imread\n",
    "# define location of dataset\n",
    "folder = 'train-jpg/'\n",
    "# plot first few images\n",
    "for i in range(9):\n",
    "\t# define subplot\n",
    "\tpyplot.subplot(330 + 1 + i)\n",
    "\t# define filename\n",
    "\tfilename = folder + 'train_' + str(i) + '.jpg'\n",
    "\t# load image pixels\n",
    "\timage = imread(filename)\n",
    "\t# plot raw pixel data\n",
    "\tpyplot.imshow(image)\n",
    "# show the figure\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load mapping file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and summarize the mapping file for the planet dataset\n",
    "from pandas import read_csv\n",
    "# load file as CSV\n",
    "filename = 'train_v2.csv'\n",
    "mapping_csv = read_csv(filename)\n",
    "# summarize properties\n",
    "print(mapping_csv.shape)\n",
    "print(mapping_csv[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map tags to ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mapping of tags to integers\n",
    "from pandas import read_csv\n",
    "\n",
    "# create a mapping of tags to integers given the loaded mapping file\n",
    "def create_tag_mapping(mapping_csv):\n",
    "\t# create a set of all known tags\n",
    "\tlabels = set()\n",
    "\tfor i in range(len(mapping_csv)):\n",
    "\t\t# convert spaced separated tags into an array of tags\n",
    "\t\ttags = mapping_csv['tags'][i].split(' ')\n",
    "\t\t# add tags to the set of known labels\n",
    "\t\tlabels.update(tags)\n",
    "\t# convert set of labels to a list to list\n",
    "\tlabels = list(labels)\n",
    "\t# order set alphabetically\n",
    "\tlabels.sort()\n",
    "\t# dict that maps labels to integers, and the reverse\n",
    "\tlabels_map = {labels[i]:i for i in range(len(labels))}\n",
    "\tinv_labels_map = {i:labels[i] for i in range(len(labels))}\n",
    "\treturn labels_map, inv_labels_map\n",
    "\n",
    "# load file as CSV\n",
    "filename = 'train_v2.csv'\n",
    "mapping_csv = read_csv(filename)\n",
    "# create a mapping of tags to integers\n",
    "mapping, inv_mapping = create_tag_mapping(mapping_csv)\n",
    "print(len(mapping))\n",
    "print(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and prepare planet dataset and save to file\n",
    "from os import listdir\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "from numpy import savez_compressed\n",
    "from pandas import read_csv\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "# create a mapping of tags to integers given the loaded mapping file\n",
    "def create_tag_mapping(mapping_csv):\n",
    "\t# create a set of all known tags\n",
    "\tlabels = set()\n",
    "\tfor i in range(len(mapping_csv)):\n",
    "\t\t# convert spaced separated tags into an array of tags\n",
    "\t\ttags = mapping_csv['tags'][i].split(' ')\n",
    "\t\t# add tags to the set of known labels\n",
    "\t\tlabels.update(tags)\n",
    "\t# convert set of labels to a list to list\n",
    "\tlabels = list(labels)\n",
    "\t# order set alphabetically\n",
    "\tlabels.sort()\n",
    "\t# dict that maps labels to integers, and the reverse\n",
    "\tlabels_map = {labels[i]:i for i in range(len(labels))}\n",
    "\tinv_labels_map = {i:labels[i] for i in range(len(labels))}\n",
    "\treturn labels_map, inv_labels_map\n",
    "\n",
    "# create a mapping of filename to a list of tags\n",
    "def create_file_mapping(mapping_csv):\n",
    "\tmapping = dict()\n",
    "\tfor i in range(len(mapping_csv)):\n",
    "\t\tname, tags = mapping_csv['image_name'][i], mapping_csv['tags'][i]\n",
    "\t\tmapping[name] = tags.split(' ')\n",
    "\treturn mapping\n",
    "\n",
    "# create a one hot encoding for one list of tags\n",
    "def one_hot_encode(tags, mapping):\n",
    "\t# create empty vector\n",
    "\tencoding = zeros(len(mapping), dtype='uint8')\n",
    "\t# mark 1 for each tag in the vector\n",
    "\tfor tag in tags:\n",
    "\t\tencoding[mapping[tag]] = 1\n",
    "\treturn encoding\n",
    "\n",
    "# load all images into memory\n",
    "def load_dataset(path, file_mapping, tag_mapping):\n",
    "\tphotos, targets = list(), list()\n",
    "\t# enumerate files in the directory\n",
    "\tfor filename in listdir(folder):\n",
    "\t\t# load image\n",
    "\t\tphoto = load_img(path + filename, target_size=(128,128))\n",
    "\t\t# convert to numpy array\n",
    "\t\tphoto = img_to_array(photo, dtype='uint8')\n",
    "\t\t# get tags\n",
    "\t\ttags = file_mapping[filename[:-4]]\n",
    "\t\t# one hot encode tags\n",
    "\t\ttarget = one_hot_encode(tags, tag_mapping)\n",
    "\t\t# store\n",
    "\t\tphotos.append(photo)\n",
    "\t\ttargets.append(target)\n",
    "\tX = asarray(photos, dtype='uint8')\n",
    "\ty = asarray(targets, dtype='uint8')\n",
    "\treturn X, y\n",
    "\n",
    "# load the mapping file\n",
    "filename = 'train_v2.csv'\n",
    "mapping_csv = read_csv(filename)\n",
    "# create a mapping of tags to integers\n",
    "tag_mapping, _ = create_tag_mapping(mapping_csv)\n",
    "# create a mapping of filenames to tag lists\n",
    "file_mapping = create_file_mapping(mapping_csv)\n",
    "# load the jpeg images\n",
    "folder = 'train-jpg/'\n",
    "X, y = load_dataset(folder, file_mapping, tag_mapping)\n",
    "print(X.shape, y.shape)\n",
    "# save both arrays to one file in compressed format\n",
    "savez_compressed('planet_data.npz', X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load prepared planet dataset\n",
    "from numpy import load\n",
    "data = load('planet_data.npz')\n",
    "X, y = data['arr_0'], data['arr_1']\n",
    "print('Loaded: ', X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test f-beta score\n",
    "from numpy import load\n",
    "from numpy import ones\n",
    "from numpy import asarray\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "\t# load dataset\n",
    "\tdata = load('planet_data.npz')\n",
    "\tX, y = data['arr_0'], data['arr_1']\n",
    "\t# separate into train and test datasets\n",
    "\ttrainX, testX, trainY, testY = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\tprint(trainX.shape, trainY.shape, testX.shape, testY.shape)\n",
    "\treturn trainX, trainY, testX, testY\n",
    "\n",
    "# load dataset\n",
    "trainX, trainY, testX, testY = load_dataset()\n",
    "# make all one predictions\n",
    "train_yhat = asarray([ones(trainY.shape[1]) for _ in range(trainY.shape[0])])\n",
    "test_yhat = asarray([ones(testY.shape[1]) for _ in range(testY.shape[0])])\n",
    "# evaluate predictions\n",
    "train_score = fbeta_score(trainY, train_yhat, 2, average='samples')\n",
    "test_score = fbeta_score(testY, test_yhat, 2, average='samples')\n",
    "print('All Ones: train=%.3f, test=%.3f' % (train_score, test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Keras sklearn f-beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare f-beta score between sklearn and keras\n",
    "from numpy import load\n",
    "from numpy import ones\n",
    "from numpy import asarray\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import fbeta_score\n",
    "from keras import backend\n",
    "\n",
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "\t# load dataset\n",
    "\tdata = load('planet_data.npz')\n",
    "\tX, y = data['arr_0'], data['arr_1']\n",
    "\t# separate into train and test datasets\n",
    "\ttrainX, testX, trainY, testY = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\tprint(trainX.shape, trainY.shape, testX.shape, testY.shape)\n",
    "\treturn trainX, trainY, testX, testY\n",
    "\n",
    "# calculate fbeta score for multi-class/label classification\n",
    "def fbeta(y_true, y_pred, beta=2):\n",
    "\t# clip predictions\n",
    "\ty_pred = backend.clip(y_pred, 0, 1)\n",
    "\t# calculate elements\n",
    "\ttp = backend.sum(backend.round(backend.clip(y_true * y_pred, 0, 1)), axis=1)\n",
    "\tfp = backend.sum(backend.round(backend.clip(y_pred - y_true, 0, 1)), axis=1)\n",
    "\tfn = backend.sum(backend.round(backend.clip(y_true - y_pred, 0, 1)), axis=1)\n",
    "\t# calculate precision\n",
    "\tp = tp / (tp + fp + backend.epsilon())\n",
    "\t# calculate recall\n",
    "\tr = tp / (tp + fn + backend.epsilon())\n",
    "\t# calculate fbeta, averaged across each class\n",
    "\tbb = beta ** 2\n",
    "\tfbeta_score = backend.mean((1 + bb) * (p * r) / (bb * p + r + backend.epsilon()))\n",
    "\treturn fbeta_score\n",
    "\n",
    "# load dataset\n",
    "trainX, trainY, testX, testY = load_dataset()\n",
    "# make all one predictions\n",
    "train_yhat = asarray([ones(trainY.shape[1]) for _ in range(trainY.shape[0])])\n",
    "test_yhat = asarray([ones(testY.shape[1]) for _ in range(testY.shape[0])])\n",
    "# evaluate predictions with sklearn\n",
    "train_score = fbeta_score(trainY, train_yhat, 2, average='samples')\n",
    "test_score = fbeta_score(testY, test_yhat, 2, average='samples')\n",
    "print('All Ones (sklearn): train=%.3f, test=%.3f' % (train_score, test_score))\n",
    "# evaluate predictions with keras\n",
    "train_score = fbeta(backend.variable(trainY), backend.variable(train_yhat)).eval(session=backend.get_session())\n",
    "test_score = fbeta(backend.variable(testY), backend.variable(test_yhat)).eval(session=backend.get_session())\n",
    "print('All Ones (keras): train=%.3f, test=%.3f' % (train_score, test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline model for the planet dataset\n",
    "import sys\n",
    "from numpy import load\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "\t# load dataset\n",
    "\tdata = load('planet_data.npz')\n",
    "\tX, y = data['arr_0'], data['arr_1']\n",
    "\t# separate into train and test datasets\n",
    "\ttrainX, testX, trainY, testY = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\tprint(trainX.shape, trainY.shape, testX.shape, testY.shape)\n",
    "\treturn trainX, trainY, testX, testY\n",
    "\n",
    "# calculate fbeta score for multi-class/label classification\n",
    "def fbeta(y_true, y_pred, beta=2):\n",
    "\t# clip predictions\n",
    "\ty_pred = backend.clip(y_pred, 0, 1)\n",
    "\t# calculate elements\n",
    "\ttp = backend.sum(backend.round(backend.clip(y_true * y_pred, 0, 1)), axis=1)\n",
    "\tfp = backend.sum(backend.round(backend.clip(y_pred - y_true, 0, 1)), axis=1)\n",
    "\tfn = backend.sum(backend.round(backend.clip(y_true - y_pred, 0, 1)), axis=1)\n",
    "\t# calculate precision\n",
    "\tp = tp / (tp + fp + backend.epsilon())\n",
    "\t# calculate recall\n",
    "\tr = tp / (tp + fn + backend.epsilon())\n",
    "\t# calculate fbeta, averaged across each class\n",
    "\tbb = beta ** 2\n",
    "\tfbeta_score = backend.mean((1 + bb) * (p * r) / (bb * p + r + backend.epsilon()))\n",
    "\treturn fbeta_score\n",
    "\n",
    "# define cnn model\n",
    "def define_model(in_shape=(128, 128, 3), out_shape=17):\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=in_shape))\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(out_shape, activation='sigmoid'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.01, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=[fbeta])\n",
    "\treturn model\n",
    "\n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "\t# plot loss\n",
    "\tpyplot.subplot(211)\n",
    "\tpyplot.title('Cross Entropy Loss')\n",
    "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "\t# plot accuracy\n",
    "\tpyplot.subplot(212)\n",
    "\tpyplot.title('Fbeta')\n",
    "\tpyplot.plot(history.history['fbeta'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_fbeta'], color='orange', label='test')\n",
    "\t# save plot to file\n",
    "\tfilename = sys.argv[0].split('/')[-1]\n",
    "\tpyplot.savefig(filename + '_plot.png')\n",
    "\tpyplot.close()\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# load dataset\n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\t# create data generator\n",
    "\tdatagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\t# prepare iterators\n",
    "\ttrain_it = datagen.flow(trainX, trainY, batch_size=128)\n",
    "\ttest_it = datagen.flow(testX, testY, batch_size=128)\n",
    "\t# define model\n",
    "\tmodel = define_model()\n",
    "\t# fit model\n",
    "\thistory = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
    "\t\tvalidation_data=test_it, validation_steps=len(test_it), epochs=50, verbose=0)\n",
    "\t# evaluate model\n",
    "\tloss, fbeta = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
    "\tprint('> loss=%.3f, fbeta=%.3f' % (loss, fbeta))\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(history)\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model baseline dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline model with dropout on the planet dataset\n",
    "import sys\n",
    "from numpy import load\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "\t# load dataset\n",
    "\tdata = load('planet_data.npz')\n",
    "\tX, y = data['arr_0'], data['arr_1']\n",
    "\t# separate into train and test datasets\n",
    "\ttrainX, testX, trainY, testY = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\tprint(trainX.shape, trainY.shape, testX.shape, testY.shape)\n",
    "\treturn trainX, trainY, testX, testY\n",
    "\n",
    "# calculate fbeta score for multi-class/label classification\n",
    "def fbeta(y_true, y_pred, beta=2):\n",
    "\t# clip predictions\n",
    "\ty_pred = backend.clip(y_pred, 0, 1)\n",
    "\t# calculate elements\n",
    "\ttp = backend.sum(backend.round(backend.clip(y_true * y_pred, 0, 1)), axis=1)\n",
    "\tfp = backend.sum(backend.round(backend.clip(y_pred - y_true, 0, 1)), axis=1)\n",
    "\tfn = backend.sum(backend.round(backend.clip(y_true - y_pred, 0, 1)), axis=1)\n",
    "\t# calculate precision\n",
    "\tp = tp / (tp + fp + backend.epsilon())\n",
    "\t# calculate recall\n",
    "\tr = tp / (tp + fn + backend.epsilon())\n",
    "\t# calculate fbeta, averaged across each class\n",
    "\tbb = beta ** 2\n",
    "\tfbeta_score = backend.mean((1 + bb) * (p * r) / (bb * p + r + backend.epsilon()))\n",
    "\treturn fbeta_score\n",
    "\n",
    "# define cnn model\n",
    "def define_model(in_shape=(128, 128, 3), out_shape=17):\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=in_shape))\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(Dense(out_shape, activation='sigmoid'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.01, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=[fbeta])\n",
    "\treturn model\n",
    "\n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "\t# plot loss\n",
    "\tpyplot.subplot(211)\n",
    "\tpyplot.title('Cross Entropy Loss')\n",
    "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "\t# plot accuracy\n",
    "\tpyplot.subplot(212)\n",
    "\tpyplot.title('Fbeta')\n",
    "\tpyplot.plot(history.history['fbeta'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_fbeta'], color='orange', label='test')\n",
    "\t# save plot to file\n",
    "\tfilename = sys.argv[0].split('/')[-1]\n",
    "\tpyplot.savefig(filename + '_plot.png')\n",
    "\tpyplot.close()\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# load dataset\n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\t# create data generator\n",
    "\tdatagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\t# prepare iterators\n",
    "\ttrain_it = datagen.flow(trainX, trainY, batch_size=128)\n",
    "\ttest_it = datagen.flow(testX, testY, batch_size=128)\n",
    "\t# define model\n",
    "\tmodel = define_model()\n",
    "\t# fit model\n",
    "\thistory = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
    "\t\tvalidation_data=test_it, validation_steps=len(test_it), epochs=200, verbose=0)\n",
    "\t# evaluate model\n",
    "\tloss, fbeta = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
    "\tprint('> loss=%.3f, fbeta=%.3f' % (loss, fbeta))\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(history)\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model baseline data aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline model with data augmentation for the planet dataset\n",
    "import sys\n",
    "from numpy import load\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "\t# load dataset\n",
    "\tdata = load('planet_data.npz')\n",
    "\tX, y = data['arr_0'], data['arr_1']\n",
    "\t# separate into train and test datasets\n",
    "\ttrainX, testX, trainY, testY = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\tprint(trainX.shape, trainY.shape, testX.shape, testY.shape)\n",
    "\treturn trainX, trainY, testX, testY\n",
    "\n",
    "# calculate fbeta score for multi-class/label classification\n",
    "def fbeta(y_true, y_pred, beta=2):\n",
    "\t# clip predictions\n",
    "\ty_pred = backend.clip(y_pred, 0, 1)\n",
    "\t# calculate elements\n",
    "\ttp = backend.sum(backend.round(backend.clip(y_true * y_pred, 0, 1)), axis=1)\n",
    "\tfp = backend.sum(backend.round(backend.clip(y_pred - y_true, 0, 1)), axis=1)\n",
    "\tfn = backend.sum(backend.round(backend.clip(y_true - y_pred, 0, 1)), axis=1)\n",
    "\t# calculate precision\n",
    "\tp = tp / (tp + fp + backend.epsilon())\n",
    "\t# calculate recall\n",
    "\tr = tp / (tp + fn + backend.epsilon())\n",
    "\t# calculate fbeta, averaged across each class\n",
    "\tbb = beta ** 2\n",
    "\tfbeta_score = backend.mean((1 + bb) * (p * r) / (bb * p + r + backend.epsilon()))\n",
    "\treturn fbeta_score\n",
    "\n",
    "# define cnn model\n",
    "def define_model(in_shape=(128, 128, 3), out_shape=17):\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=in_shape))\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(out_shape, activation='sigmoid'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.01, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=[fbeta])\n",
    "\treturn model\n",
    "\n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "\t# plot loss\n",
    "\tpyplot.subplot(211)\n",
    "\tpyplot.title('Cross Entropy Loss')\n",
    "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "\t# plot accuracy\n",
    "\tpyplot.subplot(212)\n",
    "\tpyplot.title('Fbeta')\n",
    "\tpyplot.plot(history.history['fbeta'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_fbeta'], color='orange', label='test')\n",
    "\t# save plot to file\n",
    "\tfilename = sys.argv[0].split('/')[-1]\n",
    "\tpyplot.savefig(filename + '_plot.png')\n",
    "\tpyplot.close()\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# load dataset\n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\t# create data generator\n",
    "\ttrain_datagen = ImageDataGenerator(rescale=1.0/255.0, horizontal_flip=True, vertical_flip=True, rotation_range=90)\n",
    "\ttest_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\t# prepare iterators\n",
    "\ttrain_it = train_datagen.flow(trainX, trainY, batch_size=128)\n",
    "\ttest_it = test_datagen.flow(testX, testY, batch_size=128)\n",
    "\t# define model\n",
    "\tmodel = define_model()\n",
    "\t# fit model\n",
    "\thistory = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
    "\t\tvalidation_data=test_it, validation_steps=len(test_it), epochs=200, verbose=0)\n",
    "\t# evaluate model\n",
    "\tloss, fbeta = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
    "\tprint('> loss=%.3f, fbeta=%.3f' % (loss, fbeta))\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(history)\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vgg16 transfer learning on the planet dataset\n",
    "import sys\n",
    "from numpy import load\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "\t# load dataset\n",
    "\tdata = load('planet_data.npz')\n",
    "\tX, y = data['arr_0'], data['arr_1']\n",
    "\t# separate into train and test datasets\n",
    "\ttrainX, testX, trainY, testY = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\tprint(trainX.shape, trainY.shape, testX.shape, testY.shape)\n",
    "\treturn trainX, trainY, testX, testY\n",
    "\n",
    "# calculate fbeta score for multi-class/label classification\n",
    "def fbeta(y_true, y_pred, beta=2):\n",
    "\t# clip predictions\n",
    "\ty_pred = backend.clip(y_pred, 0, 1)\n",
    "\t# calculate elements\n",
    "\ttp = backend.sum(backend.round(backend.clip(y_true * y_pred, 0, 1)), axis=1)\n",
    "\tfp = backend.sum(backend.round(backend.clip(y_pred - y_true, 0, 1)), axis=1)\n",
    "\tfn = backend.sum(backend.round(backend.clip(y_true - y_pred, 0, 1)), axis=1)\n",
    "\t# calculate precision\n",
    "\tp = tp / (tp + fp + backend.epsilon())\n",
    "\t# calculate recall\n",
    "\tr = tp / (tp + fn + backend.epsilon())\n",
    "\t# calculate fbeta, averaged across each class\n",
    "\tbb = beta ** 2\n",
    "\tfbeta_score = backend.mean((1 + bb) * (p * r) / (bb * p + r + backend.epsilon()))\n",
    "\treturn fbeta_score\n",
    "\n",
    "# define cnn model\n",
    "def define_model(in_shape=(128, 128, 3), out_shape=17):\n",
    "\t# load model\n",
    "\tmodel = VGG16(include_top=False, input_shape=in_shape)\n",
    "\t# mark loaded layers as not trainable\n",
    "\tfor layer in model.layers:\n",
    "\t\tlayer.trainable = False\n",
    "\t# add new classifier layers\n",
    "\tflat1 = Flatten()(model.layers[-1].output)\n",
    "\tclass1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
    "\toutput = Dense(out_shape, activation='sigmoid')(class1)\n",
    "\t# define new model\n",
    "\tmodel = Model(inputs=model.inputs, outputs=output)\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.01, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=[fbeta])\n",
    "\treturn model\n",
    "\n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "\t# plot loss\n",
    "\tpyplot.subplot(211)\n",
    "\tpyplot.title('Cross Entropy Loss')\n",
    "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "\t# plot accuracy\n",
    "\tpyplot.subplot(212)\n",
    "\tpyplot.title('Fbeta')\n",
    "\tpyplot.plot(history.history['fbeta'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_fbeta'], color='orange', label='test')\n",
    "\t# save plot to file\n",
    "\tfilename = sys.argv[0].split('/')[-1]\n",
    "\tpyplot.savefig(filename + '_plot.png')\n",
    "\tpyplot.close()\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# load dataset\n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\t# create data generator\n",
    "\tdatagen = ImageDataGenerator(featurewise_center=True)\n",
    "\t# specify imagenet mean values for centering\n",
    "\tdatagen.mean = [123.68, 116.779, 103.939]\n",
    "\t# prepare iterators\n",
    "\ttrain_it = datagen.flow(trainX, trainY, batch_size=128)\n",
    "\ttest_it = datagen.flow(testX, testY, batch_size=128)\n",
    "\t# define model\n",
    "\tmodel = define_model()\n",
    "\t# fit model\n",
    "\thistory = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
    "\t\tvalidation_data=test_it, validation_steps=len(test_it), epochs=20, verbose=0)\n",
    "\t# evaluate model\n",
    "\tloss, fbeta = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
    "\tprint('> loss=%.3f, fbeta=%.3f' % (loss, fbeta))\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(history)\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model pretrained trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vgg16 transfer learning on the planet dataset with some trainable layers\n",
    "import sys\n",
    "from numpy import load\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "\t# load dataset\n",
    "\tdata = load('planet_data.npz')\n",
    "\tX, y = data['arr_0'], data['arr_1']\n",
    "\t# separate into train and test datasets\n",
    "\ttrainX, testX, trainY, testY = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\tprint(trainX.shape, trainY.shape, testX.shape, testY.shape)\n",
    "\treturn trainX, trainY, testX, testY\n",
    "\n",
    "# calculate fbeta score for multi-class/label classification\n",
    "def fbeta(y_true, y_pred, beta=2):\n",
    "\t# clip predictions\n",
    "\ty_pred = backend.clip(y_pred, 0, 1)\n",
    "\t# calculate elements\n",
    "\ttp = backend.sum(backend.round(backend.clip(y_true * y_pred, 0, 1)), axis=1)\n",
    "\tfp = backend.sum(backend.round(backend.clip(y_pred - y_true, 0, 1)), axis=1)\n",
    "\tfn = backend.sum(backend.round(backend.clip(y_true - y_pred, 0, 1)), axis=1)\n",
    "\t# calculate precision\n",
    "\tp = tp / (tp + fp + backend.epsilon())\n",
    "\t# calculate recall\n",
    "\tr = tp / (tp + fn + backend.epsilon())\n",
    "\t# calculate fbeta, averaged across each class\n",
    "\tbb = beta ** 2\n",
    "\tfbeta_score = backend.mean((1 + bb) * (p * r) / (bb * p + r + backend.epsilon()))\n",
    "\treturn fbeta_score\n",
    "\n",
    "# define cnn model\n",
    "def define_model(in_shape=(128, 128, 3), out_shape=17):\n",
    "\t# load model\n",
    "\tmodel = VGG16(include_top=False, input_shape=in_shape)\n",
    "\t# mark loaded layers as not trainable\n",
    "\tfor layer in model.layers:\n",
    "\t\tlayer.trainable = False\n",
    "\t# allow last vgg block to be trainable\n",
    "\tmodel.get_layer('block5_conv1').trainable = True\n",
    "\tmodel.get_layer('block5_conv2').trainable = True\n",
    "\tmodel.get_layer('block5_conv3').trainable = True\n",
    "\tmodel.get_layer('block5_pool').trainable = True\n",
    "\t# add new classifier layers\n",
    "\tflat1 = Flatten()(model.layers[-1].output)\n",
    "\tclass1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
    "\toutput = Dense(out_shape, activation='sigmoid')(class1)\n",
    "\t# define new model\n",
    "\tmodel = Model(inputs=model.inputs, outputs=output)\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.01, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=[fbeta])\n",
    "\treturn model\n",
    "\n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "\t# plot loss\n",
    "\tpyplot.subplot(211)\n",
    "\tpyplot.title('Cross Entropy Loss')\n",
    "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "\t# plot accuracy\n",
    "\tpyplot.subplot(212)\n",
    "\tpyplot.title('Fbeta')\n",
    "\tpyplot.plot(history.history['fbeta'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_fbeta'], color='orange', label='test')\n",
    "\t# save plot to file\n",
    "\tfilename = sys.argv[0].split('/')[-1]\n",
    "\tpyplot.savefig(filename + '_plot.png')\n",
    "\tpyplot.close()\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# load dataset\n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\t# create data generator\n",
    "\tdatagen = ImageDataGenerator(featurewise_center=True)\n",
    "\t# specify imagenet mean values for centering\n",
    "\tdatagen.mean = [123.68, 116.779, 103.939]\n",
    "\t# prepare iterators\n",
    "\ttrain_it = datagen.flow(trainX, trainY, batch_size=128)\n",
    "\ttest_it = datagen.flow(testX, testY, batch_size=128)\n",
    "\t# define model\n",
    "\tmodel = define_model()\n",
    "\t# fit model\n",
    "\thistory = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
    "\t\tvalidation_data=test_it, validation_steps=len(test_it), epochs=20, verbose=0)\n",
    "\t# evaluate model\n",
    "\tloss, fbeta = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
    "\tprint('> loss=%.3f, fbeta=%.3f' % (loss, fbeta))\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(history)\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model pretrained trainable epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vgg with fine-tuning and data augmentation for the planet dataset\n",
    "import sys\n",
    "from numpy import load\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "\t# load dataset\n",
    "\tdata = load('planet_data.npz')\n",
    "\tX, y = data['arr_0'], data['arr_1']\n",
    "\t# separate into train and test datasets\n",
    "\ttrainX, testX, trainY, testY = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\tprint(trainX.shape, trainY.shape, testX.shape, testY.shape)\n",
    "\treturn trainX, trainY, testX, testY\n",
    "\n",
    "# calculate fbeta score for multi-class/label classification\n",
    "def fbeta(y_true, y_pred, beta=2):\n",
    "\t# clip predictions\n",
    "\ty_pred = backend.clip(y_pred, 0, 1)\n",
    "\t# calculate elements\n",
    "\ttp = backend.sum(backend.round(backend.clip(y_true * y_pred, 0, 1)), axis=1)\n",
    "\tfp = backend.sum(backend.round(backend.clip(y_pred - y_true, 0, 1)), axis=1)\n",
    "\tfn = backend.sum(backend.round(backend.clip(y_true - y_pred, 0, 1)), axis=1)\n",
    "\t# calculate precision\n",
    "\tp = tp / (tp + fp + backend.epsilon())\n",
    "\t# calculate recall\n",
    "\tr = tp / (tp + fn + backend.epsilon())\n",
    "\t# calculate fbeta, averaged across each class\n",
    "\tbb = beta ** 2\n",
    "\tfbeta_score = backend.mean((1 + bb) * (p * r) / (bb * p + r + backend.epsilon()))\n",
    "\treturn fbeta_score\n",
    "\n",
    "# define cnn model\n",
    "def define_model(in_shape=(128, 128, 3), out_shape=17):\n",
    "\t# load model\n",
    "\tmodel = VGG16(include_top=False, input_shape=in_shape)\n",
    "\t# mark loaded layers as not trainable\n",
    "\tfor layer in model.layers:\n",
    "\t\tlayer.trainable = False\n",
    "\t# allow last vgg block to be trainable\n",
    "\tmodel.get_layer('block5_conv1').trainable = True\n",
    "\tmodel.get_layer('block5_conv2').trainable = True\n",
    "\tmodel.get_layer('block5_conv3').trainable = True\n",
    "\tmodel.get_layer('block5_pool').trainable = True\n",
    "\t# add new classifier layers\n",
    "\tflat1 = Flatten()(model.layers[-1].output)\n",
    "\tclass1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
    "\toutput = Dense(out_shape, activation='sigmoid')(class1)\n",
    "\t# define new model\n",
    "\tmodel = Model(inputs=model.inputs, outputs=output)\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.01, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=[fbeta])\n",
    "\treturn model\n",
    "\n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "\t# plot loss\n",
    "\tpyplot.subplot(211)\n",
    "\tpyplot.title('Cross Entropy Loss')\n",
    "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "\t# plot accuracy\n",
    "\tpyplot.subplot(212)\n",
    "\tpyplot.title('Fbeta')\n",
    "\tpyplot.plot(history.history['fbeta'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_fbeta'], color='orange', label='test')\n",
    "\t# save plot to file\n",
    "\tfilename = sys.argv[0].split('/')[-1]\n",
    "\tpyplot.savefig(filename + '_plot.png')\n",
    "\tpyplot.close()\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# load dataset\n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\t# create data generator\n",
    "\ttrain_datagen = ImageDataGenerator(featurewise_center=True, horizontal_flip=True, vertical_flip=True, rotation_range=90)\n",
    "\ttest_datagen = ImageDataGenerator(featurewise_center=True)\n",
    "\t# specify imagenet mean values for centering\n",
    "\ttrain_datagen.mean = [123.68, 116.779, 103.939]\n",
    "\ttest_datagen.mean = [123.68, 116.779, 103.939]\n",
    "\t# prepare iterators\n",
    "\ttrain_it = train_datagen.flow(trainX, trainY, batch_size=128)\n",
    "\ttest_it = test_datagen.flow(testX, testY, batch_size=128)\n",
    "\t# define model\n",
    "\tmodel = define_model()\n",
    "\t# fit model\n",
    "\thistory = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
    "\t\tvalidation_data=test_it, validation_steps=len(test_it), epochs=50, verbose=0)\n",
    "\t# evaluate model\n",
    "\tloss, fbeta = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
    "\tprint('> loss=%.3f, fbeta=%.3f' % (loss, fbeta))\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(history)\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the final model to file\n",
    "from numpy import load\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "\t# load dataset\n",
    "\tdata = load('planet_data.npz')\n",
    "\tX, y = data['arr_0'], data['arr_1']\n",
    "\treturn X, y\n",
    "\n",
    "# define cnn model\n",
    "def define_model(in_shape=(128, 128, 3), out_shape=17):\n",
    "\t# load model\n",
    "\tmodel = VGG16(include_top=False, input_shape=in_shape)\n",
    "\t# mark loaded layers as not trainable\n",
    "\tfor layer in model.layers:\n",
    "\t\tlayer.trainable = False\n",
    "\t# allow last vgg block to be trainable\n",
    "\tmodel.get_layer('block5_conv1').trainable = True\n",
    "\tmodel.get_layer('block5_conv2').trainable = True\n",
    "\tmodel.get_layer('block5_conv3').trainable = True\n",
    "\tmodel.get_layer('block5_pool').trainable = True\n",
    "\t# add new classifier layers\n",
    "\tflat1 = Flatten()(model.layers[-1].output)\n",
    "\tclass1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
    "\toutput = Dense(out_shape, activation='sigmoid')(class1)\n",
    "\t# define new model\n",
    "\tmodel = Model(inputs=model.inputs, outputs=output)\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.01, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='binary_crossentropy')\n",
    "\treturn model\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# load dataset\n",
    "\tX, y = load_dataset()\n",
    "\t# create data generator\n",
    "\tdatagen = ImageDataGenerator(featurewise_center=True, horizontal_flip=True, vertical_flip=True, rotation_range=90)\n",
    "\t# specify imagenet mean values for centering\n",
    "\tdatagen.mean = [123.68, 116.779, 103.939]\n",
    "\t# prepare iterator\n",
    "\ttrain_it = datagen.flow(X, y, batch_size=128)\n",
    "\t# define model\n",
    "\tmodel = define_model()\n",
    "\t# fit model\n",
    "\tmodel.fit_generator(train_it, steps_per_epoch=len(train_it), epochs=50, verbose=0)\n",
    "\t# save model\n",
    "\tmodel.save('final_model.h5')\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction for a new image\n",
    "from pandas import read_csv\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import load_model\n",
    "\n",
    "# create a mapping of tags to integers given the loaded mapping file\n",
    "def create_tag_mapping(mapping_csv):\n",
    "\t# create a set of all known tags\n",
    "\tlabels = set()\n",
    "\tfor i in range(len(mapping_csv)):\n",
    "\t\t# convert spaced separated tags into an array of tags\n",
    "\t\ttags = mapping_csv['tags'][i].split(' ')\n",
    "\t\t# add tags to the set of known labels\n",
    "\t\tlabels.update(tags)\n",
    "\t# convert set of labels to a list to list\n",
    "\tlabels = list(labels)\n",
    "\t# order set alphabetically\n",
    "\tlabels.sort()\n",
    "\t# dict that maps labels to integers, and the reverse\n",
    "\tlabels_map = {labels[i]:i for i in range(len(labels))}\n",
    "\tinv_labels_map = {i:labels[i] for i in range(len(labels))}\n",
    "\treturn labels_map, inv_labels_map\n",
    "\n",
    "# convert a prediction to tags\n",
    "def prediction_to_tags(inv_mapping, prediction):\n",
    "\t# round probabilities to {0, 1}\n",
    "\tvalues = prediction.round()\n",
    "\t# collect all predicted tags\n",
    "\ttags = [inv_mapping[i] for i in range(len(values)) if values[i] == 1.0]\n",
    "\treturn tags\n",
    "\n",
    "# load and prepare the image\n",
    "def load_image(filename):\n",
    "\t# load the image\n",
    "\timg = load_img(filename, target_size=(128, 128))\n",
    "\t# convert to array\n",
    "\timg = img_to_array(img)\n",
    "\t# reshape into a single sample with 3 channels\n",
    "\timg = img.reshape(1, 128, 128, 3)\n",
    "\t# center pixel data\n",
    "\timg = img.astype('float32')\n",
    "\timg = img - [123.68, 116.779, 103.939]\n",
    "\treturn img\n",
    "\n",
    "# load an image and predict the class\n",
    "def run_example(inv_mapping):\n",
    "\t# load the image\n",
    "\timg = load_image('sample_image_22.jpg')\n",
    "\t# load model\n",
    "\tmodel = load_model('final_model.h5')\n",
    "\t# predict the class\n",
    "\tresult = model.predict(img)\n",
    "\tprint(result[0])\n",
    "\t# map prediction to tags\n",
    "\ttags = prediction_to_tags(inv_mapping, result[0])\n",
    "\tprint(tags)\n",
    "\n",
    "# load the mapping file\n",
    "filename = 'train_v2.csv'\n",
    "mapping_csv = read_csv(filename)\n",
    "# create a mapping of tags to integers\n",
    "_, inv_mapping = create_tag_mapping(mapping_csv)\n",
    "# entry point, run the example\n",
    "run_example(inv_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a YOLOv3 Keras model and save it to file\n",
    "# based on https://github.com/experiencor/keras-yolo3\n",
    "import struct\n",
    "import numpy as np\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Input\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import ZeroPadding2D\n",
    "from keras.layers import UpSampling2D\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "def _conv_block(inp, convs, skip=True):\n",
    "\tx = inp\n",
    "\tcount = 0\n",
    "\tfor conv in convs:\n",
    "\t\tif count == (len(convs) - 2) and skip:\n",
    "\t\t\tskip_connection = x\n",
    "\t\tcount += 1\n",
    "\t\tif conv['stride'] > 1: x = ZeroPadding2D(((1,0),(1,0)))(x) # peculiar padding as darknet prefer left and top\n",
    "\t\tx = Conv2D(conv['filter'],\n",
    "\t\t\t\t   conv['kernel'],\n",
    "\t\t\t\t   strides=conv['stride'],\n",
    "\t\t\t\t   padding='valid' if conv['stride'] > 1 else 'same', # peculiar padding as darknet prefer left and top\n",
    "\t\t\t\t   name='conv_' + str(conv['layer_idx']),\n",
    "\t\t\t\t   use_bias=False if conv['bnorm'] else True)(x)\n",
    "\t\tif conv['bnorm']: x = BatchNormalization(epsilon=0.001, name='bnorm_' + str(conv['layer_idx']))(x)\n",
    "\t\tif conv['leaky']: x = LeakyReLU(alpha=0.1, name='leaky_' + str(conv['layer_idx']))(x)\n",
    "\treturn add([skip_connection, x]) if skip else x\n",
    "\n",
    "def make_yolov3_model():\n",
    "\tinput_image = Input(shape=(None, None, 3))\n",
    "\t# Layer  0 => 4\n",
    "\tx = _conv_block(input_image, [{'filter': 32, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 0},\n",
    "\t\t\t\t\t\t\t\t  {'filter': 64, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 1},\n",
    "\t\t\t\t\t\t\t\t  {'filter': 32, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 2},\n",
    "\t\t\t\t\t\t\t\t  {'filter': 64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 3}])\n",
    "\t# Layer  5 => 8\n",
    "\tx = _conv_block(x, [{'filter': 128, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 5},\n",
    "\t\t\t\t\t\t{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 6},\n",
    "\t\t\t\t\t\t{'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 7}])\n",
    "\t# Layer  9 => 11\n",
    "\tx = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 9},\n",
    "\t\t\t\t\t\t{'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 10}])\n",
    "\t# Layer 12 => 15\n",
    "\tx = _conv_block(x, [{'filter': 256, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 12},\n",
    "\t\t\t\t\t\t{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 13},\n",
    "\t\t\t\t\t\t{'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 14}])\n",
    "\t# Layer 16 => 36\n",
    "\tfor i in range(7):\n",
    "\t\tx = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 16+i*3},\n",
    "\t\t\t\t\t\t\t{'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 17+i*3}])\n",
    "\tskip_36 = x\n",
    "\t# Layer 37 => 40\n",
    "\tx = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 37},\n",
    "\t\t\t\t\t\t{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 38},\n",
    "\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 39}])\n",
    "\t# Layer 41 => 61\n",
    "\tfor i in range(7):\n",
    "\t\tx = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 41+i*3},\n",
    "\t\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 42+i*3}])\n",
    "\tskip_61 = x\n",
    "\t# Layer 62 => 65\n",
    "\tx = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 62},\n",
    "\t\t\t\t\t\t{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 63},\n",
    "\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 64}])\n",
    "\t# Layer 66 => 74\n",
    "\tfor i in range(3):\n",
    "\t\tx = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 66+i*3},\n",
    "\t\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 67+i*3}])\n",
    "\t# Layer 75 => 79\n",
    "\tx = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 75},\n",
    "\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 76},\n",
    "\t\t\t\t\t\t{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 77},\n",
    "\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 78},\n",
    "\t\t\t\t\t\t{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 79}], skip=False)\n",
    "\t# Layer 80 => 82\n",
    "\tyolo_82 = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 80},\n",
    "\t\t\t\t\t\t\t  {'filter':  255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 81}], skip=False)\n",
    "\t# Layer 83 => 86\n",
    "\tx = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 84}], skip=False)\n",
    "\tx = UpSampling2D(2)(x)\n",
    "\tx = concatenate([x, skip_61])\n",
    "\t# Layer 87 => 91\n",
    "\tx = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 87},\n",
    "\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 88},\n",
    "\t\t\t\t\t\t{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 89},\n",
    "\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 90},\n",
    "\t\t\t\t\t\t{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 91}], skip=False)\n",
    "\t# Layer 92 => 94\n",
    "\tyolo_94 = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 92},\n",
    "\t\t\t\t\t\t\t  {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 93}], skip=False)\n",
    "\t# Layer 95 => 98\n",
    "\tx = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True,   'layer_idx': 96}], skip=False)\n",
    "\tx = UpSampling2D(2)(x)\n",
    "\tx = concatenate([x, skip_36])\n",
    "\t# Layer 99 => 106\n",
    "\tyolo_106 = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 99},\n",
    "\t\t\t\t\t\t\t   {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 100},\n",
    "\t\t\t\t\t\t\t   {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 101},\n",
    "\t\t\t\t\t\t\t   {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 102},\n",
    "\t\t\t\t\t\t\t   {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 103},\n",
    "\t\t\t\t\t\t\t   {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 104},\n",
    "\t\t\t\t\t\t\t   {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 105}], skip=False)\n",
    "\tmodel = Model(input_image, [yolo_82, yolo_94, yolo_106])\n",
    "\treturn model\n",
    "\n",
    "class WeightReader:\n",
    "\tdef __init__(self, weight_file):\n",
    "\t\twith open(weight_file, 'rb') as w_f:\n",
    "\t\t\tmajor,\t= struct.unpack('i', w_f.read(4))\n",
    "\t\t\tminor,\t= struct.unpack('i', w_f.read(4))\n",
    "\t\t\trevision, = struct.unpack('i', w_f.read(4))\n",
    "\t\t\tif (major*10 + minor) >= 2 and major < 1000 and minor < 1000:\n",
    "\t\t\t\tw_f.read(8)\n",
    "\t\t\telse:\n",
    "\t\t\t\tw_f.read(4)\n",
    "\t\t\ttranspose = (major > 1000) or (minor > 1000)\n",
    "\t\t\tbinary = w_f.read()\n",
    "\t\tself.offset = 0\n",
    "\t\tself.all_weights = np.frombuffer(binary, dtype='float32')\n",
    "\n",
    "\tdef read_bytes(self, size):\n",
    "\t\tself.offset = self.offset + size\n",
    "\t\treturn self.all_weights[self.offset-size:self.offset]\n",
    "\n",
    "\tdef load_weights(self, model):\n",
    "\t\tfor i in range(106):\n",
    "\t\t\ttry:\n",
    "\t\t\t\tconv_layer = model.get_layer('conv_' + str(i))\n",
    "\t\t\t\tprint(\"loading weights of convolution #\" + str(i))\n",
    "\t\t\t\tif i not in [81, 93, 105]:\n",
    "\t\t\t\t\tnorm_layer = model.get_layer('bnorm_' + str(i))\n",
    "\t\t\t\t\tsize = np.prod(norm_layer.get_weights()[0].shape)\n",
    "\t\t\t\t\tbeta  = self.read_bytes(size) # bias\n",
    "\t\t\t\t\tgamma = self.read_bytes(size) # scale\n",
    "\t\t\t\t\tmean  = self.read_bytes(size) # mean\n",
    "\t\t\t\t\tvar   = self.read_bytes(size) # variance\n",
    "\t\t\t\t\tweights = norm_layer.set_weights([gamma, beta, mean, var])\n",
    "\t\t\t\tif len(conv_layer.get_weights()) > 1:\n",
    "\t\t\t\t\tbias   = self.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\n",
    "\t\t\t\t\tkernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "\t\t\t\t\tkernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "\t\t\t\t\tkernel = kernel.transpose([2,3,1,0])\n",
    "\t\t\t\t\tconv_layer.set_weights([kernel, bias])\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tkernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "\t\t\t\t\tkernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "\t\t\t\t\tkernel = kernel.transpose([2,3,1,0])\n",
    "\t\t\t\t\tconv_layer.set_weights([kernel])\n",
    "\t\t\texcept ValueError:\n",
    "\t\t\t\tprint(\"no convolution #\" + str(i))\n",
    "\n",
    "\tdef reset(self):\n",
    "\t\tself.offset = 0\n",
    "\n",
    "# define the model\n",
    "model = make_yolov3_model()\n",
    "# load the model weights\n",
    "weight_reader = WeightReader('yolov3.weights')\n",
    "# set the model weights into the model\n",
    "weight_reader.load_weights(model)\n",
    "# save the model to file\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load yolov3 model and perform object detection\n",
    "# based on https://github.com/experiencor/keras-yolo3\n",
    "from numpy import expand_dims\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "# load and prepare an image\n",
    "def load_image_pixels(filename, shape):\n",
    "    # load the image to get its shape\n",
    "    image = load_img(filename)\n",
    "    width, height = image.size\n",
    "    # load the image with the required size\n",
    "    image = load_img(filename, target_size=shape)\n",
    "    # convert to numpy array\n",
    "    image = img_to_array(image)\n",
    "    # scale pixel values to [0, 1]\n",
    "    image = image.astype('float32')\n",
    "    image /= 255.0\n",
    "    # add a dimension so that we have one sample\n",
    "    image = expand_dims(image, 0)\n",
    "    return image, width, height\n",
    "\n",
    "# load yolov3 model\n",
    "model = load_model('model.h5')\n",
    "# define the expected input shape for the model\n",
    "input_w, input_h = 416, 416\n",
    "# define our new photo\n",
    "photo_filename = 'zebra.jpg'\n",
    "# load and prepare image\n",
    "image, image_w, image_h = load_image_pixels(photo_filename, (input_w, input_h))\n",
    "# make prediction\n",
    "yhat = model.predict(image)\n",
    "# summarize the shape of the list of arrays\n",
    "print([a.shape for a in yhat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load yolov3 model and perform object detection\n",
    "# based on https://github.com/experiencor/keras-yolo3\n",
    "import numpy as np\n",
    "from numpy import expand_dims\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "class BoundBox:\n",
    "\tdef __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n",
    "\t\tself.xmin = xmin\n",
    "\t\tself.ymin = ymin\n",
    "\t\tself.xmax = xmax\n",
    "\t\tself.ymax = ymax\n",
    "\t\tself.objness = objness\n",
    "\t\tself.classes = classes\n",
    "\t\tself.label = -1\n",
    "\t\tself.score = -1\n",
    "\n",
    "\tdef get_label(self):\n",
    "\t\tif self.label == -1:\n",
    "\t\t\tself.label = np.argmax(self.classes)\n",
    "\n",
    "\t\treturn self.label\n",
    "\n",
    "\tdef get_score(self):\n",
    "\t\tif self.score == -1:\n",
    "\t\t\tself.score = self.classes[self.get_label()]\n",
    "\n",
    "\t\treturn self.score\n",
    "\n",
    "def _sigmoid(x):\n",
    "\treturn 1. / (1. + np.exp(-x))\n",
    "\n",
    "def decode_netout(netout, anchors, obj_thresh, net_h, net_w):\n",
    "\tgrid_h, grid_w = netout.shape[:2]\n",
    "\tnb_box = 3\n",
    "\tnetout = netout.reshape((grid_h, grid_w, nb_box, -1))\n",
    "\tnb_class = netout.shape[-1] - 5\n",
    "\tboxes = []\n",
    "\tnetout[..., :2]  = _sigmoid(netout[..., :2])\n",
    "\tnetout[..., 4:]  = _sigmoid(netout[..., 4:])\n",
    "\tnetout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n",
    "\tnetout[..., 5:] *= netout[..., 5:] > obj_thresh\n",
    "\n",
    "\tfor i in range(grid_h*grid_w):\n",
    "\t\trow = i / grid_w\n",
    "\t\tcol = i % grid_w\n",
    "\t\tfor b in range(nb_box):\n",
    "\t\t\t# 4th element is objectness score\n",
    "\t\t\tobjectness = netout[int(row)][int(col)][b][4]\n",
    "\t\t\tif(objectness.all() <= obj_thresh): continue\n",
    "\t\t\t# first 4 elements are x, y, w, and h\n",
    "\t\t\tx, y, w, h = netout[int(row)][int(col)][b][:4]\n",
    "\t\t\tx = (col + x) / grid_w # center position, unit: image width\n",
    "\t\t\ty = (row + y) / grid_h # center position, unit: image height\n",
    "\t\t\tw = anchors[2 * b + 0] * np.exp(w) / net_w # unit: image width\n",
    "\t\t\th = anchors[2 * b + 1] * np.exp(h) / net_h # unit: image height\n",
    "\t\t\t# last elements are class probabilities\n",
    "\t\t\tclasses = netout[int(row)][col][b][5:]\n",
    "\t\t\tbox = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n",
    "\t\t\tboxes.append(box)\n",
    "\treturn boxes\n",
    "\n",
    "def correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n",
    "\tnew_w, new_h = net_w, net_h\n",
    "\tfor i in range(len(boxes)):\n",
    "\t\tx_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n",
    "\t\ty_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n",
    "\t\tboxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
    "\t\tboxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
    "\t\tboxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
    "\t\tboxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)\n",
    "\n",
    "def _interval_overlap(interval_a, interval_b):\n",
    "\tx1, x2 = interval_a\n",
    "\tx3, x4 = interval_b\n",
    "\tif x3 < x1:\n",
    "\t\tif x4 < x1:\n",
    "\t\t\treturn 0\n",
    "\t\telse:\n",
    "\t\t\treturn min(x2,x4) - x1\n",
    "\telse:\n",
    "\t\tif x2 < x3:\n",
    "\t\t\t return 0\n",
    "\t\telse:\n",
    "\t\t\treturn min(x2,x4) - x3\n",
    "\n",
    "def bbox_iou(box1, box2):\n",
    "\tintersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
    "\tintersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
    "\tintersect = intersect_w * intersect_h\n",
    "\tw1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
    "\tw2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
    "\tunion = w1*h1 + w2*h2 - intersect\n",
    "\treturn float(intersect) / union\n",
    "\n",
    "def do_nms(boxes, nms_thresh):\n",
    "\tif len(boxes) > 0:\n",
    "\t\tnb_class = len(boxes[0].classes)\n",
    "\telse:\n",
    "\t\treturn\n",
    "\tfor c in range(nb_class):\n",
    "\t\tsorted_indices = np.argsort([-box.classes[c] for box in boxes])\n",
    "\t\tfor i in range(len(sorted_indices)):\n",
    "\t\t\tindex_i = sorted_indices[i]\n",
    "\t\t\tif boxes[index_i].classes[c] == 0: continue\n",
    "\t\t\tfor j in range(i+1, len(sorted_indices)):\n",
    "\t\t\t\tindex_j = sorted_indices[j]\n",
    "\t\t\t\tif bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n",
    "\t\t\t\t\tboxes[index_j].classes[c] = 0\n",
    "\n",
    "# load and prepare an image\n",
    "def load_image_pixels(filename, shape):\n",
    "\t# load the image to get its shape\n",
    "\timage = load_img(filename)\n",
    "\twidth, height = image.size\n",
    "\t# load the image with the required size\n",
    "\timage = load_img(filename, target_size=shape)\n",
    "\t# convert to numpy array\n",
    "\timage = img_to_array(image)\n",
    "\t# scale pixel values to [0, 1]\n",
    "\timage = image.astype('float32')\n",
    "\timage /= 255.0\n",
    "\t# add a dimension so that we have one sample\n",
    "\timage = expand_dims(image, 0)\n",
    "\treturn image, width, height\n",
    "\n",
    "# get all of the results above a threshold\n",
    "def get_boxes(boxes, labels, thresh):\n",
    "\tv_boxes, v_labels, v_scores = list(), list(), list()\n",
    "\t# enumerate all boxes\n",
    "\tfor box in boxes:\n",
    "\t\t# enumerate all possible labels\n",
    "\t\tfor i in range(len(labels)):\n",
    "\t\t\t# check if the threshold for this label is high enough\n",
    "\t\t\tif box.classes[i] > thresh:\n",
    "\t\t\t\tv_boxes.append(box)\n",
    "\t\t\t\tv_labels.append(labels[i])\n",
    "\t\t\t\tv_scores.append(box.classes[i]*100)\n",
    "\t\t\t\t# don't break, many labels may trigger for one box\n",
    "\treturn v_boxes, v_labels, v_scores\n",
    "\n",
    "# draw all results\n",
    "def draw_boxes(filename, v_boxes, v_labels, v_scores):\n",
    "\t# load the image\n",
    "\tdata = pyplot.imread(filename)\n",
    "\t# plot the image\n",
    "\tpyplot.imshow(data)\n",
    "\t# get the context for drawing boxes\n",
    "\tax = pyplot.gca()\n",
    "\t# plot each box\n",
    "\tfor i in range(len(v_boxes)):\n",
    "\t\tbox = v_boxes[i]\n",
    "\t\t# get coordinates\n",
    "\t\ty1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax\n",
    "\t\t# calculate width and height of the box\n",
    "\t\twidth, height = x2 - x1, y2 - y1\n",
    "\t\t# create the shape\n",
    "\t\trect = Rectangle((x1, y1), width, height, fill=False, color='white')\n",
    "\t\t# draw the box\n",
    "\t\tax.add_patch(rect)\n",
    "\t\t# draw text and score in top left corner\n",
    "\t\tlabel = \"%s (%.3f)\" % (v_labels[i], v_scores[i])\n",
    "\t\tpyplot.text(x1, y1, label, color='white')\n",
    "\t# show the plot\n",
    "\tpyplot.show()\n",
    "\n",
    "# load yolov3 model\n",
    "model = load_model('model.h5')\n",
    "# define the expected input shape for the model\n",
    "input_w, input_h = 416, 416\n",
    "# define our new photo\n",
    "photo_filename = 'zebra.jpg'\n",
    "# load and prepare image\n",
    "image, image_w, image_h = load_image_pixels(photo_filename, (input_w, input_h))\n",
    "# make prediction\n",
    "yhat = model.predict(image)\n",
    "# summarize the shape of the list of arrays\n",
    "print([a.shape for a in yhat])\n",
    "# define the anchors\n",
    "anchors = [[116,90, 156,198, 373,326], [30,61, 62,45, 59,119], [10,13, 16,30, 33,23]]\n",
    "# define the probability threshold for detected objects\n",
    "class_threshold = 0.6\n",
    "boxes = list()\n",
    "for i in range(len(yhat)):\n",
    "\t# decode the output of the network\n",
    "\tboxes += decode_netout(yhat[i][0], anchors[i], class_threshold, input_h, input_w)\n",
    "# correct the sizes of the bounding boxes for the shape of the image\n",
    "correct_yolo_boxes(boxes, image_h, image_w, input_h, input_w)\n",
    "# suppress non-maximal boxes\n",
    "do_nms(boxes, 0.5)\n",
    "# define the labels\n",
    "labels = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\",\n",
    "\t\"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\",\n",
    "\t\"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\",\n",
    "\t\"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\",\n",
    "\t\"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\",\n",
    "\t\"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\",\n",
    "\t\"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\",\n",
    "\t\"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\",\n",
    "\t\"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\",\n",
    "\t\"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
    "# get the details of the detected objects\n",
    "v_boxes, v_labels, v_scores = get_boxes(boxes, labels, class_threshold)\n",
    "# summarize what we found\n",
    "for i in range(len(v_boxes)):\n",
    "\tprint(v_labels[i], v_scores[i])\n",
    "# draw what we found\n",
    "draw_boxes(photo_filename, v_boxes, v_labels, v_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Localize objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of inference with a pre-trained coco model\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from mrcnn.config import Config\n",
    "from mrcnn.model import MaskRCNN\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# draw an image with detected objects\n",
    "def draw_image_with_boxes(filename, boxes_list):\n",
    "     # load the image\n",
    "     data = pyplot.imread(filename)\n",
    "     # plot the image\n",
    "     pyplot.imshow(data)\n",
    "     # get the context for drawing boxes\n",
    "     ax = pyplot.gca()\n",
    "     # plot each box\n",
    "     for box in boxes_list:\n",
    "          # get coordinates\n",
    "          y1, x1, y2, x2 = box\n",
    "          # calculate width and height of the box\n",
    "          width, height = x2 - x1, y2 - y1\n",
    "          # create the shape\n",
    "          rect = Rectangle((x1, y1), width, height, fill=False, color='red')\n",
    "          # draw the box\n",
    "          ax.add_patch(rect)\n",
    "     # show the plot\n",
    "     pyplot.show()\n",
    "\n",
    "# define the test configuration\n",
    "class TestConfig(Config):\n",
    "     NAME = \"test\"\n",
    "     GPU_COUNT = 1\n",
    "     IMAGES_PER_GPU = 1\n",
    "     NUM_CLASSES = 1 + 80\n",
    "\n",
    "# define the model\n",
    "rcnn = MaskRCNN(mode='inference', model_dir='./', config=TestConfig())\n",
    "# load coco model weights\n",
    "rcnn.load_weights('mask_rcnn_coco.h5', by_name=True)\n",
    "# load photograph\n",
    "img = load_img('elephant.jpg')\n",
    "img = img_to_array(img)\n",
    "# make prediction\n",
    "results = rcnn.detect([img], verbose=0)\n",
    "# visualize the results\n",
    "draw_image_with_boxes('elephant.jpg', results[0]['rois'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of inference with a pre-trained coco model\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from mrcnn.visualize import display_instances\n",
    "from mrcnn.config import Config\n",
    "from mrcnn.model import MaskRCNN\n",
    "\n",
    "# define 81 classes that the coco model knowns about\n",
    "class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
    "               'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
    "               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
    "               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
    "               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
    "               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
    "               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
    "               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
    "               'teddy bear', 'hair drier', 'toothbrush']\n",
    "\n",
    "# define the test configuration\n",
    "class TestConfig(Config):\n",
    "     NAME = \"test\"\n",
    "     GPU_COUNT = 1\n",
    "     IMAGES_PER_GPU = 1\n",
    "     NUM_CLASSES = 1 + 80\n",
    "\n",
    "# define the model\n",
    "rcnn = MaskRCNN(mode='inference', model_dir='./', config=TestConfig())\n",
    "# load coco model weights\n",
    "rcnn.load_weights('mask_rcnn_coco.h5', by_name=True)\n",
    "# load photograph\n",
    "img = load_img('elephant.jpg')\n",
    "img = img_to_array(img)\n",
    "# make prediction\n",
    "results = rcnn.detect([img], verbose=0)\n",
    "# get dictionary for first prediction\n",
    "r = results[0]\n",
    "# show photo with bounding boxes, masks, class labels and scores\n",
    "display_instances(img, r['rois'], r['masks'], r['class_ids'], class_names, r['scores'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of extracting bounding boxes from an annotation file\n",
    "from xml.etree import ElementTree\n",
    "\n",
    "# function to extract bounding boxes from an annotation file\n",
    "def extract_boxes(filename):\n",
    "\t# load and parse the file\n",
    "\ttree = ElementTree.parse(filename)\n",
    "\t# get the root of the document\n",
    "\troot = tree.getroot()\n",
    "\t# extract each bounding box\n",
    "\tboxes = list()\n",
    "\tfor box in root.findall('.//bndbox'):\n",
    "\t\txmin = int(box.find('xmin').text)\n",
    "\t\tymin = int(box.find('ymin').text)\n",
    "\t\txmax = int(box.find('xmax').text)\n",
    "\t\tymax = int(box.find('ymax').text)\n",
    "\t\tcoors = [xmin, ymin, xmax, ymax]\n",
    "\t\tboxes.append(coors)\n",
    "\t# extract image dimensions\n",
    "\twidth = int(root.find('.//size/width').text)\n",
    "\theight = int(root.find('.//size/height').text)\n",
    "\treturn boxes, width, height\n",
    "\n",
    "# extract details form annotation file\n",
    "boxes, w, h = extract_boxes('kangaroo/annots/00001.xml')\n",
    "# summarize extracted details\n",
    "print(boxes, w, h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test set\n",
    "from os import listdir\n",
    "from xml.etree import ElementTree\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "from mrcnn.utils import Dataset\n",
    "\n",
    "# class that defines and loads the kangaroo dataset\n",
    "class KangarooDataset(Dataset):\n",
    "\t# load the dataset definitions\n",
    "\tdef load_dataset(self, dataset_dir, is_train=True):\n",
    "\t\t# define one class\n",
    "\t\tself.add_class(\"dataset\", 1, \"kangaroo\")\n",
    "\t\t# define data locations\n",
    "\t\timages_dir = dataset_dir + '/images/'\n",
    "\t\tannotations_dir = dataset_dir + '/annots/'\n",
    "\t\t# find all images\n",
    "\t\tfor filename in listdir(images_dir):\n",
    "\t\t\t# extract image id\n",
    "\t\t\timage_id = filename[:-4]\n",
    "\t\t\t# skip bad images\n",
    "\t\t\tif image_id in ['00090']:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t# skip all images after 150 if we are building the train set\n",
    "\t\t\tif is_train and int(image_id) >= 150:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t# skip all images before 150 if we are building the test/val set\n",
    "\t\t\tif not is_train and int(image_id) < 150:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\timg_path = images_dir + filename\n",
    "\t\t\tann_path = annotations_dir + image_id + '.xml'\n",
    "\t\t\t# add to dataset\n",
    "\t\t\tself.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path)\n",
    "\n",
    "\t# extract bounding boxes from an annotation file\n",
    "\tdef extract_boxes(self, filename):\n",
    "\t\t# load and parse the file\n",
    "\t\ttree = ElementTree.parse(filename)\n",
    "\t\t# get the root of the document\n",
    "\t\troot = tree.getroot()\n",
    "\t\t# extract each bounding box\n",
    "\t\tboxes = list()\n",
    "\t\tfor box in root.findall('.//bndbox'):\n",
    "\t\t\txmin = int(box.find('xmin').text)\n",
    "\t\t\tymin = int(box.find('ymin').text)\n",
    "\t\t\txmax = int(box.find('xmax').text)\n",
    "\t\t\tymax = int(box.find('ymax').text)\n",
    "\t\t\tcoors = [xmin, ymin, xmax, ymax]\n",
    "\t\t\tboxes.append(coors)\n",
    "\t\t# extract image dimensions\n",
    "\t\twidth = int(root.find('.//size/width').text)\n",
    "\t\theight = int(root.find('.//size/height').text)\n",
    "\t\treturn boxes, width, height\n",
    "\n",
    "\t# load the masks for an image\n",
    "\tdef load_mask(self, image_id):\n",
    "\t\t# get details of image\n",
    "\t\tinfo = self.image_info[image_id]\n",
    "\t\t# define box file location\n",
    "\t\tpath = info['annotation']\n",
    "\t\t# load XML\n",
    "\t\tboxes, w, h = self.extract_boxes(path)\n",
    "\t\t# create one array for all masks, each on a different channel\n",
    "\t\tmasks = zeros([h, w, len(boxes)], dtype='uint8')\n",
    "\t\t# create masks\n",
    "\t\tclass_ids = list()\n",
    "\t\tfor i in range(len(boxes)):\n",
    "\t\t\tbox = boxes[i]\n",
    "\t\t\trow_s, row_e = box[1], box[3]\n",
    "\t\t\tcol_s, col_e = box[0], box[2]\n",
    "\t\t\tmasks[row_s:row_e, col_s:col_e, i] = 1\n",
    "\t\t\tclass_ids.append(self.class_names.index('kangaroo'))\n",
    "\t\treturn masks, asarray(class_ids, dtype='int32')\n",
    "\n",
    "\t# load an image reference\n",
    "\tdef image_reference(self, image_id):\n",
    "\t\tinfo = self.image_info[image_id]\n",
    "\t\treturn info['path']\n",
    "\n",
    "# train set\n",
    "train_set = KangarooDataset()\n",
    "train_set.load_dataset('kangaroo', is_train=True)\n",
    "train_set.prepare()\n",
    "print('Train: %d' % len(train_set.image_ids))\n",
    "\n",
    "# test/val set\n",
    "test_set = KangarooDataset()\n",
    "test_set.load_dataset('kangaroo', is_train=False)\n",
    "test_set.prepare()\n",
    "print('Test: %d' % len(test_set.image_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot photo with mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot one photograph and mask\n",
    "from os import listdir\n",
    "from xml.etree import ElementTree\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "from mrcnn.utils import Dataset\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# class that defines and loads the kangaroo dataset\n",
    "class KangarooDataset(Dataset):\n",
    "\t# load the dataset definitions\n",
    "\tdef load_dataset(self, dataset_dir, is_train=True):\n",
    "\t\t# define one class\n",
    "\t\tself.add_class(\"dataset\", 1, \"kangaroo\")\n",
    "\t\t# define data locations\n",
    "\t\timages_dir = dataset_dir + '/images/'\n",
    "\t\tannotations_dir = dataset_dir + '/annots/'\n",
    "\t\t# find all images\n",
    "\t\tfor filename in listdir(images_dir):\n",
    "\t\t\t# extract image id\n",
    "\t\t\timage_id = filename[:-4]\n",
    "\t\t\t# skip bad images\n",
    "\t\t\tif image_id in ['00090']:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t# skip all images after 150 if we are building the train set\n",
    "\t\t\tif is_train and int(image_id) >= 150:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t# skip all images before 150 if we are building the test/val set\n",
    "\t\t\tif not is_train and int(image_id) < 150:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\timg_path = images_dir + filename\n",
    "\t\t\tann_path = annotations_dir + image_id + '.xml'\n",
    "\t\t\t# add to dataset\n",
    "\t\t\tself.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path)\n",
    "\n",
    "\t# extract bounding boxes from an annotation file\n",
    "\tdef extract_boxes(self, filename):\n",
    "\t\t# load and parse the file\n",
    "\t\ttree = ElementTree.parse(filename)\n",
    "\t\t# get the root of the document\n",
    "\t\troot = tree.getroot()\n",
    "\t\t# extract each bounding box\n",
    "\t\tboxes = list()\n",
    "\t\tfor box in root.findall('.//bndbox'):\n",
    "\t\t\txmin = int(box.find('xmin').text)\n",
    "\t\t\tymin = int(box.find('ymin').text)\n",
    "\t\t\txmax = int(box.find('xmax').text)\n",
    "\t\t\tymax = int(box.find('ymax').text)\n",
    "\t\t\tcoors = [xmin, ymin, xmax, ymax]\n",
    "\t\t\tboxes.append(coors)\n",
    "\t\t# extract image dimensions\n",
    "\t\twidth = int(root.find('.//size/width').text)\n",
    "\t\theight = int(root.find('.//size/height').text)\n",
    "\t\treturn boxes, width, height\n",
    "\n",
    "\t# load the masks for an image\n",
    "\tdef load_mask(self, image_id):\n",
    "\t\t# get details of image\n",
    "\t\tinfo = self.image_info[image_id]\n",
    "\t\t# define box file location\n",
    "\t\tpath = info['annotation']\n",
    "\t\t# load XML\n",
    "\t\tboxes, w, h = self.extract_boxes(path)\n",
    "\t\t# create one array for all masks, each on a different channel\n",
    "\t\tmasks = zeros([h, w, len(boxes)], dtype='uint8')\n",
    "\t\t# create masks\n",
    "\t\tclass_ids = list()\n",
    "\t\tfor i in range(len(boxes)):\n",
    "\t\t\tbox = boxes[i]\n",
    "\t\t\trow_s, row_e = box[1], box[3]\n",
    "\t\t\tcol_s, col_e = box[0], box[2]\n",
    "\t\t\tmasks[row_s:row_e, col_s:col_e, i] = 1\n",
    "\t\t\tclass_ids.append(self.class_names.index('kangaroo'))\n",
    "\t\treturn masks, asarray(class_ids, dtype='int32')\n",
    "\n",
    "\t# load an image reference\n",
    "\tdef image_reference(self, image_id):\n",
    "\t\tinfo = self.image_info[image_id]\n",
    "\t\treturn info['path']\n",
    "\n",
    "# train set\n",
    "train_set = KangarooDataset()\n",
    "train_set.load_dataset('kangaroo', is_train=True)\n",
    "train_set.prepare()\n",
    "# load an image\n",
    "image_id = 0\n",
    "image = train_set.load_image(image_id)\n",
    "print(image.shape)\n",
    "# load image mask\n",
    "mask, class_ids = train_set.load_mask(image_id)\n",
    "print(mask.shape)\n",
    "# plot image\n",
    "pyplot.imshow(image)\n",
    "# plot mask\n",
    "pyplot.imshow(mask[:, :, 0], cmap='gray', alpha=0.5)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot multiple photos with mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a number of photographs and their mask\n",
    "from os import listdir\n",
    "from xml.etree import ElementTree\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "from mrcnn.utils import Dataset\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# class that defines and loads the kangaroo dataset\n",
    "class KangarooDataset(Dataset):\n",
    "\t# load the dataset definitions\n",
    "\tdef load_dataset(self, dataset_dir, is_train=True):\n",
    "\t\t# define one class\n",
    "\t\tself.add_class(\"dataset\", 1, \"kangaroo\")\n",
    "\t\t# define data locations\n",
    "\t\timages_dir = dataset_dir + '/images/'\n",
    "\t\tannotations_dir = dataset_dir + '/annots/'\n",
    "\t\t# find all images\n",
    "\t\tfor filename in listdir(images_dir):\n",
    "\t\t\t# extract image id\n",
    "\t\t\timage_id = filename[:-4]\n",
    "\t\t\t# skip bad images\n",
    "\t\t\tif image_id in ['00090']:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t# skip all images after 150 if we are building the train set\n",
    "\t\t\tif is_train and int(image_id) >= 150:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t# skip all images before 150 if we are building the test/val set\n",
    "\t\t\tif not is_train and int(image_id) < 150:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\timg_path = images_dir + filename\n",
    "\t\t\tann_path = annotations_dir + image_id + '.xml'\n",
    "\t\t\t# add to dataset\n",
    "\t\t\tself.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path)\n",
    "\n",
    "\t# extract bounding boxes from an annotation file\n",
    "\tdef extract_boxes(self, filename):\n",
    "\t\t# load and parse the file\n",
    "\t\ttree = ElementTree.parse(filename)\n",
    "\t\t# get the root of the document\n",
    "\t\troot = tree.getroot()\n",
    "\t\t# extract each bounding box\n",
    "\t\tboxes = list()\n",
    "\t\tfor box in root.findall('.//bndbox'):\n",
    "\t\t\txmin = int(box.find('xmin').text)\n",
    "\t\t\tymin = int(box.find('ymin').text)\n",
    "\t\t\txmax = int(box.find('xmax').text)\n",
    "\t\t\tymax = int(box.find('ymax').text)\n",
    "\t\t\tcoors = [xmin, ymin, xmax, ymax]\n",
    "\t\t\tboxes.append(coors)\n",
    "\t\t# extract image dimensions\n",
    "\t\twidth = int(root.find('.//size/width').text)\n",
    "\t\theight = int(root.find('.//size/height').text)\n",
    "\t\treturn boxes, width, height\n",
    "\n",
    "\t# load the masks for an image\n",
    "\tdef load_mask(self, image_id):\n",
    "\t\t# get details of image\n",
    "\t\tinfo = self.image_info[image_id]\n",
    "\t\t# define box file location\n",
    "\t\tpath = info['annotation']\n",
    "\t\t# load XML\n",
    "\t\tboxes, w, h = self.extract_boxes(path)\n",
    "\t\t# create one array for all masks, each on a different channel\n",
    "\t\tmasks = zeros([h, w, len(boxes)], dtype='uint8')\n",
    "\t\t# create masks\n",
    "\t\tclass_ids = list()\n",
    "\t\tfor i in range(len(boxes)):\n",
    "\t\t\tbox = boxes[i]\n",
    "\t\t\trow_s, row_e = box[1], box[3]\n",
    "\t\t\tcol_s, col_e = box[0], box[2]\n",
    "\t\t\tmasks[row_s:row_e, col_s:col_e, i] = 1\n",
    "\t\t\tclass_ids.append(self.class_names.index('kangaroo'))\n",
    "\t\treturn masks, asarray(class_ids, dtype='int32')\n",
    "\n",
    "\t# load an image reference\n",
    "\tdef image_reference(self, image_id):\n",
    "\t\tinfo = self.image_info[image_id]\n",
    "\t\treturn info['path']\n",
    "\n",
    "# train set\n",
    "train_set = KangarooDataset()\n",
    "train_set.load_dataset('kangaroo', is_train=True)\n",
    "train_set.prepare()\n",
    "# load an image\n",
    "image_id = 0\n",
    "image = train_set.load_image(image_id)\n",
    "print(image.shape)\n",
    "# load image mask\n",
    "mask, class_ids = train_set.load_mask(image_id)\n",
    "print(mask.shape)\n",
    "# plot first few images\n",
    "for i in range(9):\n",
    "\t# define subplot\n",
    "\tpyplot.subplot(330 + 1 + i)\n",
    "\t# turn off axis labels\n",
    "\tpyplot.axis('off')\n",
    "\t# plot raw pixel data\n",
    "\timage = train_set.load_image(i)\n",
    "\tpyplot.imshow(image)\n",
    "\t# plot all masks\n",
    "\tmask, _ = train_set.load_mask(i)\n",
    "\tfor j in range(mask.shape[2]):\n",
    "\t\tpyplot.imshow(mask[:, :, j], cmap='gray', alpha=0.3)\n",
    "# show the figure\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize image paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize the paths to images in the dataset\n",
    "from os import listdir\n",
    "from xml.etree import ElementTree\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "from mrcnn.utils import Dataset\n",
    "\n",
    "# class that defines and loads the kangaroo dataset\n",
    "class KangarooDataset(Dataset):\n",
    "\t# load the dataset definitions\n",
    "\tdef load_dataset(self, dataset_dir, is_train=True):\n",
    "\t\t# define one class\n",
    "\t\tself.add_class(\"dataset\", 1, \"kangaroo\")\n",
    "\t\t# define data locations\n",
    "\t\timages_dir = dataset_dir + '/images/'\n",
    "\t\tannotations_dir = dataset_dir + '/annots/'\n",
    "\t\t# find all images\n",
    "\t\tfor filename in listdir(images_dir):\n",
    "\t\t\t# extract image id\n",
    "\t\t\timage_id = filename[:-4]\n",
    "\t\t\t# skip bad images\n",
    "\t\t\tif image_id in ['00090']:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t# skip all images after 150 if we are building the train set\n",
    "\t\t\tif is_train and int(image_id) >= 150:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t# skip all images before 150 if we are building the test/val set\n",
    "\t\t\tif not is_train and int(image_id) < 150:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\timg_path = images_dir + filename\n",
    "\t\t\tann_path = annotations_dir + image_id + '.xml'\n",
    "\t\t\t# add to dataset\n",
    "\t\t\tself.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path)\n",
    "\n",
    "\t# extract bounding boxes from an annotation file\n",
    "\tdef extract_boxes(self, filename):\n",
    "\t\t# load and parse the file\n",
    "\t\ttree = ElementTree.parse(filename)\n",
    "\t\t# get the root of the document\n",
    "\t\troot = tree.getroot()\n",
    "\t\t# extract each bounding box\n",
    "\t\tboxes = list()\n",
    "\t\tfor box in root.findall('.//bndbox'):\n",
    "\t\t\txmin = int(box.find('xmin').text)\n",
    "\t\t\tymin = int(box.find('ymin').text)\n",
    "\t\t\txmax = int(box.find('xmax').text)\n",
    "\t\t\tymax = int(box.find('ymax').text)\n",
    "\t\t\tcoors = [xmin, ymin, xmax, ymax]\n",
    "\t\t\tboxes.append(coors)\n",
    "\t\t# extract image dimensions\n",
    "\t\twidth = int(root.find('.//size/width').text)\n",
    "\t\theight = int(root.find('.//size/height').text)\n",
    "\t\treturn boxes, width, height\n",
    "\n",
    "\t# load the masks for an image\n",
    "\tdef load_mask(self, image_id):\n",
    "\t\t# get details of image\n",
    "\t\tinfo = self.image_info[image_id]\n",
    "\t\t# define box file location\n",
    "\t\tpath = info['annotation']\n",
    "\t\t# load XML\n",
    "\t\tboxes, w, h = self.extract_boxes(path)\n",
    "\t\t# create one array for all masks, each on a different channel\n",
    "\t\tmasks = zeros([h, w, len(boxes)], dtype='uint8')\n",
    "\t\t# create masks\n",
    "\t\tclass_ids = list()\n",
    "\t\tfor i in range(len(boxes)):\n",
    "\t\t\tbox = boxes[i]\n",
    "\t\t\trow_s, row_e = box[1], box[3]\n",
    "\t\t\tcol_s, col_e = box[0], box[2]\n",
    "\t\t\tmasks[row_s:row_e, col_s:col_e, i] = 1\n",
    "\t\t\tclass_ids.append(self.class_names.index('kangaroo'))\n",
    "\t\treturn masks, asarray(class_ids, dtype='int32')\n",
    "\n",
    "\t# load an image reference\n",
    "\tdef image_reference(self, image_id):\n",
    "\t\tinfo = self.image_info[image_id]\n",
    "\t\treturn info['path']\n",
    "\n",
    "# train set\n",
    "train_set = KangarooDataset()\n",
    "train_set.load_dataset('kangaroo', is_train=True)\n",
    "train_set.prepare()\n",
    "# load an image\n",
    "image_id = 0\n",
    "image = train_set.load_image(image_id)\n",
    "print(image.shape)\n",
    "# load image mask\n",
    "mask, class_ids = train_set.load_mask(image_id)\n",
    "print(mask.shape)\n",
    "# enumerate all images in the dataset\n",
    "for image_id in train_set.image_ids:\n",
    "\t# load image info\n",
    "\tinfo = train_set.image_info[image_id]\n",
    "\t# display on the console\n",
    "\tprint(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot photo mask builtin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display image with masks and bounding boxes\n",
    "from os import listdir\n",
    "from xml.etree import ElementTree\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "from mrcnn.utils import Dataset\n",
    "from mrcnn.visualize import display_instances\n",
    "from mrcnn.utils import extract_bboxes\n",
    "\n",
    "# class that defines and loads the kangaroo dataset\n",
    "class KangarooDataset(Dataset):\n",
    "\t# load the dataset definitions\n",
    "\tdef load_dataset(self, dataset_dir, is_train=True):\n",
    "\t\t# define one class\n",
    "\t\tself.add_class(\"dataset\", 1, \"kangaroo\")\n",
    "\t\t# define data locations\n",
    "\t\timages_dir = dataset_dir + '/images/'\n",
    "\t\tannotations_dir = dataset_dir + '/annots/'\n",
    "\t\t# find all images\n",
    "\t\tfor filename in listdir(images_dir):\n",
    "\t\t\t# extract image id\n",
    "\t\t\timage_id = filename[:-4]\n",
    "\t\t\t# skip bad images\n",
    "\t\t\tif image_id in ['00090']:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t# skip all images after 150 if we are building the train set\n",
    "\t\t\tif is_train and int(image_id) >= 150:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t# skip all images before 150 if we are building the test/val set\n",
    "\t\t\tif not is_train and int(image_id) < 150:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\timg_path = images_dir + filename\n",
    "\t\t\tann_path = annotations_dir + image_id + '.xml'\n",
    "\t\t\t# add to dataset\n",
    "\t\t\tself.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path)\n",
    "\n",
    "\t# extract bounding boxes from an annotation file\n",
    "\tdef extract_boxes(self, filename):\n",
    "\t\t# load and parse the file\n",
    "\t\ttree = ElementTree.parse(filename)\n",
    "\t\t# get the root of the document\n",
    "\t\troot = tree.getroot()\n",
    "\t\t# extract each bounding box\n",
    "\t\tboxes = list()\n",
    "\t\tfor box in root.findall('.//bndbox'):\n",
    "\t\t\txmin = int(box.find('xmin').text)\n",
    "\t\t\tymin = int(box.find('ymin').text)\n",
    "\t\t\txmax = int(box.find('xmax').text)\n",
    "\t\t\tymax = int(box.find('ymax').text)\n",
    "\t\t\tcoors = [xmin, ymin, xmax, ymax]\n",
    "\t\t\tboxes.append(coors)\n",
    "\t\t# extract image dimensions\n",
    "\t\twidth = int(root.find('.//size/width').text)\n",
    "\t\theight = int(root.find('.//size/height').text)\n",
    "\t\treturn boxes, width, height\n",
    "\n",
    "\t# load the masks for an image\n",
    "\tdef load_mask(self, image_id):\n",
    "\t\t# get details of image\n",
    "\t\tinfo = self.image_info[image_id]\n",
    "\t\t# define box file location\n",
    "\t\tpath = info['annotation']\n",
    "\t\t# load XML\n",
    "\t\tboxes, w, h = self.extract_boxes(path)\n",
    "\t\t# create one array for all masks, each on a different channel\n",
    "\t\tmasks = zeros([h, w, len(boxes)], dtype='uint8')\n",
    "\t\t# create masks\n",
    "\t\tclass_ids = list()\n",
    "\t\tfor i in range(len(boxes)):\n",
    "\t\t\tbox = boxes[i]\n",
    "\t\t\trow_s, row_e = box[1], box[3]\n",
    "\t\t\tcol_s, col_e = box[0], box[2]\n",
    "\t\t\tmasks[row_s:row_e, col_s:col_e, i] = 1\n",
    "\t\t\tclass_ids.append(self.class_names.index('kangaroo'))\n",
    "\t\treturn masks, asarray(class_ids, dtype='int32')\n",
    "\n",
    "\t# load an image reference\n",
    "\tdef image_reference(self, image_id):\n",
    "\t\tinfo = self.image_info[image_id]\n",
    "\t\treturn info['path']\n",
    "\n",
    "# train set\n",
    "train_set = KangarooDataset()\n",
    "train_set.load_dataset('kangaroo', is_train=True)\n",
    "train_set.prepare()\n",
    "# define image id\n",
    "image_id = 1\n",
    "# load the image\n",
    "image = train_set.load_image(image_id)\n",
    "# load the masks and the class ids\n",
    "mask, class_ids = train_set.load_mask(image_id)\n",
    "# extract bounding boxes from the masks\n",
    "bbox = extract_bboxes(mask)\n",
    "# display image with masks and bounding boxes\n",
    "display_instances(image, bbox, mask, class_ids, train_set.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a mask rcnn on the kangaroo dataset\n",
    "from os import listdir\n",
    "from xml.etree import ElementTree\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "from mrcnn.utils import Dataset\n",
    "from mrcnn.config import Config\n",
    "from mrcnn.model import MaskRCNN\n",
    "\n",
    "# class that defines and loads the kangaroo dataset\n",
    "class KangarooDataset(Dataset):\n",
    "\t# load the dataset definitions\n",
    "\tdef load_dataset(self, dataset_dir, is_train=True):\n",
    "\t\t# define one class\n",
    "\t\tself.add_class(\"dataset\", 1, \"kangaroo\")\n",
    "\t\t# define data locations\n",
    "\t\timages_dir = dataset_dir + '/images/'\n",
    "\t\tannotations_dir = dataset_dir + '/annots/'\n",
    "\t\t# find all images\n",
    "\t\tfor filename in listdir(images_dir):\n",
    "\t\t\t# extract image id\n",
    "\t\t\timage_id = filename[:-4]\n",
    "\t\t\t# skip bad images\n",
    "\t\t\tif image_id in ['00090']:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t# skip all images after 150 if we are building the train set\n",
    "\t\t\tif is_train and int(image_id) >= 150:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t# skip all images before 150 if we are building the test/val set\n",
    "\t\t\tif not is_train and int(image_id) < 150:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\timg_path = images_dir + filename\n",
    "\t\t\tann_path = annotations_dir + image_id + '.xml'\n",
    "\t\t\t# add to dataset\n",
    "\t\t\tself.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path)\n",
    "\n",
    "\t# extract bounding boxes from an annotation file\n",
    "\tdef extract_boxes(self, filename):\n",
    "\t\t# load and parse the file\n",
    "\t\ttree = ElementTree.parse(filename)\n",
    "\t\t# get the root of the document\n",
    "\t\troot = tree.getroot()\n",
    "\t\t# extract each bounding box\n",
    "\t\tboxes = list()\n",
    "\t\tfor box in root.findall('.//bndbox'):\n",
    "\t\t\txmin = int(box.find('xmin').text)\n",
    "\t\t\tymin = int(box.find('ymin').text)\n",
    "\t\t\txmax = int(box.find('xmax').text)\n",
    "\t\t\tymax = int(box.find('ymax').text)\n",
    "\t\t\tcoors = [xmin, ymin, xmax, ymax]\n",
    "\t\t\tboxes.append(coors)\n",
    "\t\t# extract image dimensions\n",
    "\t\twidth = int(root.find('.//size/width').text)\n",
    "\t\theight = int(root.find('.//size/height').text)\n",
    "\t\treturn boxes, width, height\n",
    "\n",
    "\t# load the masks for an image\n",
    "\tdef load_mask(self, image_id):\n",
    "\t\t# get details of image\n",
    "\t\tinfo = self.image_info[image_id]\n",
    "\t\t# define box file location\n",
    "\t\tpath = info['annotation']\n",
    "\t\t# load XML\n",
    "\t\tboxes, w, h = self.extract_boxes(path)\n",
    "\t\t# create one array for all masks, each on a different channel\n",
    "\t\tmasks = zeros([h, w, len(boxes)], dtype='uint8')\n",
    "\t\t# create masks\n",
    "\t\tclass_ids = list()\n",
    "\t\tfor i in range(len(boxes)):\n",
    "\t\t\tbox = boxes[i]\n",
    "\t\t\trow_s, row_e = box[1], box[3]\n",
    "\t\t\tcol_s, col_e = box[0], box[2]\n",
    "\t\t\tmasks[row_s:row_e, col_s:col_e, i] = 1\n",
    "\t\t\tclass_ids.append(self.class_names.index('kangaroo'))\n",
    "\t\treturn masks, asarray(class_ids, dtype='int32')\n",
    "\n",
    "\t# load an image reference\n",
    "\tdef image_reference(self, image_id):\n",
    "\t\tinfo = self.image_info[image_id]\n",
    "\t\treturn info['path']\n",
    "\n",
    "# define a configuration for the model\n",
    "class KangarooConfig(Config):\n",
    "\t# define the name of the configuration\n",
    "\tNAME = \"kangaroo_cfg\"\n",
    "\t# number of classes (background + kangaroo)\n",
    "\tNUM_CLASSES = 1 + 1\n",
    "\t# number of training steps per epoch\n",
    "\tSTEPS_PER_EPOCH = 131\n",
    "\n",
    "# prepare train set\n",
    "train_set = KangarooDataset()\n",
    "train_set.load_dataset('kangaroo', is_train=True)\n",
    "train_set.prepare()\n",
    "print('Train: %d' % len(train_set.image_ids))\n",
    "# prepare test/val set\n",
    "test_set = KangarooDataset()\n",
    "test_set.load_dataset('kangaroo', is_train=False)\n",
    "test_set.prepare()\n",
    "print('Test: %d' % len(test_set.image_ids))\n",
    "# prepare config\n",
    "config = KangarooConfig()\n",
    "config.display()\n",
    "# define the model\n",
    "model = MaskRCNN(mode='training', model_dir='./', config=config)\n",
    "# load weights (mscoco) and exclude the output layers\n",
    "model.load_weights('mask_rcnn_coco.h5', by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "# train weights (output layers or 'heads')\n",
    "model.train(train_set, test_set, learning_rate=config.LEARNING_RATE, epochs=5, layers='heads')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the mask rcnn model on the kangaroo dataset\n",
    "from os import listdir\n",
    "from xml.etree import ElementTree\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "from numpy import expand_dims\n",
    "from numpy import mean\n",
    "from mrcnn.config import Config\n",
    "from mrcnn.model import MaskRCNN\n",
    "from mrcnn.utils import Dataset\n",
    "from mrcnn.utils import compute_ap\n",
    "from mrcnn.model import load_image_gt\n",
    "from mrcnn.model import mold_image\n",
    "\n",
    "# class that defines and loads the kangaroo dataset\n",
    "class KangarooDataset(Dataset):\n",
    "\t# load the dataset definitions\n",
    "\tdef load_dataset(self, dataset_dir, is_train=True):\n",
    "\t\t# define one class\n",
    "\t\tself.add_class(\"dataset\", 1, \"kangaroo\")\n",
    "\t\t# define data locations\n",
    "\t\timages_dir = dataset_dir + '/images/'\n",
    "\t\tannotations_dir = dataset_dir + '/annots/'\n",
    "\t\t# find all images\n",
    "\t\tfor filename in listdir(images_dir):\n",
    "\t\t\t# extract image id\n",
    "\t\t\timage_id = filename[:-4]\n",
    "\t\t\t# skip bad images\n",
    "\t\t\tif image_id in ['00090']:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t# skip all images after 150 if we are building the train set\n",
    "\t\t\tif is_train and int(image_id) >= 150:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t# skip all images before 150 if we are building the test/val set\n",
    "\t\t\tif not is_train and int(image_id) < 150:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\timg_path = images_dir + filename\n",
    "\t\t\tann_path = annotations_dir + image_id + '.xml'\n",
    "\t\t\t# add to dataset\n",
    "\t\t\tself.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path)\n",
    "\n",
    "\t# extract bounding boxes from an annotation file\n",
    "\tdef extract_boxes(self, filename):\n",
    "\t\t# load and parse the file\n",
    "\t\ttree = ElementTree.parse(filename)\n",
    "\t\t# get the root of the document\n",
    "\t\troot = tree.getroot()\n",
    "\t\t# extract each bounding box\n",
    "\t\tboxes = list()\n",
    "\t\tfor box in root.findall('.//bndbox'):\n",
    "\t\t\txmin = int(box.find('xmin').text)\n",
    "\t\t\tymin = int(box.find('ymin').text)\n",
    "\t\t\txmax = int(box.find('xmax').text)\n",
    "\t\t\tymax = int(box.find('ymax').text)\n",
    "\t\t\tcoors = [xmin, ymin, xmax, ymax]\n",
    "\t\t\tboxes.append(coors)\n",
    "\t\t# extract image dimensions\n",
    "\t\twidth = int(root.find('.//size/width').text)\n",
    "\t\theight = int(root.find('.//size/height').text)\n",
    "\t\treturn boxes, width, height\n",
    "\n",
    "\t# load the masks for an image\n",
    "\tdef load_mask(self, image_id):\n",
    "\t\t# get details of image\n",
    "\t\tinfo = self.image_info[image_id]\n",
    "\t\t# define box file location\n",
    "\t\tpath = info['annotation']\n",
    "\t\t# load XML\n",
    "\t\tboxes, w, h = self.extract_boxes(path)\n",
    "\t\t# create one array for all masks, each on a different channel\n",
    "\t\tmasks = zeros([h, w, len(boxes)], dtype='uint8')\n",
    "\t\t# create masks\n",
    "\t\tclass_ids = list()\n",
    "\t\tfor i in range(len(boxes)):\n",
    "\t\t\tbox = boxes[i]\n",
    "\t\t\trow_s, row_e = box[1], box[3]\n",
    "\t\t\tcol_s, col_e = box[0], box[2]\n",
    "\t\t\tmasks[row_s:row_e, col_s:col_e, i] = 1\n",
    "\t\t\tclass_ids.append(self.class_names.index('kangaroo'))\n",
    "\t\treturn masks, asarray(class_ids, dtype='int32')\n",
    "\n",
    "\t# load an image reference\n",
    "\tdef image_reference(self, image_id):\n",
    "\t\tinfo = self.image_info[image_id]\n",
    "\t\treturn info['path']\n",
    "\n",
    "# define the prediction configuration\n",
    "class PredictionConfig(Config):\n",
    "\t# define the name of the configuration\n",
    "\tNAME = \"kangaroo_cfg\"\n",
    "\t# number of classes (background + kangaroo)\n",
    "\tNUM_CLASSES = 1 + 1\n",
    "\t# simplify GPU config\n",
    "\tGPU_COUNT = 1\n",
    "\tIMAGES_PER_GPU = 1\n",
    "\n",
    "# calculate the mAP for a model on a given dataset\n",
    "def evaluate_model(dataset, model, cfg):\n",
    "\tAPs = list()\n",
    "\tfor image_id in dataset.image_ids:\n",
    "\t\t# load image, bounding boxes and masks for the image id\n",
    "\t\timage, _, gt_class_id, gt_bbox, gt_mask = load_image_gt(dataset, cfg, image_id, use_mini_mask=False)\n",
    "\t\t# convert pixel values (e.g. center)\n",
    "\t\tscaled_image = mold_image(image, cfg)\n",
    "\t\t# convert image into one sample\n",
    "\t\tsample = expand_dims(scaled_image, 0)\n",
    "\t\t# make prediction\n",
    "\t\tyhat = model.detect(sample, verbose=0)\n",
    "\t\t# extract results for first sample\n",
    "\t\tr = yhat[0]\n",
    "\t\t# calculate statistics, including AP\n",
    "\t\tAP, _, _, _ = compute_ap(gt_bbox, gt_class_id, gt_mask, r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "\t\t# store\n",
    "\t\tAPs.append(AP)\n",
    "\t# calculate the mean AP across all images\n",
    "\tmAP = mean(APs)\n",
    "\treturn mAP\n",
    "\n",
    "# load the train dataset\n",
    "train_set = KangarooDataset()\n",
    "train_set.load_dataset('kangaroo', is_train=True)\n",
    "train_set.prepare()\n",
    "print('Train: %d' % len(train_set.image_ids))\n",
    "# load the test dataset\n",
    "test_set = KangarooDataset()\n",
    "test_set.load_dataset('kangaroo', is_train=False)\n",
    "test_set.prepare()\n",
    "print('Test: %d' % len(test_set.image_ids))\n",
    "# create config\n",
    "cfg = PredictionConfig()\n",
    "# define the model\n",
    "model = MaskRCNN(mode='inference', model_dir='./', config=cfg)\n",
    "# load model weights\n",
    "model.load_weights('mask_rcnn_kangaroo_cfg_0005.h5', by_name=True)\n",
    "# evaluate model on training dataset\n",
    "train_mAP = evaluate_model(train_set, model, cfg)\n",
    "print(\"Train mAP: %.3f\" % train_mAP)\n",
    "# evaluate model on test dataset\n",
    "test_mAP = evaluate_model(test_set, model, cfg)\n",
    "print(\"Test mAP: %.3f\" % test_mAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect kangaroos in photos with mask rcnn model\n",
    "from os import listdir\n",
    "from xml.etree import ElementTree\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "from numpy import expand_dims\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.patches import Rectangle\n",
    "from mrcnn.config import Config\n",
    "from mrcnn.model import MaskRCNN\n",
    "from mrcnn.model import mold_image\n",
    "from mrcnn.utils import Dataset\n",
    "\n",
    "# class that defines and loads the kangaroo dataset\n",
    "class KangarooDataset(Dataset):\n",
    "\t# load the dataset definitions\n",
    "\tdef load_dataset(self, dataset_dir, is_train=True):\n",
    "\t\t# define one class\n",
    "\t\tself.add_class(\"dataset\", 1, \"kangaroo\")\n",
    "\t\t# define data locations\n",
    "\t\timages_dir = dataset_dir + '/images/'\n",
    "\t\tannotations_dir = dataset_dir + '/annots/'\n",
    "\t\t# find all images\n",
    "\t\tfor filename in listdir(images_dir):\n",
    "\t\t\t# extract image id\n",
    "\t\t\timage_id = filename[:-4]\n",
    "\t\t\t# skip bad images\n",
    "\t\t\tif image_id in ['00090']:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t# skip all images after 150 if we are building the train set\n",
    "\t\t\tif is_train and int(image_id) >= 150:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t# skip all images before 150 if we are building the test/val set\n",
    "\t\t\tif not is_train and int(image_id) < 150:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\timg_path = images_dir + filename\n",
    "\t\t\tann_path = annotations_dir + image_id + '.xml'\n",
    "\t\t\t# add to dataset\n",
    "\t\t\tself.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path)\n",
    "\n",
    "\t# load all bounding boxes for an image\n",
    "\tdef extract_boxes(self, filename):\n",
    "\t\t# load and parse the file\n",
    "\t\troot = ElementTree.parse(filename)\n",
    "\t\tboxes = list()\n",
    "\t\t# extract each bounding box\n",
    "\t\tfor box in root.findall('.//bndbox'):\n",
    "\t\t\txmin = int(box.find('xmin').text)\n",
    "\t\t\tymin = int(box.find('ymin').text)\n",
    "\t\t\txmax = int(box.find('xmax').text)\n",
    "\t\t\tymax = int(box.find('ymax').text)\n",
    "\t\t\tcoors = [xmin, ymin, xmax, ymax]\n",
    "\t\t\tboxes.append(coors)\n",
    "\t\t# extract image dimensions\n",
    "\t\twidth = int(root.find('.//size/width').text)\n",
    "\t\theight = int(root.find('.//size/height').text)\n",
    "\t\treturn boxes, width, height\n",
    "\n",
    "\t# load the masks for an image\n",
    "\tdef load_mask(self, image_id):\n",
    "\t\t# get details of image\n",
    "\t\tinfo = self.image_info[image_id]\n",
    "\t\t# define box file location\n",
    "\t\tpath = info['annotation']\n",
    "\t\t# load XML\n",
    "\t\tboxes, w, h = self.extract_boxes(path)\n",
    "\t\t# create one array for all masks, each on a different channel\n",
    "\t\tmasks = zeros([h, w, len(boxes)], dtype='uint8')\n",
    "\t\t# create masks\n",
    "\t\tclass_ids = list()\n",
    "\t\tfor i in range(len(boxes)):\n",
    "\t\t\tbox = boxes[i]\n",
    "\t\t\trow_s, row_e = box[1], box[3]\n",
    "\t\t\tcol_s, col_e = box[0], box[2]\n",
    "\t\t\tmasks[row_s:row_e, col_s:col_e, i] = 1\n",
    "\t\t\tclass_ids.append(self.class_names.index('kangaroo'))\n",
    "\t\treturn masks, asarray(class_ids, dtype='int32')\n",
    "\n",
    "\t# load an image reference\n",
    "\tdef image_reference(self, image_id):\n",
    "\t\tinfo = self.image_info[image_id]\n",
    "\t\treturn info['path']\n",
    "\n",
    "# define the prediction configuration\n",
    "class PredictionConfig(Config):\n",
    "\t# define the name of the configuration\n",
    "\tNAME = \"kangaroo_cfg\"\n",
    "\t# number of classes (background + kangaroo)\n",
    "\tNUM_CLASSES = 1 + 1\n",
    "\t# simplify GPU config\n",
    "\tGPU_COUNT = 1\n",
    "\tIMAGES_PER_GPU = 1\n",
    "\n",
    "# plot a number of photos with ground truth and predictions\n",
    "def plot_actual_vs_predicted(dataset, model, cfg, n_images=5):\n",
    "\t# load image and mask\n",
    "\tfor i in range(n_images):\n",
    "\t\t# load the image and mask\n",
    "\t\timage = dataset.load_image(i)\n",
    "\t\tmask, _ = dataset.load_mask(i)\n",
    "\t\t# convert pixel values (e.g. center)\n",
    "\t\tscaled_image = mold_image(image, cfg)\n",
    "\t\t# convert image into one sample\n",
    "\t\tsample = expand_dims(scaled_image, 0)\n",
    "\t\t# make prediction\n",
    "\t\tyhat = model.detect(sample, verbose=0)[0]\n",
    "\t\t# define subplot\n",
    "\t\tpyplot.subplot(n_images, 2, i*2+1)\n",
    "\t\t# turn off axis labels\n",
    "\t\tpyplot.axis('off')\n",
    "\t\t# plot raw pixel data\n",
    "\t\tpyplot.imshow(image)\n",
    "\t\tif i == 0:\n",
    "\t\t\tpyplot.title('Actual')\n",
    "\t\t# plot masks\n",
    "\t\tfor j in range(mask.shape[2]):\n",
    "\t\t\tpyplot.imshow(mask[:, :, j], cmap='gray', alpha=0.3)\n",
    "\t\t# get the context for drawing boxes\n",
    "\t\tpyplot.subplot(n_images, 2, i*2+2)\n",
    "\t\t# turn off axis labels\n",
    "\t\tpyplot.axis('off')\n",
    "\t\t# plot raw pixel data\n",
    "\t\tpyplot.imshow(image)\n",
    "\t\tif i == 0:\n",
    "\t\t\tpyplot.title('Predicted')\n",
    "\t\tax = pyplot.gca()\n",
    "\t\t# plot each box\n",
    "\t\tfor box in yhat['rois']:\n",
    "\t\t\t# get coordinates\n",
    "\t\t\ty1, x1, y2, x2 = box\n",
    "\t\t\t# calculate width and height of the box\n",
    "\t\t\twidth, height = x2 - x1, y2 - y1\n",
    "\t\t\t# create the shape\n",
    "\t\t\trect = Rectangle((x1, y1), width, height, fill=False, color='red')\n",
    "\t\t\t# draw the box\n",
    "\t\t\tax.add_patch(rect)\n",
    "\t# show the figure\n",
    "\tpyplot.show()\n",
    "\n",
    "# load the train dataset\n",
    "train_set = KangarooDataset()\n",
    "train_set.load_dataset('kangaroo', is_train=True)\n",
    "train_set.prepare()\n",
    "print('Train: %d' % len(train_set.image_ids))\n",
    "# load the test dataset\n",
    "test_set = KangarooDataset()\n",
    "test_set.load_dataset('kangaroo', is_train=False)\n",
    "test_set.prepare()\n",
    "print('Test: %d' % len(test_set.image_ids))\n",
    "# create config\n",
    "cfg = PredictionConfig()\n",
    "# define the model\n",
    "model = MaskRCNN(mode='inference', model_dir='./', config=cfg)\n",
    "# load model weights\n",
    "model_path = 'mask_rcnn_kangaroo_cfg_0005.h5'\n",
    "model.load_weights(model_path, by_name=True)\n",
    "# plot predictions for train dataset\n",
    "plot_actual_vs_predicted(train_set, model, cfg)\n",
    "# plot predictions for test dataset\n",
    "plot_actual_vs_predicted(test_set, model, cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirm OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check opencv version\n",
    "import cv2\n",
    "# print version number\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenCV face detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of face detection with opencv cascade classifier\n",
    "from cv2 import imread\n",
    "from cv2 import CascadeClassifier\n",
    "# load the photograph\n",
    "pixels = imread('test1.jpg')\n",
    "# load the pre-trained model\n",
    "classifier = CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "# perform face detection\n",
    "bboxes = classifier.detectMultiScale(pixels)\n",
    "# print bounding box for each detected face\n",
    "for box in bboxes:\n",
    "\tprint(box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenCV face detector plot 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot photo with detected faces using opencv cascade classifier\n",
    "from cv2 import imread\n",
    "from google.colab.patches import cv2_imshow as imshow\n",
    "from cv2 import waitKey\n",
    "from cv2 import destroyAllWindows\n",
    "from cv2 import CascadeClassifier\n",
    "from cv2 import rectangle\n",
    "# load the photograph\n",
    "pixels = imread('test1.jpg')\n",
    "# load the pre-trained model\n",
    "classifier = CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "# perform face detection\n",
    "bboxes = classifier.detectMultiScale(pixels)\n",
    "# print bounding box for each detected face\n",
    "for box in bboxes:\n",
    "\t# extract\n",
    "\tx, y, width, height = box\n",
    "\tx2, y2 = x + width, y + height\n",
    "\t# draw a rectangle over the pixels\n",
    "\trectangle(pixels, (x, y), (x2, y2), (0,0,255), 1)\n",
    "# show the image\n",
    "imshow(pixels)\n",
    "# keep the window open until we press a key\n",
    "waitKey(0)\n",
    "# close the window\n",
    "destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenCV face detector plot 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot photo with detected faces using opencv cascade classifier\n",
    "from cv2 import imread\n",
    "from google.colab.patches import cv2_imshow as imshow\n",
    "from cv2 import waitKey\n",
    "from cv2 import destroyAllWindows\n",
    "from cv2 import CascadeClassifier\n",
    "from cv2 import rectangle\n",
    "# load the photograph\n",
    "pixels = imread('test2.jpg')\n",
    "# load the pre-trained model\n",
    "classifier = CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "# perform face detection\n",
    "bboxes = classifier.detectMultiScale(pixels)\n",
    "# print bounding box for each detected face\n",
    "for box in bboxes:\n",
    "\t# extract\n",
    "\tx, y, width, height = box\n",
    "\tx2, y2 = x + width, y + height\n",
    "\t# draw a rectangle over the pixels\n",
    "\trectangle(pixels, (x, y), (x2, y2), (0,0,255), 1)\n",
    "# show the image\n",
    "imshow(pixels)\n",
    "# keep the window open until we press a key\n",
    "waitKey(0)\n",
    "# close the window\n",
    "destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check MTCNN version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm mtcnn was installed correctly\n",
    "import mtcnn\n",
    "# print version\n",
    "print(mtcnn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MTCNN face detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# face detection with mtcnn on a photograph\n",
    "from matplotlib import pyplot\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "# load image from file\n",
    "filename = 'test1.jpg'\n",
    "pixels = pyplot.imread(filename)\n",
    "# create the detector, using default weights\n",
    "detector = MTCNN()\n",
    "# detect faces in the image\n",
    "faces = detector.detect_faces(pixels)\n",
    "for face in faces:\n",
    "\tprint(face)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MTCNN face detection plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# face detection with mtcnn on a photograph\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.patches import Rectangle\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "\n",
    "# draw an image with detected objects\n",
    "def draw_image_with_boxes(filename, result_list):\n",
    "\t# load the image\n",
    "\tdata = pyplot.imread(filename)\n",
    "\t# plot the image\n",
    "\tpyplot.imshow(data)\n",
    "\t# get the context for drawing boxes\n",
    "\tax = pyplot.gca()\n",
    "\t# plot each box\n",
    "\tfor result in result_list:\n",
    "\t\t# get coordinates\n",
    "\t\tx, y, width, height = result['box']\n",
    "\t\t# create the shape\n",
    "\t\trect = Rectangle((x, y), width, height, fill=False, color='red')\n",
    "\t\t# draw the box\n",
    "\t\tax.add_patch(rect)\n",
    "\t# show the plot\n",
    "\tpyplot.show()\n",
    "\n",
    "filename = 'test1.jpg'\n",
    "# load image from file\n",
    "pixels = pyplot.imread(filename)\n",
    "# create the detector, using default weights\n",
    "detector = MTCNN()\n",
    "# detect faces in the image\n",
    "faces = detector.detect_faces(pixels)\n",
    "# display faces on the original image\n",
    "draw_image_with_boxes(filename, faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MTCNN face detection plot landmarks 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# face detection with mtcnn on a photograph\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.patches import Circle\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "\n",
    "# draw an image with detected objects\n",
    "def draw_image_with_boxes(filename, result_list):\n",
    "\t# load the image\n",
    "\tdata = pyplot.imread(filename)\n",
    "\t# plot the image\n",
    "\tpyplot.imshow(data)\n",
    "\t# get the context for drawing boxes\n",
    "\tax = pyplot.gca()\n",
    "\t# plot each box\n",
    "\tfor result in result_list:\n",
    "\t\t# get coordinates\n",
    "\t\tx, y, width, height = result['box']\n",
    "\t\t# create the shape\n",
    "\t\trect = Rectangle((x, y), width, height, fill=False, color='red')\n",
    "\t\t# draw the box\n",
    "\t\tax.add_patch(rect)\n",
    "\t\t# draw the dots\n",
    "\t\tfor _, value in result['keypoints'].items():\n",
    "\t\t\t# create and draw dot\n",
    "\t\t\tdot = Circle(value, radius=2, color='red')\n",
    "\t\t\tax.add_patch(dot)\n",
    "\t# show the plot\n",
    "\tpyplot.show()\n",
    "\n",
    "filename = 'test1.jpg'\n",
    "# load image from file\n",
    "pixels = pyplot.imread(filename)\n",
    "# create the detector, using default weights\n",
    "detector = MTCNN()\n",
    "# detect faces in the image\n",
    "faces = detector.detect_faces(pixels)\n",
    "# display faces on the original image\n",
    "draw_image_with_boxes(filename, faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MTCNN face detection plot landmarks 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# face detection with mtcnn on a photograph\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.patches import Circle\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "\n",
    "# draw an image with detected objects\n",
    "def draw_image_with_boxes(filename, result_list):\n",
    "\t# load the image\n",
    "\tdata = pyplot.imread(filename)\n",
    "\t# plot the image\n",
    "\tpyplot.imshow(data)\n",
    "\t# get the context for drawing boxes\n",
    "\tax = pyplot.gca()\n",
    "\t# plot each box\n",
    "\tfor result in result_list:\n",
    "\t\t# get coordinates\n",
    "\t\tx, y, width, height = result['box']\n",
    "\t\t# create the shape\n",
    "\t\trect = Rectangle((x, y), width, height, fill=False, color='red')\n",
    "\t\t# draw the box\n",
    "\t\tax.add_patch(rect)\n",
    "\t\t# draw the dots\n",
    "\t\tfor _, value in result['keypoints'].items():\n",
    "\t\t\t# create and draw dot\n",
    "\t\t\tdot = Circle(value, radius=2, color='red')\n",
    "\t\t\tax.add_patch(dot)\n",
    "\t# show the plot\n",
    "\tpyplot.show()\n",
    "\n",
    "filename = 'test2.jpg'\n",
    "# load image from file\n",
    "pixels = pyplot.imread(filename)\n",
    "# create the detector, using default weights\n",
    "detector = MTCNN()\n",
    "# detect faces in the image\n",
    "faces = detector.detect_faces(pixels)\n",
    "# display faces on the original image\n",
    "draw_image_with_boxes(filename, faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MTCNN extract faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract and plot each detected face in a photograph\n",
    "from matplotlib import pyplot\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "\n",
    "# draw each face separately\n",
    "def draw_faces(filename, result_list):\n",
    "\t# load the image\n",
    "\tdata = pyplot.imread(filename)\n",
    "\t# plot each face as a subplot\n",
    "\tfor i in range(len(result_list)):\n",
    "\t\t# get coordinates\n",
    "\t\tx1, y1, width, height = result_list[i]['box']\n",
    "\t\tx2, y2 = x1 + width, y1 + height\n",
    "\t\t# define subplot\n",
    "\t\tpyplot.subplot(1, len(result_list), i+1)\n",
    "\t\tpyplot.axis('off')\n",
    "\t\t# plot face\n",
    "\t\tpyplot.imshow(data[y1:y2, x1:x2])\n",
    "\t# show the plot\n",
    "\tpyplot.show()\n",
    "\n",
    "filename = 'test2.jpg'\n",
    "# load image from file\n",
    "pixels = pyplot.imread(filename)\n",
    "# create the detector, using default weights\n",
    "detector = MTCNN()\n",
    "# detect faces in the image\n",
    "faces = detector.detect_faces(pixels)\n",
    "# display faces on the original image\n",
    "draw_faces(filename, faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check VGGFace version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check version of keras_vggface\n",
    "import keras_vggface\n",
    "# print version\n",
    "print(keras_vggface.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check MTCNN version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm mtcnn was installed correctly\n",
    "import mtcnn\n",
    "# print version\n",
    "print(mtcnn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of face detection with mtcnn\n",
    "from matplotlib import pyplot\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "\n",
    "# extract a single face from a given photograph\n",
    "def extract_face(filename, required_size=(224, 224)):\n",
    "\t# load image from file\n",
    "\tpixels = pyplot.imread(filename)\n",
    "\t# create the detector, using default weights\n",
    "\tdetector = MTCNN()\n",
    "\t# detect faces in the image\n",
    "\tresults = detector.detect_faces(pixels)\n",
    "\t# extract the bounding box from the first face\n",
    "\tx1, y1, width, height = results[0]['box']\n",
    "\tx2, y2 = x1 + width, y1 + height\n",
    "\t# extract the face\n",
    "\tface = pixels[y1:y2, x1:x2]\n",
    "\t# resize pixels to the model size\n",
    "\timage = Image.fromarray(face)\n",
    "\timage = image.resize(required_size)\n",
    "\tface_array = asarray(image)\n",
    "\treturn face_array\n",
    "\n",
    "# load the photo and extract the face\n",
    "pixels = extract_face('sharon_stone1.jpg')\n",
    "# plot the extracted face\n",
    "pyplot.imshow(pixels)\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGGFace model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of creating a face embedding\n",
    "from keras_vggface.vggface import VGGFace\n",
    "# create a vggface2 model\n",
    "model = VGGFace(model='resnet50')\n",
    "# summarize input and output shape\n",
    "print('Inputs: %s' % model.inputs)\n",
    "print('Outputs: %s' % model.outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGGFace face identification Stone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of face detection with a vggface2 model (Sharon Stone)\n",
    "from numpy import expand_dims\n",
    "from matplotlib import pyplot\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras_vggface.utils import preprocess_input\n",
    "from keras_vggface.utils import decode_predictions\n",
    "\n",
    "# extract a single face from a given photograph\n",
    "def extract_face(filename, required_size=(224, 224)):\n",
    "\t# load image from file\n",
    "\tpixels = pyplot.imread(filename)\n",
    "\t# create the detector, using default weights\n",
    "\tdetector = MTCNN()\n",
    "\t# detect faces in the image\n",
    "\tresults = detector.detect_faces(pixels)\n",
    "\t# extract the bounding box from the first face\n",
    "\tx1, y1, width, height = results[0]['box']\n",
    "\tx2, y2 = x1 + width, y1 + height\n",
    "\t# extract the face\n",
    "\tface = pixels[y1:y2, x1:x2]\n",
    "\t# resize pixels to the model size\n",
    "\timage = Image.fromarray(face)\n",
    "\timage = image.resize(required_size)\n",
    "\tface_array = asarray(image)\n",
    "\treturn face_array\n",
    "\n",
    "# load the photo and extract the face\n",
    "pixels = extract_face('sharon_stone1.jpg')\n",
    "# convert one face into samples\n",
    "pixels = pixels.astype('float32')\n",
    "samples = expand_dims(pixels, axis=0)\n",
    "# prepare the face for the model, e.g. center pixels\n",
    "samples = preprocess_input(samples, version=2)\n",
    "# create a vggface model\n",
    "model = VGGFace(model='resnet50')\n",
    "# perform prediction\n",
    "yhat = model.predict(samples)\n",
    "# convert prediction into names\n",
    "results = decode_predictions(yhat)\n",
    "# display most likely results\n",
    "for result in results[0]:\n",
    "\tprint('%s: %.3f%%' % (result[0][3:-1], result[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGGFace face identification Tatum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of face detection with a vggface2 model (Channing Tatum)\n",
    "from numpy import expand_dims\n",
    "from matplotlib import pyplot\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras_vggface.utils import preprocess_input\n",
    "from keras_vggface.utils import decode_predictions\n",
    "\n",
    "# extract a single face from a given photograph\n",
    "def extract_face(filename, required_size=(224, 224)):\n",
    "\t# load image from file\n",
    "\tpixels = pyplot.imread(filename)\n",
    "\t# create the detector, using default weights\n",
    "\tdetector = MTCNN()\n",
    "\t# detect faces in the image\n",
    "\tresults = detector.detect_faces(pixels)\n",
    "\t# extract the bounding box from the first face\n",
    "\tx1, y1, width, height = results[0]['box']\n",
    "\tx2, y2 = x1 + width, y1 + height\n",
    "\t# extract the face\n",
    "\tface = pixels[y1:y2, x1:x2]\n",
    "\t# resize pixels to the model size\n",
    "\timage = Image.fromarray(face)\n",
    "\timage = image.resize(required_size)\n",
    "\tface_array = asarray(image)\n",
    "\treturn face_array\n",
    "\n",
    "# load the photo and extract the face\n",
    "pixels = extract_face('channing_tatum.jpg')\n",
    "# convert one face into samples\n",
    "pixels = pixels.astype('float32')\n",
    "samples = expand_dims(pixels, axis=0)\n",
    "# prepare the face for the model, e.g. center pixels\n",
    "samples = preprocess_input(samples, version=2)\n",
    "# create a vggface model\n",
    "model = VGGFace(model='resnet50')\n",
    "# perform prediction\n",
    "yhat = model.predict(samples)\n",
    "# convert prediction into names\n",
    "results = decode_predictions(yhat)\n",
    "# display most likely results\n",
    "for result in results[0]:\n",
    "\tprint('%s: %.3f%%' % (result[0][3:-1], result[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# face verification with the VGGFace2 model\n",
    "from matplotlib import pyplot\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "from scipy.spatial.distance import cosine\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras_vggface.utils import preprocess_input\n",
    "\n",
    "# extract a single face from a given photograph\n",
    "def extract_face(filename, required_size=(224, 224)):\n",
    "\t# load image from file\n",
    "\tpixels = pyplot.imread(filename)\n",
    "\t# create the detector, using default weights\n",
    "\tdetector = MTCNN()\n",
    "\t# detect faces in the image\n",
    "\tresults = detector.detect_faces(pixels)\n",
    "\t# extract the bounding box from the first face\n",
    "\tx1, y1, width, height = results[0]['box']\n",
    "\tx2, y2 = x1 + width, y1 + height\n",
    "\t# extract the face\n",
    "\tface = pixels[y1:y2, x1:x2]\n",
    "\t# resize pixels to the model size\n",
    "\timage = Image.fromarray(face)\n",
    "\timage = image.resize(required_size)\n",
    "\tface_array = asarray(image)\n",
    "\treturn face_array\n",
    "\n",
    "# extract faces and calculate face embeddings for a list of photo files\n",
    "def get_embeddings(filenames):\n",
    "\t# extract faces\n",
    "\tfaces = [extract_face(f) for f in filenames]\n",
    "\t# convert into an array of samples\n",
    "\tsamples = asarray(faces, 'float32')\n",
    "\t# prepare the face for the model, e.g. center pixels\n",
    "\tsamples = preprocess_input(samples, version=2)\n",
    "\t# create a vggface model\n",
    "\tmodel = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3), pooling='avg')\n",
    "\t# perform prediction\n",
    "\tyhat = model.predict(samples)\n",
    "\treturn yhat\n",
    "\n",
    "# determine if a candidate face is a match for a known face\n",
    "def is_match(known_embedding, candidate_embedding, thresh=0.5):\n",
    "\t# calculate distance between embeddings\n",
    "\tscore = cosine(known_embedding, candidate_embedding)\n",
    "\tif score <= thresh:\n",
    "\t\tprint('>face is a Match (%.3f <= %.3f)' % (score, thresh))\n",
    "\telse:\n",
    "\t\tprint('>face is NOT a Match (%.3f > %.3f)' % (score, thresh))\n",
    "\n",
    "# define filenames\n",
    "filenames = ['sharon_stone1.jpg', 'sharon_stone2.jpg', 'sharon_stone3.jpg', 'channing_tatum.jpg']\n",
    "# get embeddings file filenames\n",
    "embeddings = get_embeddings(filenames)\n",
    "# define sharon stone\n",
    "sharon_id = embeddings[0]\n",
    "# verify known photos of sharon\n",
    "print('Positive Tests')\n",
    "is_match(embeddings[0], embeddings[1])\n",
    "is_match(embeddings[0], embeddings[2])\n",
    "# verify known photos of other people\n",
    "print('Negative Tests')\n",
    "is_match(embeddings[0], embeddings[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FaceNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of loading the keras facenet model\n",
    "from keras.models import load_model\n",
    "# load the model\n",
    "model = load_model('facenet_keras.h5')\n",
    "# summarize input and output shape\n",
    "print(model.inputs)\n",
    "print(model.outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check MTCNN version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm mtcnn was installed correctly\n",
    "import mtcnn\n",
    "# print version\n",
    "print(mtcnn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate face detection on 5 Celebrity Faces Dataset\n",
    "from os import listdir\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "from matplotlib import pyplot\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "\n",
    "# extract a single face from a given photograph\n",
    "def extract_face(filename, required_size=(160, 160)):\n",
    "\t# load image from file\n",
    "\timage = Image.open(filename)\n",
    "\t# convert to RGB, if needed\n",
    "\timage = image.convert('RGB')\n",
    "\t# convert to array\n",
    "\tpixels = asarray(image)\n",
    "\t# create the detector, using default weights\n",
    "\tdetector = MTCNN()\n",
    "\t# detect faces in the image\n",
    "\tresults = detector.detect_faces(pixels)\n",
    "\t# extract the bounding box from the first face\n",
    "\tx1, y1, width, height = results[0]['box']\n",
    "\t# bug fix\n",
    "\tx1, y1 = abs(x1), abs(y1)\n",
    "\tx2, y2 = x1 + width, y1 + height\n",
    "\t# extract the face\n",
    "\tface = pixels[y1:y2, x1:x2]\n",
    "\t# resize pixels to the model size\n",
    "\timage = Image.fromarray(face)\n",
    "\timage = image.resize(required_size)\n",
    "\tface_array = asarray(image)\n",
    "\treturn face_array\n",
    "\n",
    "# specify folder to plot\n",
    "folder = '5-celebrity-faces-dataset/train/ben_afflek/'\n",
    "i = 1\n",
    "# enumerate files\n",
    "for filename in listdir(folder):\n",
    "\t# path\n",
    "\tpath = folder + filename\n",
    "\t# get face\n",
    "\tface = extract_face(path)\n",
    "\tprint(i, face.shape)\n",
    "\t# plot\n",
    "\tpyplot.subplot(2, 7, i)\n",
    "\tpyplot.axis('off')\n",
    "\tpyplot.imshow(face)\n",
    "\ti += 1\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract faces dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# face detection for the 5 Celebrity Faces Dataset\n",
    "from os import listdir\n",
    "from os.path import isdir\n",
    "from PIL import Image\n",
    "from numpy import savez_compressed\n",
    "from numpy import asarray\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "\n",
    "# extract a single face from a given photograph\n",
    "def extract_face(filename, required_size=(160, 160)):\n",
    "\t# load image from file\n",
    "\timage = Image.open(filename)\n",
    "\t# convert to RGB, if needed\n",
    "\timage = image.convert('RGB')\n",
    "\t# convert to array\n",
    "\tpixels = asarray(image)\n",
    "\t# create the detector, using default weights\n",
    "\tdetector = MTCNN()\n",
    "\t# detect faces in the image\n",
    "\tresults = detector.detect_faces(pixels)\n",
    "\t# extract the bounding box from the first face\n",
    "\tx1, y1, width, height = results[0]['box']\n",
    "\t# bug fix\n",
    "\tx1, y1 = abs(x1), abs(y1)\n",
    "\tx2, y2 = x1 + width, y1 + height\n",
    "\t# extract the face\n",
    "\tface = pixels[y1:y2, x1:x2]\n",
    "\t# resize pixels to the model size\n",
    "\timage = Image.fromarray(face)\n",
    "\timage = image.resize(required_size)\n",
    "\tface_array = asarray(image)\n",
    "\treturn face_array\n",
    "\n",
    "# load images and extract faces for all images in a directory\n",
    "def load_faces(directory):\n",
    "\tfaces = list()\n",
    "\t# enumerate files\n",
    "\tfor filename in listdir(directory):\n",
    "\t\t# path\n",
    "\t\tpath = directory + filename\n",
    "\t\t# get face\n",
    "\t\tface = extract_face(path)\n",
    "\t\t# store\n",
    "\t\tfaces.append(face)\n",
    "\treturn faces\n",
    "\n",
    "# load a dataset that contains one subdir for each class that in turn contains images\n",
    "def load_dataset(directory):\n",
    "\tX, y = list(), list()\n",
    "\t# enumerate folders, on per class\n",
    "\tfor subdir in listdir(directory):\n",
    "\t\t# path\n",
    "\t\tpath = directory + subdir + '/'\n",
    "\t\t# skip any files that might be in the dir\n",
    "\t\tif not isdir(path):\n",
    "\t\t\tcontinue\n",
    "\t\t# load all faces in the subdirectory\n",
    "\t\tfaces = load_faces(path)\n",
    "\t\t# create labels\n",
    "\t\tlabels = [subdir for _ in range(len(faces))]\n",
    "\t\t# summarize progress\n",
    "\t\tprint('>loaded %d examples for class: %s' % (len(faces), subdir))\n",
    "\t\t# store\n",
    "\t\tX.extend(faces)\n",
    "\t\ty.extend(labels)\n",
    "\treturn asarray(X), asarray(y)\n",
    "\n",
    "# load train dataset\n",
    "trainX, trainy = load_dataset('5-celebrity-faces-dataset/train/')\n",
    "print(trainX.shape, trainy.shape)\n",
    "# load test dataset\n",
    "testX, testy = load_dataset('5-celebrity-faces-dataset/val/')\n",
    "# save arrays to one file in compressed format\n",
    "savez_compressed('5-celebrity-faces-dataset.npz', trainX, trainy, testX, testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict face embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate a face embedding for each face in the dataset using facenet\n",
    "from numpy import load\n",
    "from numpy import expand_dims\n",
    "from numpy import asarray\n",
    "from numpy import savez_compressed\n",
    "from keras.models import load_model\n",
    "\n",
    "# get the face embedding for one face\n",
    "def get_embedding(model, face_pixels):\n",
    "\t# scale pixel values\n",
    "\tface_pixels = face_pixels.astype('float32')\n",
    "\t# standardize pixel values across channels (global)\n",
    "\tmean, std = face_pixels.mean(), face_pixels.std()\n",
    "\tface_pixels = (face_pixels - mean) / std\n",
    "\t# transform face into one sample\n",
    "\tsamples = expand_dims(face_pixels, axis=0)\n",
    "\t# make prediction to get embedding\n",
    "\tyhat = model.predict(samples)\n",
    "\treturn yhat[0]\n",
    "\n",
    "# load the face dataset\n",
    "data = load('5-celebrity-faces-dataset.npz')\n",
    "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
    "print('Loaded: ', trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
    "# load the facenet model\n",
    "model = load_model('facenet_keras.h5')\n",
    "print('Loaded Model')\n",
    "# convert each face in the train set to an embedding\n",
    "newTrainX = list()\n",
    "for face_pixels in trainX:\n",
    "\tembedding = get_embedding(model, face_pixels)\n",
    "\tnewTrainX.append(embedding)\n",
    "newTrainX = asarray(newTrainX)\n",
    "print(newTrainX.shape)\n",
    "# convert each face in the test set to an embedding\n",
    "newTestX = list()\n",
    "for face_pixels in testX:\n",
    "\tembedding = get_embedding(model, face_pixels)\n",
    "\tnewTestX.append(embedding)\n",
    "newTestX = asarray(newTestX)\n",
    "print(newTestX.shape)\n",
    "# save arrays to one file in compressed format\n",
    "savez_compressed('5-celebrity-faces-embeddings.npz', newTrainX, trainy, newTestX, testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# develop a classifier for the 5 Celebrity Faces Dataset\n",
    "from numpy import load\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.svm import SVC\n",
    "# load dataset\n",
    "data = load('5-celebrity-faces-embeddings.npz')\n",
    "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
    "print('Dataset: train=%d, test=%d' % (trainX.shape[0], testX.shape[0]))\n",
    "# normalize input vectors\n",
    "in_encoder = Normalizer(norm='l2')\n",
    "trainX = in_encoder.transform(trainX)\n",
    "testX = in_encoder.transform(testX)\n",
    "# label encode targets\n",
    "out_encoder = LabelEncoder()\n",
    "out_encoder.fit(trainy)\n",
    "trainy = out_encoder.transform(trainy)\n",
    "testy = out_encoder.transform(testy)\n",
    "# fit model\n",
    "model = SVC(kernel='linear', probability=True)\n",
    "model.fit(trainX, trainy)\n",
    "# predict\n",
    "yhat_train = model.predict(trainX)\n",
    "yhat_test = model.predict(testX)\n",
    "# score\n",
    "score_train = accuracy_score(trainy, yhat_train)\n",
    "score_test = accuracy_score(testy, yhat_test)\n",
    "# summarize\n",
    "print('Accuracy: train=%.3f, test=%.3f' % (score_train*100, score_test*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random face identity classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# develop a classifier for the 5 Celebrity Faces Dataset\n",
    "from random import choice\n",
    "from numpy import load\n",
    "from numpy import expand_dims\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.svm import SVC\n",
    "from matplotlib import pyplot\n",
    "# load faces\n",
    "data = load('5-celebrity-faces-dataset.npz')\n",
    "testX_faces = data['arr_2']\n",
    "# load face embeddings\n",
    "data = load('5-celebrity-faces-embeddings.npz')\n",
    "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
    "# normalize input vectors\n",
    "in_encoder = Normalizer(norm='l2')\n",
    "trainX = in_encoder.transform(trainX)\n",
    "testX = in_encoder.transform(testX)\n",
    "# label encode targets\n",
    "out_encoder = LabelEncoder()\n",
    "out_encoder.fit(trainy)\n",
    "trainy = out_encoder.transform(trainy)\n",
    "testy = out_encoder.transform(testy)\n",
    "# fit model\n",
    "model = SVC(kernel='linear', probability=True)\n",
    "model.fit(trainX, trainy)\n",
    "# test model on a random example from the test dataset\n",
    "selection = choice([i for i in range(testX.shape[0])])\n",
    "random_face_pixels = testX_faces[selection]\n",
    "random_face_emb = testX[selection]\n",
    "random_face_class = testy[selection]\n",
    "random_face_name = out_encoder.inverse_transform([random_face_class])\n",
    "# prediction for the face\n",
    "samples = expand_dims(random_face_emb, axis=0)\n",
    "yhat_class = model.predict(samples)\n",
    "yhat_prob = model.predict_proba(samples)\n",
    "# get name\n",
    "class_index = yhat_class[0]\n",
    "class_probability = yhat_prob[0,class_index] * 100\n",
    "predict_names = out_encoder.inverse_transform(yhat_class)\n",
    "print('Predicted: %s (%.3f)' % (predict_names[0], class_probability))\n",
    "print('Expected: %s' % random_face_name[0])\n",
    "# plot for fun\n",
    "pyplot.imshow(random_face_pixels)\n",
    "title = '%s (%.3f)' % (predict_names[0], class_probability)\n",
    "pyplot.title(title)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix 02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check library version numbers\n",
    "# scipy\n",
    "import scipy\n",
    "print('scipy: %s' % scipy.__version__)\n",
    "# numpy\n",
    "import numpy\n",
    "print('numpy: %s' % numpy.__version__)\n",
    "# matplotlib\n",
    "import matplotlib\n",
    "print('matplotlib: %s' % matplotlib.__version__)\n",
    "# pandas\n",
    "import pandas\n",
    "print('pandas: %s' % pandas.__version__)\n",
    "# statsmodels\n",
    "import statsmodels\n",
    "print('statsmodels: %s' % statsmodels.__version__)\n",
    "# scikit-learn\n",
    "import sklearn\n",
    "print('sklearn: %s' % sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check deep learning version numbers\n",
    "# theano\n",
    "import theano\n",
    "print('theano: %s' % theano.__version__)\n",
    "# tensorflow\n",
    "import tensorflow\n",
    "print('tensorflow: %s' % tensorflow.__version__)\n",
    "# keras\n",
    "import keras\n",
    "print('keras: %s' % keras.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

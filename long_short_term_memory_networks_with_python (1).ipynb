{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# define contrived series\n",
    "data = [10.0, 20.0, 30.0, 40.0, 50.0, 60.0, 70.0, 80.0, 90.0, 100.0]\n",
    "series = Series(data)\n",
    "print(series)\n",
    "# prepare data for normalization\n",
    "values = series.values\n",
    "values = values.reshape((len(values), 1))\n",
    "# train the normalization\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler = scaler.fit(values)\n",
    "print('Min: %f, Max: %f' % (scaler.data_min_, scaler.data_max_))\n",
    "# normalize the dataset and print\n",
    "normalized = scaler.transform(values)\n",
    "print(normalized)\n",
    "# inverse transform and print\n",
    "inversed = scaler.inverse_transform(normalized)\n",
    "print(inversed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from math import sqrt\n",
    "# define contrived series\n",
    "data = [1.0, 5.5, 9.0, 2.6, 8.8, 3.0, 4.1, 7.9, 6.3]\n",
    "series = Series(data)\n",
    "print(series)\n",
    "# prepare data for normalization\n",
    "values = series.values\n",
    "values = values.reshape((len(values), 1))\n",
    "# train the normalization\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(values)\n",
    "print('Mean: %f, StandardDeviation: %f' % (scaler.mean_, sqrt(scaler.var_)))\n",
    "# normalize the dataset and print\n",
    "standardized = scaler.transform(values)\n",
    "print(standardized)\n",
    "# inverse transform and print\n",
    "inversed = scaler.inverse_transform(standardized)\n",
    "print(inversed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# define example\n",
    "data = ['cold', 'cold', 'warm', 'cold', 'hot', 'hot', 'warm', 'cold', 'warm', 'hot']\n",
    "values = array(data)\n",
    "print(values)\n",
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "print(integer_encoded)\n",
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "print(onehot_encoded)\n",
    "# invert first example\n",
    "inverted = label_encoder.inverse_transform([argmax(onehot_encoded[0, :])])\n",
    "print(inverted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-sequence padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "# define sequences\n",
    "sequences = [\n",
    "\t[1, 2, 3, 4],\n",
    "\t   [1, 2, 3],\n",
    "\t\t     [1]\n",
    "\t]\n",
    "# pad sequence\n",
    "padded = pad_sequences(sequences)\n",
    "print(padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-sequence padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "# define sequences\n",
    "sequences = [\n",
    "\t[1, 2, 3, 4],\n",
    "\t   [1, 2, 3],\n",
    "\t\t     [1]\n",
    "\t]\n",
    "# pad sequence\n",
    "padded = pad_sequences(sequences, padding='post')\n",
    "print(padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-sequence truncating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "# define sequences\n",
    "sequences = [\n",
    "\t[1, 2, 3, 4],\n",
    "\t   [1, 2, 3],\n",
    "\t\t     [1]\n",
    "\t]\n",
    "# truncate sequence\n",
    "truncated= pad_sequences(sequences, maxlen=2)\n",
    "print(truncated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-sequence truncating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "# define sequences\n",
    "sequences = [\n",
    "\t[1, 2, 3, 4],\n",
    "\t   [1, 2, 3],\n",
    "\t\t     [1]\n",
    "\t]\n",
    "# truncate sequence\n",
    "truncated= pad_sequences(sequences, maxlen=2, truncating='post')\n",
    "print(truncated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shift sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "# define the sequence\n",
    "df = DataFrame()\n",
    "df['t'] = [x for x in range(10)]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shift forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "# define the sequence\n",
    "df = DataFrame()\n",
    "df['t'] = [x for x in range(10)]\n",
    "# shift forward\n",
    "df['t-1'] = df['t'].shift(1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shift backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "# define the sequence\n",
    "df = DataFrame()\n",
    "df['t'] = [x for x in range(10)]\n",
    "# shift backward\n",
    "df['t+1'] = df['t'].shift(-1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "data = array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "data = data.reshape((1, 10, 1))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "data = array([\n",
    "\t[0.1, 1.0],\n",
    "\t[0.2, 0.9],\n",
    "\t[0.3, 0.8],\n",
    "\t[0.4, 0.7],\n",
    "\t[0.5, 0.6],\n",
    "\t[0.6, 0.5],\n",
    "\t[0.7, 0.4],\n",
    "\t[0.8, 0.3],\n",
    "\t[0.9, 0.2],\n",
    "\t[1.0, 0.1]])\n",
    "data = data.reshape(1, 10, 2)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 06"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "\n",
    "# generate a sequence of random numbers in [0, n_features)\n",
    "def generate_sequence(length, n_features):\n",
    "\treturn [randint(0, n_features-1) for _ in range(length)]\n",
    "\n",
    "# one hot encode sequence\n",
    "def one_hot_encode(sequence, n_features):\n",
    "\tencoding = list()\n",
    "\tfor value in sequence:\n",
    "\t\tvector = [0 for _ in range(n_features)]\n",
    "\t\tvector[value] = 1\n",
    "\t\tencoding.append(vector)\n",
    "\treturn array(encoding)\n",
    "\n",
    "# decode a one hot encoded string\n",
    "def one_hot_decode(encoded_seq):\n",
    "\treturn [argmax(vector) for vector in encoded_seq]\n",
    "\n",
    "# generate random sequence\n",
    "sequence = generate_sequence(25, 100)\n",
    "print(sequence)\n",
    "# one hot encode\n",
    "encoded = one_hot_encode(sequence, 100)\n",
    "print(encoded)\n",
    "# one hot decode\n",
    "decoded = one_hot_decode(encoded)\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem example reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "\n",
    "# generate a sequence of random numbers in [0, n_features)\n",
    "def generate_sequence(length, n_features):\n",
    "\treturn [randint(0, n_features-1) for _ in range(length)]\n",
    "\n",
    "# one hot encode sequence\n",
    "def one_hot_encode(sequence, n_features):\n",
    "\tencoding = list()\n",
    "\tfor value in sequence:\n",
    "\t\tvector = [0 for _ in range(n_features)]\n",
    "\t\tvector[value] = 1\n",
    "\t\tencoding.append(vector)\n",
    "\treturn array(encoding)\n",
    "\n",
    "# decode a one hot encoded string\n",
    "def one_hot_decode(encoded_seq):\n",
    "\treturn [argmax(vector) for vector in encoded_seq]\n",
    "\n",
    "# generate one example for an lstm\n",
    "def generate_example(length, n_features, out_index):\n",
    "\t# generate sequence\n",
    "\tsequence = generate_sequence(length, n_features)\n",
    "\t# one hot encode\n",
    "\tencoded = one_hot_encode(sequence, n_features)\n",
    "\t# reshape sequence to be 3D\n",
    "\tX = encoded.reshape((1, length, n_features))\n",
    "\t# select output\n",
    "\ty = encoded[out_index].reshape(1, n_features)\n",
    "\treturn X, y\n",
    "\n",
    "X, y = generate_example(25, 100, 2)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "\n",
    "# generate a sequence of random numbers in [0, n_features)\n",
    "def generate_sequence(length, n_features):\n",
    "\treturn [randint(0, n_features-1) for _ in range(length)]\n",
    "\n",
    "# one hot encode sequence\n",
    "def one_hot_encode(sequence, n_features):\n",
    "\tencoding = list()\n",
    "\tfor value in sequence:\n",
    "\t\tvector = [0 for _ in range(n_features)]\n",
    "\t\tvector[value] = 1\n",
    "\t\tencoding.append(vector)\n",
    "\treturn array(encoding)\n",
    "\n",
    "# decode a one hot encoded string\n",
    "def one_hot_decode(encoded_seq):\n",
    "\treturn [argmax(vector) for vector in encoded_seq]\n",
    "\n",
    "# generate one example for an lstm\n",
    "def generate_example(length, n_features, out_index):\n",
    "\t# generate sequence\n",
    "\tsequence = generate_sequence(length, n_features)\n",
    "\t# one hot encode\n",
    "\tencoded = one_hot_encode(sequence, n_features)\n",
    "\t# reshape sequence to be 3D\n",
    "\tX = encoded.reshape((1, length, n_features))\n",
    "\t# select output\n",
    "\ty = encoded[out_index].reshape(1, n_features)\n",
    "\treturn X, y\n",
    "\n",
    "# define model\n",
    "length = 5\n",
    "n_features = 10\n",
    "out_index = 2\n",
    "model = Sequential()\n",
    "model.add(LSTM(25, input_shape=(length, n_features)))\n",
    "model.add(Dense(n_features, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "model.summary()\n",
    "\n",
    "# fit model\n",
    "for i in range(10000):\n",
    "\tX, y = generate_example(length, n_features, out_index)\n",
    "\tmodel.fit(X, y, epochs=1, verbose=2)\n",
    "\n",
    "# evaluate model\n",
    "correct = 0\n",
    "for i in range(100):\n",
    "\tX, y = generate_example(length, n_features, out_index)\n",
    "\tyhat = model.predict(X)\n",
    "\tif one_hot_decode(yhat) == one_hot_decode(y):\n",
    "\t\tcorrect += 1\n",
    "print('Accuracy: %f' % ((correct/100.0)*100.0))\n",
    "\n",
    "# prediction on new data\n",
    "X, y = generate_example(length, n_features, out_index)\n",
    "yhat = model.predict(X)\n",
    "print('Sequence:  %s' % [one_hot_decode(x) for x in X])\n",
    "print('Expected:  %s' % one_hot_decode(y))\n",
    "print('Predicted: %s' % one_hot_decode(yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM single layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of one output for whole sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from numpy import array\n",
    "# define model where LSTM is also output layer\n",
    "model = Sequential()\n",
    "model.add(LSTM(1, input_shape=(3,1)))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# input time steps\n",
    "data = array([0.1, 0.2, 0.3]).reshape((1,3,1))\n",
    "# make and show prediction\n",
    "print(model.predict(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of one output for each input time step\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from numpy import array\n",
    "# define model where LSTM is also output layer\n",
    "model = Sequential()\n",
    "model.add(LSTM(1, return_sequences=True, input_shape=(3,1)))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# input time steps\n",
    "data = array([0.1, 0.2, 0.3]).reshape((1,3,1))\n",
    "# make and show prediction\n",
    "print(model.predict(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sine wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sin\n",
    "from math import pi\n",
    "from matplotlib import pyplot\n",
    "# create sequence\n",
    "length = 100\n",
    "freq = 5\n",
    "sequence = [sin(2 * pi * freq * (i/float(length))) for i in range(length)]\n",
    "# plot sequence\n",
    "pyplot.plot(sequence)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Damped sine wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sin\n",
    "from math import pi\n",
    "from math import exp\n",
    "from matplotlib import pyplot\n",
    "# create sequence\n",
    "length = 100\n",
    "period = 10\n",
    "decay = 0.05\n",
    "sequence = [0.5 + 0.5 * sin(2 * pi * i / period) * exp(-decay * i) for i in range(length)]\n",
    "# plot sequence\n",
    "pyplot.plot(sequence)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Damped sine wave sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sin\n",
    "from math import pi\n",
    "from math import exp\n",
    "from random import randint\n",
    "from random import uniform\n",
    "from numpy import array\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# generate damped sine wave in [0,1]\n",
    "def generate_sequence(length, period, decay):\n",
    "\treturn [0.5 + 0.5 * sin(2 * pi * i / period) * exp(-decay * i) for i in range(length)]\n",
    "\n",
    "# generate input and output pairs of damped sine waves\n",
    "def generate_examples(length, n_patterns, output):\n",
    "\tX, y = list(), list()\n",
    "\tfor _ in range(n_patterns):\n",
    "\t\tp = randint(10, 20)\n",
    "\t\td = uniform(0.01, 0.1)\n",
    "\t\tsequence = generate_sequence(length + output, p, d)\n",
    "\t\tX.append(sequence[:-output])\n",
    "\t\ty.append(sequence[-output:])\n",
    "\tX = array(X).reshape(n_patterns, length, 1)\n",
    "\ty = array(y).reshape(n_patterns, output)\n",
    "\treturn X, y\n",
    "\n",
    "# test problem generation\n",
    "X, y = generate_examples(20, 5, 5)\n",
    "for i in range(len(X)):\n",
    "\tpyplot.plot([x for x in X[i, :, 0]] + [x for x in y[i]], '-o')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sin\n",
    "from math import pi\n",
    "from math import exp\n",
    "from random import randint\n",
    "from random import uniform\n",
    "from numpy import array\n",
    "from matplotlib import pyplot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "\n",
    "# generate damped sine wave in [0,1]\n",
    "def generate_sequence(length, period, decay):\n",
    "\treturn [0.5 + 0.5 * sin(2 * pi * i / period) * exp(-decay * i) for i in range(length)]\n",
    "\n",
    "# generate input and output pairs of damped sine waves\n",
    "def generate_examples(length, n_patterns, output):\n",
    "\tX, y = list(), list()\n",
    "\tfor _ in range(n_patterns):\n",
    "\t\tp = randint(10, 20)\n",
    "\t\td = uniform(0.01, 0.1)\n",
    "\t\tsequence = generate_sequence(length + output, p, d)\n",
    "\t\tX.append(sequence[:-output])\n",
    "\t\ty.append(sequence[-output:])\n",
    "\tX = array(X).reshape(n_patterns, length, 1)\n",
    "\ty = array(y).reshape(n_patterns, output)\n",
    "\treturn X, y\n",
    "\n",
    "# configure problem\n",
    "length = 50\n",
    "output = 5\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(20, return_sequences=True, input_shape=(length, 1)))\n",
    "model.add(LSTM(20))\n",
    "model.add(Dense(output))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "model.summary()\n",
    "\n",
    "# fit model\n",
    "X, y = generate_examples(length, 10000, output)\n",
    "history = model.fit(X, y, batch_size=10, epochs=1)\n",
    "\n",
    "# evaluate model\n",
    "X, y = generate_examples(length, 1000, output)\n",
    "loss = model.evaluate(X, y, verbose=0)\n",
    "print('MAE: %f' % loss)\n",
    "\n",
    "# prediction on new data\n",
    "X, y = generate_examples(length, 1, output)\n",
    "yhat = model.predict(X, verbose=0)\n",
    "pyplot.plot(y[0], label='y')\n",
    "pyplot.plot(yhat[0], label='yhat')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 08"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import zeros\n",
    "from random import randint\n",
    "from random import random\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# generate the next frame in the sequence\n",
    "def next_frame(last_step, last_frame, column):\n",
    "\t# define the scope of the next step\n",
    "\tlower = max(0, last_step-1)\n",
    "\tupper = min(last_frame.shape[0]-1, last_step+1)\n",
    "\t# choose the row index for the next step\n",
    "\tstep = randint(lower, upper)\n",
    "\t# copy the prior frame\n",
    "\tframe = last_frame.copy()\n",
    "\t# add the new step\n",
    "\tframe[step, column] = 1\n",
    "\treturn frame, step\n",
    "\n",
    "# generate a sequence of frames of a dot moving across an image\n",
    "def build_frames(size):\n",
    "\tframes = list()\n",
    "\t# create the first frame\n",
    "\tframe = zeros((size,size))\n",
    "\tstep = randint(0, size-1)\n",
    "\t# decide if we are heading left or right\n",
    "\tright = 1 if random() < 0.5 else 0\n",
    "\tcol = 0 if right else size-1\n",
    "\tframe[step, col] = 1\n",
    "\tframes.append(frame)\n",
    "\t# create all remaining frames\n",
    "\tfor i in range(1, size):\n",
    "\t\tcol = i if right else size-1-i\n",
    "\t\tframe, step = next_frame(step, frame, col)\n",
    "\t\tframes.append(frame)\n",
    "\treturn frames, right\n",
    "\n",
    "# generate sequence of frames\n",
    "size = 5\n",
    "frames, right = build_frames(size)\n",
    "# plot all frames\n",
    "pyplot.figure()\n",
    "for i in range(size):\n",
    "\t# create a gray scale subplot for each frame\n",
    "\tpyplot.subplot(1, size, i+1)\n",
    "\tpyplot.imshow(frames[i], cmap='Greys')\n",
    "\t# turn of the scale to make it clearer\n",
    "\tax = pyplot.gca()\n",
    "\tax.get_xaxis().set_visible(False)\n",
    "\tax.get_yaxis().set_visible(False)\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "from random import randint\n",
    "from numpy import array\n",
    "from numpy import zeros\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import TimeDistributed\n",
    "\n",
    "# generate the next frame in the sequence\n",
    "def next_frame(last_step, last_frame, column):\n",
    "\t# define the scope of the next step\n",
    "\tlower = max(0, last_step-1)\n",
    "\tupper = min(last_frame.shape[0]-1, last_step+1)\n",
    "\t# choose the row index for the next step\n",
    "\tstep = randint(lower, upper)\n",
    "\t# copy the prior frame\n",
    "\tframe = last_frame.copy()\n",
    "\t# add the new step\n",
    "\tframe[step, column] = 1\n",
    "\treturn frame, step\n",
    "\n",
    "# generate a sequence of frames of a dot moving across an image\n",
    "def build_frames(size):\n",
    "\tframes = list()\n",
    "\t# create the first frame\n",
    "\tframe = zeros((size,size))\n",
    "\tstep = randint(0, size-1)\n",
    "\t# decide if we are heading left or right\n",
    "\tright = 1 if random() < 0.5 else 0\n",
    "\tcol = 0 if right else size-1\n",
    "\tframe[step, col] = 1\n",
    "\tframes.append(frame)\n",
    "\t# create all remaining frames\n",
    "\tfor i in range(1, size):\n",
    "\t\tcol = i if right else size-1-i\n",
    "\t\tframe, step = next_frame(step, frame, col)\n",
    "\t\tframes.append(frame)\n",
    "\treturn frames, right\n",
    "\n",
    "# generate multiple sequences of frames and reshape for network input\n",
    "def generate_examples(size, n_patterns):\n",
    "\tX, y = list(), list()\n",
    "\tfor _ in range(n_patterns):\n",
    "\t\tframes, right = build_frames(size)\n",
    "\t\tX.append(frames)\n",
    "\t\ty.append(right)\n",
    "\t# resize as [samples, timesteps, width, height, channels]\n",
    "\tX = array(X).reshape(n_patterns, size, size, size, 1)\n",
    "\ty = array(y).reshape(n_patterns, 1)\n",
    "\treturn X, y\n",
    "\n",
    "# configure problem\n",
    "size = 50\n",
    "\n",
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(TimeDistributed(Conv2D(2, (2,2), activation='relu'), input_shape=(None,size,size,1)))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "model.summary()\n",
    "\n",
    "# fit model\n",
    "X, y = generate_examples(size, 5000)\n",
    "model.fit(X, y, batch_size=32, epochs=1)\n",
    "\n",
    "# evaluate model\n",
    "X, y = generate_examples(size, 100)\n",
    "loss, acc = model.evaluate(X, y, verbose=0)\n",
    "print('loss: %f, acc: %f' % (loss, acc*100))\n",
    "\n",
    "# prediction on new data\n",
    "X, y = generate_examples(size, 1)\n",
    "yhat = model.predict_classes(X, verbose=0)\n",
    "expected = \"Right\" if y[0]==1 else \"Left\"\n",
    "predicted = \"Right\" if yhat[0]==1 else \"Left\"\n",
    "print('Expected: %s, Predicted: %s' % (expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 09"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem generate pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed\n",
    "from random import randint\n",
    "\n",
    "# generate lists of random integers and their sum\n",
    "def random_sum_pairs(n_examples, n_numbers, largest):\n",
    "\tX, y = list(), list()\n",
    "\tfor _ in range(n_examples):\n",
    "\t\tin_pattern = [randint(1,largest) for _ in range(n_numbers)]\n",
    "\t\tout_pattern = sum(in_pattern)\n",
    "\t\tX.append(in_pattern)\n",
    "\t\ty.append(out_pattern)\n",
    "\treturn X, y\n",
    "\n",
    "seed(1)\n",
    "n_samples = 1\n",
    "n_numbers = 2\n",
    "largest = 10\n",
    "# generate pairs\n",
    "X, y = random_sum_pairs(n_samples, n_numbers, largest)\n",
    "print(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed\n",
    "from random import randint\n",
    "from math import ceil\n",
    "from math import log10\n",
    "\n",
    "# generate lists of random integers and their sum\n",
    "def random_sum_pairs(n_examples, n_numbers, largest):\n",
    "\tX, y = list(), list()\n",
    "\tfor _ in range(n_examples):\n",
    "\t\tin_pattern = [randint(1,largest) for _ in range(n_numbers)]\n",
    "\t\tout_pattern = sum(in_pattern)\n",
    "\t\tX.append(in_pattern)\n",
    "\t\ty.append(out_pattern)\n",
    "\treturn X, y\n",
    "\n",
    "# convert data to strings\n",
    "def to_string(X, y, n_numbers, largest):\n",
    "\tmax_length = int(n_numbers * ceil(log10(largest+1)) + n_numbers - 1)\n",
    "\tXstr = list()\n",
    "\tfor pattern in X:\n",
    "\t\tstrp = '+'.join([str(n) for n in pattern])\n",
    "\t\tstrp = ''.join([' ' for _ in range(max_length-len(strp))]) + strp\n",
    "\t\tXstr.append(strp)\n",
    "\tmax_length = int(ceil(log10(n_numbers * (largest+1))))\n",
    "\tystr = list()\n",
    "\tfor pattern in y:\n",
    "\t\tstrp = str(pattern)\n",
    "\t\tstrp = ''.join([' ' for _ in range(max_length-len(strp))]) + strp\n",
    "\t\tystr.append(strp)\n",
    "\treturn Xstr, ystr\n",
    "\n",
    "seed(1)\n",
    "n_samples = 1\n",
    "n_numbers = 2\n",
    "largest = 10\n",
    "# generate pairs\n",
    "X, y = random_sum_pairs(n_samples, n_numbers, largest)\n",
    "print(X, y)\n",
    "# convert to strings\n",
    "X, y = to_string(X, y, n_numbers, largest)\n",
    "print(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem integer encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed\n",
    "from random import randint\n",
    "from math import ceil\n",
    "from math import log10\n",
    "\n",
    "# generate lists of random integers and their sum\n",
    "def random_sum_pairs(n_examples, n_numbers, largest):\n",
    "\tX, y = list(), list()\n",
    "\tfor _ in range(n_examples):\n",
    "\t\tin_pattern = [randint(1,largest) for _ in range(n_numbers)]\n",
    "\t\tout_pattern = sum(in_pattern)\n",
    "\t\tX.append(in_pattern)\n",
    "\t\ty.append(out_pattern)\n",
    "\treturn X, y\n",
    "\n",
    "# convert data to strings\n",
    "def to_string(X, y, n_numbers, largest):\n",
    "\tmax_length = int(n_numbers * ceil(log10(largest+1)) + n_numbers - 1)\n",
    "\tXstr = list()\n",
    "\tfor pattern in X:\n",
    "\t\tstrp = '+'.join([str(n) for n in pattern])\n",
    "\t\tstrp = ''.join([' ' for _ in range(max_length-len(strp))]) + strp\n",
    "\t\tXstr.append(strp)\n",
    "\tmax_length = int(ceil(log10(n_numbers * (largest+1))))\n",
    "\tystr = list()\n",
    "\tfor pattern in y:\n",
    "\t\tstrp = str(pattern)\n",
    "\t\tstrp = ''.join([' ' for _ in range(max_length-len(strp))]) + strp\n",
    "\t\tystr.append(strp)\n",
    "\treturn Xstr, ystr\n",
    "\n",
    "# integer encode strings\n",
    "def integer_encode(X, y, alphabet):\n",
    "\tchar_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "\tXenc = list()\n",
    "\tfor pattern in X:\n",
    "\t\tinteger_encoded = [char_to_int[char] for char in pattern]\n",
    "\t\tXenc.append(integer_encoded)\n",
    "\tyenc = list()\n",
    "\tfor pattern in y:\n",
    "\t\tinteger_encoded = [char_to_int[char] for char in pattern]\n",
    "\t\tyenc.append(integer_encoded)\n",
    "\treturn Xenc, yenc\n",
    "\n",
    "seed(1)\n",
    "n_samples = 1\n",
    "n_numbers = 2\n",
    "largest = 10\n",
    "# generate pairs\n",
    "X, y = random_sum_pairs(n_samples, n_numbers, largest)\n",
    "print(X, y)\n",
    "# convert to strings\n",
    "X, y = to_string(X, y, n_numbers, largest)\n",
    "print(X, y)\n",
    "# integer encode\n",
    "alphabet = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '+', ' ']\n",
    "X, y = integer_encode(X, y, alphabet)\n",
    "print(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed\n",
    "from random import randint\n",
    "from math import ceil\n",
    "from math import log10\n",
    "\n",
    "# generate lists of random integers and their sum\n",
    "def random_sum_pairs(n_examples, n_numbers, largest):\n",
    "\tX, y = list(), list()\n",
    "\tfor _ in range(n_examples):\n",
    "\t\tin_pattern = [randint(1,largest) for _ in range(n_numbers)]\n",
    "\t\tout_pattern = sum(in_pattern)\n",
    "\t\tX.append(in_pattern)\n",
    "\t\ty.append(out_pattern)\n",
    "\treturn X, y\n",
    "\n",
    "# convert data to strings\n",
    "def to_string(X, y, n_numbers, largest):\n",
    "\tmax_length = int(n_numbers * ceil(log10(largest+1)) + n_numbers - 1)\n",
    "\tXstr = list()\n",
    "\tfor pattern in X:\n",
    "\t\tstrp = '+'.join([str(n) for n in pattern])\n",
    "\t\tstrp = ''.join([' ' for _ in range(max_length-len(strp))]) + strp\n",
    "\t\tXstr.append(strp)\n",
    "\tmax_length = int(ceil(log10(n_numbers * (largest+1))))\n",
    "\tystr = list()\n",
    "\tfor pattern in y:\n",
    "\t\tstrp = str(pattern)\n",
    "\t\tstrp = ''.join([' ' for _ in range(max_length-len(strp))]) + strp\n",
    "\t\tystr.append(strp)\n",
    "\treturn Xstr, ystr\n",
    "\n",
    "# integer encode strings\n",
    "def integer_encode(X, y, alphabet):\n",
    "\tchar_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "\tXenc = list()\n",
    "\tfor pattern in X:\n",
    "\t\tinteger_encoded = [char_to_int[char] for char in pattern]\n",
    "\t\tXenc.append(integer_encoded)\n",
    "\tyenc = list()\n",
    "\tfor pattern in y:\n",
    "\t\tinteger_encoded = [char_to_int[char] for char in pattern]\n",
    "\t\tyenc.append(integer_encoded)\n",
    "\treturn Xenc, yenc\n",
    "\n",
    "# one hot encode\n",
    "def one_hot_encode(X, y, max_int):\n",
    "\tXenc = list()\n",
    "\tfor seq in X:\n",
    "\t\tpattern = list()\n",
    "\t\tfor index in seq:\n",
    "\t\t\tvector = [0 for _ in range(max_int)]\n",
    "\t\t\tvector[index] = 1\n",
    "\t\t\tpattern.append(vector)\n",
    "\t\tXenc.append(pattern)\n",
    "\tyenc = list()\n",
    "\tfor seq in y:\n",
    "\t\tpattern = list()\n",
    "\t\tfor index in seq:\n",
    "\t\t\tvector = [0 for _ in range(max_int)]\n",
    "\t\t\tvector[index] = 1\n",
    "\t\t\tpattern.append(vector)\n",
    "\t\tyenc.append(pattern)\n",
    "\treturn Xenc, yenc\n",
    "\n",
    "seed(1)\n",
    "n_samples = 1\n",
    "n_numbers = 2\n",
    "largest = 10\n",
    "# generate pairs\n",
    "X, y = random_sum_pairs(n_samples, n_numbers, largest)\n",
    "print(X, y)\n",
    "# convert to strings\n",
    "X, y = to_string(X, y, n_numbers, largest)\n",
    "print(X, y)\n",
    "# integer encode\n",
    "alphabet = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '+', ' ']\n",
    "X, y = integer_encode(X, y, alphabet)\n",
    "print(X, y)\n",
    "# one hot encode\n",
    "X, y = one_hot_encode(X, y, len(alphabet))\n",
    "print(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder decoder LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from numpy import array\n",
    "from math import ceil\n",
    "from math import log10\n",
    "from numpy import argmax\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import RepeatVector\n",
    "\n",
    "# generate lists of random integers and their sum\n",
    "def random_sum_pairs(n_examples, n_numbers, largest):\n",
    "\tX, y = list(), list()\n",
    "\tfor _ in range(n_examples):\n",
    "\t\tin_pattern = [randint(1,largest) for _ in range(n_numbers)]\n",
    "\t\tout_pattern = sum(in_pattern)\n",
    "\t\tX.append(in_pattern)\n",
    "\t\ty.append(out_pattern)\n",
    "\treturn X, y\n",
    "\n",
    "# convert data to strings\n",
    "def to_string(X, y, n_numbers, largest):\n",
    "\tmax_length = int(n_numbers * ceil(log10(largest+1)) + n_numbers - 1)\n",
    "\tXstr = list()\n",
    "\tfor pattern in X:\n",
    "\t\tstrp = '+'.join([str(n) for n in pattern])\n",
    "\t\tstrp = ''.join([' ' for _ in range(max_length-len(strp))]) + strp\n",
    "\t\tXstr.append(strp)\n",
    "\tmax_length = int(ceil(log10(n_numbers * (largest+1))))\n",
    "\tystr = list()\n",
    "\tfor pattern in y:\n",
    "\t\tstrp = str(pattern)\n",
    "\t\tstrp = ''.join([' ' for _ in range(max_length-len(strp))]) + strp\n",
    "\t\tystr.append(strp)\n",
    "\treturn Xstr, ystr\n",
    "\n",
    "# integer encode strings\n",
    "def integer_encode(X, y, alphabet):\n",
    "\tchar_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "\tXenc = list()\n",
    "\tfor pattern in X:\n",
    "\t\tinteger_encoded = [char_to_int[char] for char in pattern]\n",
    "\t\tXenc.append(integer_encoded)\n",
    "\tyenc = list()\n",
    "\tfor pattern in y:\n",
    "\t\tinteger_encoded = [char_to_int[char] for char in pattern]\n",
    "\t\tyenc.append(integer_encoded)\n",
    "\treturn Xenc, yenc\n",
    "\n",
    "# one hot encode\n",
    "def one_hot_encode(X, y, max_int):\n",
    "\tXenc = list()\n",
    "\tfor seq in X:\n",
    "\t\tpattern = list()\n",
    "\t\tfor index in seq:\n",
    "\t\t\tvector = [0 for _ in range(max_int)]\n",
    "\t\t\tvector[index] = 1\n",
    "\t\t\tpattern.append(vector)\n",
    "\t\tXenc.append(pattern)\n",
    "\tyenc = list()\n",
    "\tfor seq in y:\n",
    "\t\tpattern = list()\n",
    "\t\tfor index in seq:\n",
    "\t\t\tvector = [0 for _ in range(max_int)]\n",
    "\t\t\tvector[index] = 1\n",
    "\t\t\tpattern.append(vector)\n",
    "\t\tyenc.append(pattern)\n",
    "\treturn Xenc, yenc\n",
    "\n",
    "# generate an encoded dataset\n",
    "def generate_data(n_samples, n_numbers, largest, alphabet):\n",
    "\t# generate pairs\n",
    "\tX, y = random_sum_pairs(n_samples, n_numbers, largest)\n",
    "\t# convert to strings\n",
    "\tX, y = to_string(X, y, n_numbers, largest)\n",
    "\t# integer encode\n",
    "\tX, y = integer_encode(X, y, alphabet)\n",
    "\t# one hot encode\n",
    "\tX, y = one_hot_encode(X, y, len(alphabet))\n",
    "\t# return as numpy arrays\n",
    "\tX, y = array(X), array(y)\n",
    "\treturn X, y\n",
    "\n",
    "# invert encoding\n",
    "def invert(seq, alphabet):\n",
    "\tint_to_char = dict((i, c) for i, c in enumerate(alphabet))\n",
    "\tstrings = list()\n",
    "\tfor pattern in seq:\n",
    "\t\tstring = int_to_char[argmax(pattern)]\n",
    "\t\tstrings.append(string)\n",
    "\treturn ''.join(strings)\n",
    "\n",
    "# configure problem\n",
    "\n",
    "# number of math terms\n",
    "n_terms = 3\n",
    "# largest value for any single input digit\n",
    "largest = 10\n",
    "# scope of possible symbols for each input or output time step\n",
    "alphabet = [str(x) for x in range(10)] + ['+', ' ']\n",
    "\n",
    "# size of alphabet: (12 for 0-9, + and ' ')\n",
    "n_chars = len(alphabet)\n",
    "# length of encoded input sequence (8 for '10+10+10)\n",
    "n_in_seq_length = int(n_terms * ceil(log10(largest+1)) + n_terms - 1)\n",
    "# length of encoded output sequence (2 for '30')\n",
    "n_out_seq_length = int(ceil(log10(n_terms * (largest+1))))\n",
    "\n",
    "# define LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(75, input_shape=(n_in_seq_length, n_chars)))\n",
    "model.add(RepeatVector(n_out_seq_length))\n",
    "model.add(LSTM(50, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(n_chars, activation='softmax')))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# fit LSTM\n",
    "X, y = generate_data(75000, n_terms, largest, alphabet)\n",
    "model.fit(X, y, epochs=1, batch_size=32)\n",
    "\n",
    "# evaluate LSTM\n",
    "X, y = generate_data(100, n_terms, largest, alphabet)\n",
    "loss, acc = model.evaluate(X, y, verbose=0)\n",
    "print('Loss: %f, Accuracy: %f' % (loss, acc*100))\n",
    "\n",
    "# predict\n",
    "for _ in range(10):\n",
    "\t# generate an input-output pair\n",
    "\tX, y = generate_data(1, n_terms, largest, alphabet)\n",
    "\t# make prediction\n",
    "\tyhat = model.predict(X, verbose=0)\n",
    "\t# decode input, expected and predicted\n",
    "\tin_seq = invert(X[0], alphabet)\n",
    "\tout_seq = invert(y[0], alphabet)\n",
    "\tpredicted = invert(yhat[0], alphabet)\n",
    "\tprint('%s = %s (expect %s)' % (in_seq, predicted, out_seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "from numpy import array\n",
    "from numpy import cumsum\n",
    "\n",
    "# create a cumulative sum sequence\n",
    "def get_sequence(n_timesteps):\n",
    "\t# create a sequence of random numbers in [0,1]\n",
    "\tX = array([random() for _ in range(n_timesteps)])\n",
    "\t# calculate cut-off value to change class values\n",
    "\tlimit = n_timesteps/4.0\n",
    "\t# determine the class outcome for each item in cumulative sequence\n",
    "\ty = array([0 if x < limit else 1 for x in cumsum(X)])\n",
    "\treturn X, y\n",
    "\n",
    "X, y = get_sequence(10)\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "from numpy import array\n",
    "from numpy import cumsum\n",
    "from numpy import array_equal\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "\n",
    "# create a cumulative sum sequence\n",
    "def get_sequence(n_timesteps):\n",
    "\t# create a sequence of random numbers in [0,1]\n",
    "\tX = array([random() for _ in range(n_timesteps)])\n",
    "\t# calculate cut-off value to change class values\n",
    "\tlimit = n_timesteps/4.0\n",
    "\t# determine the class outcome for each item in cumulative sequence\n",
    "\ty = array([0 if x < limit else 1 for x in cumsum(X)])\n",
    "\treturn X, y\n",
    "\n",
    "# create multiple samples of cumulative sum sequences\n",
    "def get_sequences(n_sequences, n_timesteps):\n",
    "\tseqX, seqY = list(), list()\n",
    "\t# create and store sequences\n",
    "\tfor _ in range(n_sequences):\n",
    "\t\tX, y = get_sequence(n_timesteps)\n",
    "\t\tseqX.append(X)\n",
    "\t\tseqY.append(y)\n",
    "\t# reshape input and output for lstm\n",
    "\tseqX = array(seqX).reshape(n_sequences, n_timesteps, 1)\n",
    "\tseqY = array(seqY).reshape(n_sequences, n_timesteps, 1)\n",
    "\treturn seqX, seqY\n",
    "\n",
    "# define problem\n",
    "n_timesteps = 10\n",
    "\n",
    "# define LSTM\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(50, return_sequences=True), input_shape=(n_timesteps, 1)))\n",
    "model.add(TimeDistributed(Dense(1, activation='sigmoid')))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "model.summary()\n",
    "\n",
    "# train LSTM\n",
    "X, y = get_sequences(50000, n_timesteps)\n",
    "model.fit(X, y, epochs=1, batch_size=10)\n",
    "\n",
    "# evaluate LSTM\n",
    "X, y = get_sequences(100, n_timesteps)\n",
    "loss, acc = model.evaluate(X, y, verbose=0)\n",
    "print('Loss: %f, Accuracy: %f' % (loss, acc*100))\n",
    "\n",
    "# make predictions\n",
    "for _ in range(10):\n",
    "\tX, y = get_sequences(1, n_timesteps)\n",
    "\tyhat = model.predict_classes(X, verbose=0)\n",
    "\texp, pred = y.reshape(n_timesteps), yhat.reshape(n_timesteps)\n",
    "\tprint('y=%s, yhat=%s, correct=%s' % (exp, pred, array_equal(exp,pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem random rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "\n",
    "# generate a rectangle with random width and height\n",
    "def random_rectangle():\n",
    "\twidth, height = random(), random()\n",
    "\tpoints = list()\n",
    "\t# bottom left\n",
    "\tpoints.append([0.0, 0.0])\n",
    "\t# bottom right\n",
    "\tpoints.append([width, 0.0])\n",
    "\t# top right\n",
    "\tpoints.append([width, height])\n",
    "\t# top left\n",
    "\tpoints.append([0.0, height])\n",
    "\treturn points\n",
    "\n",
    "rect = random_rectangle()\n",
    "print(rect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.patches import PathPatch\n",
    "from matplotlib.path import Path\n",
    "\n",
    "# generate a rectangle with random width and height\n",
    "def random_rectangle():\n",
    "\twidth, height = random(), random()\n",
    "\tpoints = list()\n",
    "\t# bottom left\n",
    "\tpoints.append([0.0, 0.0])\n",
    "\t# bottom right\n",
    "\tpoints.append([width, 0.0])\n",
    "\t# top right\n",
    "\tpoints.append([width, height])\n",
    "\t# top left\n",
    "\tpoints.append([0.0, height])\n",
    "\treturn points\n",
    "\n",
    "# plot a rectangle\n",
    "def plot_rectangle(rect):\n",
    "\t# close the rectangle path\n",
    "\trect.append(rect[0])\n",
    "\t# define path\n",
    "\tcodes = [Path.MOVETO, Path.LINETO, Path.LINETO, Path.LINETO, Path.CLOSEPOLY]\n",
    "\tpath = Path(rect, codes)\n",
    "\taxis = pyplot.gca()\n",
    "\tpatch = PathPatch(path)\n",
    "\t# add shape to plot\n",
    "\taxis.add_patch(patch)\n",
    "\taxis.set_xlim(-0.1,1.1)\n",
    "\taxis.set_ylim(-0.1,1.1)\n",
    "\tpyplot.show()\n",
    "\n",
    "rect = random_rectangle()\n",
    "plot_rectangle(rect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "from numpy import array\n",
    "\n",
    "# generate a rectangle with random width and height\n",
    "def random_rectangle():\n",
    "\twidth, height = random(), random()\n",
    "\tpoints = list()\n",
    "\t# bottom left\n",
    "\tpoints.append([0.0, 0.0])\n",
    "\t# bottom right\n",
    "\tpoints.append([width, 0.0])\n",
    "\t# top right\n",
    "\tpoints.append([width, height])\n",
    "\t# top left\n",
    "\tpoints.append([0.0, height])\n",
    "\treturn points\n",
    "\n",
    "# generate input and output sequences for one random rectangle\n",
    "def get_samples():\n",
    "\t# generate rectangle\n",
    "\trect = random_rectangle()\n",
    "\tX, y = list(), list()\n",
    "\t# create input output pairs for each coordinate\n",
    "\tfor i in range(1, len(rect)):\n",
    "\t\tX.append(rect[i-1])\n",
    "\t\ty.append(rect[i])\n",
    "\t# convert input sequence shape to have 1 time step and 2 features\n",
    "\tX, y = array(X), array(y)\n",
    "\tX = X.reshape((X.shape[0], 1, 2))\n",
    "\treturn X, y\n",
    "\n",
    "X, y = get_samples()\n",
    "for i in range(X.shape[0]):\n",
    "\tprint(X[i][0], '=>', y[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "from numpy import array\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.patches import PathPatch\n",
    "from matplotlib.path import Path\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "\n",
    "# generate a rectangle with random width and height\n",
    "def random_rectangle():\n",
    "\twidth, height = random(), random()\n",
    "\tpoints = list()\n",
    "\t# bottom left\n",
    "\tpoints.append([0.0, 0.0])\n",
    "\t# bottom right\n",
    "\tpoints.append([width, 0.0])\n",
    "\t# top right\n",
    "\tpoints.append([width, height])\n",
    "\t# top left\n",
    "\tpoints.append([0.0, height])\n",
    "\treturn points\n",
    "\n",
    "# plot a rectangle\n",
    "def plot_rectangle(rect):\n",
    "\t# close the rectangle path\n",
    "\trect.append(rect[0])\n",
    "\t# define path\n",
    "\tcodes = [Path.MOVETO, Path.LINETO, Path.LINETO, Path.LINETO, Path.CLOSEPOLY]\n",
    "\tpath = Path(rect, codes)\n",
    "\taxis = pyplot.gca()\n",
    "\tpatch = PathPatch(path)\n",
    "\t# add shape to plot\n",
    "\taxis.add_patch(patch)\n",
    "\taxis.set_xlim(-0.1,1.1)\n",
    "\taxis.set_ylim(-0.1,1.1)\n",
    "\tpyplot.show()\n",
    "\n",
    "# generate input and output sequences for one random rectangle\n",
    "def get_samples():\n",
    "\t# generate rectangle\n",
    "\trect = random_rectangle()\n",
    "\tX, y = list(), list()\n",
    "\t# create input output pairs for each coordinate\n",
    "\tfor i in range(1, len(rect)):\n",
    "\t\tX.append(rect[i-1])\n",
    "\t\ty.append(rect[i])\n",
    "\t# convert input sequence shape to have 1 time step and 2 features\n",
    "\tX, y = array(X), array(y)\n",
    "\tX = X.reshape((X.shape[0], 1, 2))\n",
    "\treturn X, y\n",
    "\n",
    "# use a fit LSTM model to generate a new rectangle from scratch\n",
    "def generate_rectangle(model):\n",
    "\trect = list()\n",
    "\t# use [0,0] to seed the generation process\n",
    "\tlast = array([0.0,0.0]).reshape((1, 1, 2))\n",
    "\trect.append([[y for y in x] for x in last[0]][0])\n",
    "\t# generate the remaining 3 coordinates\n",
    "\tfor _ in range(3):\n",
    "\t\t# predict the next coordinate\n",
    "\t\tyhat = model.predict(last, verbose=0)\n",
    "\t\t# use this output as input for the next prediction\n",
    "\t\tlast = yhat.reshape((1, 1, 2))\n",
    "\t\t# store coordinate\n",
    "\t\trect.append([[y for y in x] for x in last[0]][0])\n",
    "\treturn rect\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(10, input_shape=(1, 2)))\n",
    "model.add(Dense(2, activation='linear'))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "model.summary()\n",
    "\n",
    "# fit model\n",
    "for i in range(25000):\n",
    "\tX, y = get_samples()\n",
    "\tmodel.fit(X, y, epochs=1, verbose=2, shuffle=False)\n",
    "\n",
    "# generate new shapes from scratch\n",
    "rect = generate_rectangle(model)\n",
    "plot_rectangle(rect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostic underfit 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from matplotlib import pyplot\n",
    "from numpy import array\n",
    "\n",
    "# return training data\n",
    "def get_train():\n",
    "\tseq = [[0.0, 0.1], [0.1, 0.2], [0.2, 0.3], [0.3, 0.4], [0.4, 0.5]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((len(X), 1, 1))\n",
    "\treturn X, y\n",
    "\n",
    "# return validation data\n",
    "def get_val():\n",
    "\tseq = [[0.5, 0.6], [0.6, 0.7], [0.7, 0.8], [0.8, 0.9], [0.9, 1.0]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((len(X), 1, 1))\n",
    "\treturn X, y\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(10, input_shape=(1,1)))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "# compile model\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "# fit model\n",
    "X,y = get_train()\n",
    "valX, valY = get_val()\n",
    "history = model.fit(X, y, epochs=100, validation_data=(valX, valY), shuffle=False)\n",
    "# plot train and validation loss\n",
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostic underfit 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from matplotlib import pyplot\n",
    "from numpy import array\n",
    "\n",
    "# return training data\n",
    "def get_train():\n",
    "\tseq = [[0.0, 0.1], [0.1, 0.2], [0.2, 0.3], [0.3, 0.4], [0.4, 0.5]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((5, 1, 1))\n",
    "\treturn X, y\n",
    "\n",
    "# return validation data\n",
    "def get_val():\n",
    "\tseq = [[0.5, 0.6], [0.6, 0.7], [0.7, 0.8], [0.8, 0.9], [0.9, 1.0]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((len(X), 1, 1))\n",
    "\treturn X, y\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(1, input_shape=(1,1)))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "# compile model\n",
    "model.compile(loss='mae', optimizer='sgd')\n",
    "# fit model\n",
    "X,y = get_train()\n",
    "valX, valY = get_val()\n",
    "history = model.fit(X, y, epochs=300, validation_data=(valX, valY), shuffle=False)\n",
    "# plot train and validation loss\n",
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostic good fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from matplotlib import pyplot\n",
    "from numpy import array\n",
    "\n",
    "# return training data\n",
    "def get_train():\n",
    "\tseq = [[0.0, 0.1], [0.1, 0.2], [0.2, 0.3], [0.3, 0.4], [0.4, 0.5]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((5, 1, 1))\n",
    "\treturn X, y\n",
    "\n",
    "# return validation data\n",
    "def get_val():\n",
    "\tseq = [[0.5, 0.6], [0.6, 0.7], [0.7, 0.8], [0.8, 0.9], [0.9, 1.0]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((len(X), 1, 1))\n",
    "\treturn X, y\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(10, input_shape=(1,1)))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "# compile model\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "# fit model\n",
    "X,y = get_train()\n",
    "valX, valY = get_val()\n",
    "history = model.fit(X, y, epochs=800, validation_data=(valX, valY), shuffle=False)\n",
    "# plot train and validation loss\n",
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostic overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from matplotlib import pyplot\n",
    "from numpy import array\n",
    "\n",
    "# return training data\n",
    "def get_train():\n",
    "\tseq = [[0.0, 0.1], [0.1, 0.2], [0.2, 0.3], [0.3, 0.4], [0.4, 0.5]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((5, 1, 1))\n",
    "\treturn X, y\n",
    "\n",
    "# return validation data\n",
    "def get_val():\n",
    "\tseq = [[0.5, 0.6], [0.6, 0.7], [0.7, 0.8], [0.8, 0.9], [0.9, 1.0]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((len(X), 1, 1))\n",
    "\treturn X, y\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(10, input_shape=(1,1)))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "# compile model\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "# fit model\n",
    "X,y = get_train()\n",
    "valX, valY = get_val()\n",
    "history = model.fit(X, y, epochs=1200, validation_data=(valX, valY), shuffle=False)\n",
    "# plot train and validation loss\n",
    "pyplot.plot(history.history['loss'][500:])\n",
    "pyplot.plot(history.history['val_loss'][500:])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostic multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from matplotlib import pyplot\n",
    "from numpy import array\n",
    "from pandas import DataFrame\n",
    "\n",
    "# return training data\n",
    "def get_train():\n",
    "\tseq = [[0.0, 0.1], [0.1, 0.2], [0.2, 0.3], [0.3, 0.4], [0.4, 0.5]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((5, 1, 1))\n",
    "\treturn X, y\n",
    "\n",
    "# return validation data\n",
    "def get_val():\n",
    "\tseq = [[0.5, 0.6], [0.6, 0.7], [0.7, 0.8], [0.8, 0.9], [0.9, 1.0]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((len(X), 1, 1))\n",
    "\treturn X, y\n",
    "\n",
    "# collect data across multiple repeats\n",
    "train = DataFrame()\n",
    "val = DataFrame()\n",
    "for i in range(5):\n",
    "\t# define model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(LSTM(10, input_shape=(1,1)))\n",
    "\tmodel.add(Dense(1, activation='linear'))\n",
    "\t# compile model\n",
    "\tmodel.compile(loss='mse', optimizer='adam')\n",
    "\tX,y = get_train()\n",
    "\tvalX, valY = get_val()\n",
    "\t# fit model\n",
    "\thistory = model.fit(X, y, epochs=300, validation_data=(valX, valY), shuffle=False)\n",
    "\t# story history\n",
    "\ttrain[str(i)] = history.history['loss']\n",
    "\tval[str(i)] = history.history['val_loss']\n",
    "\n",
    "# plot train and validation loss across multiple runs\n",
    "pyplot.plot(train, color='blue', label='train')\n",
    "pyplot.plot(val, color='orange', label='validation')\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune memory cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from matplotlib import pyplot\n",
    "from pandas import DataFrame\n",
    "from numpy import array\n",
    "\n",
    "# return training data\n",
    "def get_train():\n",
    "\tseq = [[0.0, 0.1], [0.1, 0.2], [0.2, 0.3], [0.3, 0.4], [0.4, 0.5]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((5, 1, 1))\n",
    "\treturn X, y\n",
    "\n",
    "# return validation data\n",
    "def get_val():\n",
    "\tseq = [[0.5, 0.6], [0.6, 0.7], [0.7, 0.8], [0.8, 0.9], [0.9, 1.0]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((len(X), 1, 1))\n",
    "\treturn X, y\n",
    "\n",
    "# fit an LSTM model\n",
    "def fit_model(n_cells):\n",
    "\t# define model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(LSTM(n_cells, input_shape=(1,1)))\n",
    "\tmodel.add(Dense(1, activation='linear'))\n",
    "\t# compile model\n",
    "\tmodel.compile(loss='mse', optimizer='adam')\n",
    "\t# fit model\n",
    "\tX,y = get_train()\n",
    "\tmodel.fit(X, y, epochs=500, shuffle=False, verbose=0)\n",
    "\t# evaluate model\n",
    "\tvalX, valY = get_val()\n",
    "\tloss = model.evaluate(valX, valY, verbose=0)\n",
    "\treturn loss\n",
    "\n",
    "# define scope of search\n",
    "params = [1, 5, 10]\n",
    "n_repeats = 5\n",
    "# grid search parameter values\n",
    "scores = DataFrame()\n",
    "for value in params:\n",
    "\t# repeat each experiment multiple times\n",
    "\tloss_values = list()\n",
    "\tfor i in range(n_repeats):\n",
    "\t\tloss = fit_model(value)\n",
    "\t\tloss_values.append(loss)\n",
    "\t\tprint('>%d/%d param=%f, loss=%f' % (i+1, n_repeats, value, loss))\n",
    "\t# store results for this parameter\n",
    "\tscores[str(value)] = loss_values\n",
    "# summary statistics of results\n",
    "print(scores.describe())\n",
    "# box and whisker plot of results\n",
    "scores.boxplot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from matplotlib import pyplot\n",
    "from pandas import DataFrame\n",
    "from numpy import array\n",
    "\n",
    "# return training data\n",
    "def get_train():\n",
    "\tseq = [[0.0, 0.1], [0.1, 0.2], [0.2, 0.3], [0.3, 0.4], [0.4, 0.5]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((5, 1, 1))\n",
    "\treturn X, y\n",
    "\n",
    "# return validation data\n",
    "def get_val():\n",
    "\tseq = [[0.5, 0.6], [0.6, 0.7], [0.7, 0.8], [0.8, 0.9], [0.9, 1.0]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((len(X), 1, 1))\n",
    "\treturn X, y\n",
    "\n",
    "# fit an LSTM model\n",
    "def fit_model(n_batch):\n",
    "\t# define model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(LSTM(10, input_shape=(1,1)))\n",
    "\tmodel.add(Dense(1, activation='linear'))\n",
    "\t# compile model\n",
    "\tmodel.compile(loss='mse', optimizer='adam')\n",
    "\t# fit model\n",
    "\tX,y = get_train()\n",
    "\tmodel.fit(X, y, epochs=500, shuffle=False, verbose=0, batch_size=n_batch)\n",
    "\t# evaluate model\n",
    "\tvalX, valY = get_val()\n",
    "\tloss = model.evaluate(valX, valY, verbose=0)\n",
    "\treturn loss\n",
    "\n",
    "# define scope of search\n",
    "params = [1, 2, 3]\n",
    "n_repeats = 5\n",
    "# grid search parameter values\n",
    "scores = DataFrame()\n",
    "for value in params:\n",
    "\t# repeat each experiment multiple times\n",
    "\tloss_values = list()\n",
    "\tfor i in range(n_repeats):\n",
    "\t\tloss = fit_model(value)\n",
    "\t\tloss_values.append(loss)\n",
    "\t\tprint('>%d/%d param=%f, loss=%f' % (i+1, n_repeats, value, loss))\n",
    "\t# store results for this parameter\n",
    "\tscores[str(value)] = loss_values\n",
    "# summary statistics of results\n",
    "print(scores.describe())\n",
    "# box and whisker plot of results\n",
    "scores.boxplot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from numpy import array\n",
    "from keras.models import load_model\n",
    "\n",
    "# return training data\n",
    "def get_train():\n",
    "\tseq = [[0.0, 0.1], [0.1, 0.2], [0.2, 0.3], [0.3, 0.4], [0.4, 0.5]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((len(X), 1, 1))\n",
    "\treturn X, y\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(10, input_shape=(1,1)))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "# compile model\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "# fit model\n",
    "X,y = get_train()\n",
    "model.fit(X, y, epochs=300, shuffle=False, verbose=0)\n",
    "# save model to single file\n",
    "model.save('lstm_model.h5')\n",
    "\n",
    "# snip...\n",
    "# later, perhaps run from another script\n",
    "\n",
    "# load model from single file\n",
    "model = load_model('lstm_model.h5')\n",
    "# make predictions\n",
    "yhat = model.predict(X, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save separate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from numpy import array\n",
    "from keras.models import model_from_json\n",
    "\n",
    "# return training data\n",
    "def get_train():\n",
    "\tseq = [[0.0, 0.1], [0.1, 0.2], [0.2, 0.3], [0.3, 0.4], [0.4, 0.5]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((len(X), 1, 1))\n",
    "\treturn X, y\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(10, input_shape=(1,1)))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "# compile model\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "# fit model\n",
    "X,y = get_train()\n",
    "model.fit(X, y, epochs=300, shuffle=False, verbose=0)\n",
    "# convert model architecture to JSON format\n",
    "architecture = model.to_json()\n",
    "# save architecture to JSON file\n",
    "with open('architecture.json', 'wt') as json_file:\n",
    "    json_file.write(architecture)\n",
    "# save weights to hdf5 file\n",
    "model.save_weights('weights.h5')\n",
    "\n",
    "# snip...\n",
    "# later, perhaps run from another script\n",
    "\n",
    "# load architecture from JSON File\n",
    "json_file = open('architecture.json', 'rt')\n",
    "architecture = json_file.read()\n",
    "json_file.close()\n",
    "# create model from architecture\n",
    "model = model_from_json(architecture)\n",
    "# load weights from hdf5 file\n",
    "model.load_weights('weights.h5')\n",
    "# make predictions\n",
    "yhat = model.predict(X, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix 02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scipy\n",
    "import scipy\n",
    "print('scipy: %s' % scipy.__version__)\n",
    "# numpy\n",
    "import numpy\n",
    "print('numpy: %s' % numpy.__version__)\n",
    "# matplotlib\n",
    "import matplotlib\n",
    "print('matplotlib: %s' % matplotlib.__version__)\n",
    "# pandas\n",
    "import pandas\n",
    "print('pandas: %s' % pandas.__version__)\n",
    "# statsmodels\n",
    "import statsmodels\n",
    "print('statsmodels: %s' % statsmodels.__version__)\n",
    "# scikit-learn\n",
    "import sklearn\n",
    "print('sklearn: %s' % sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# theano\n",
    "import theano\n",
    "print('theano: %s' % theano.__version__)\n",
    "# tensorflow\n",
    "import tensorflow\n",
    "print('tensorflow: %s' % tensorflow.__version__)\n",
    "# keras\n",
    "import keras\n",
    "print('keras: %s' % keras.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
